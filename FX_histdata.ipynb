{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFrame:\n",
    "    ONE_MINUTE = 'M1'\n",
    "    TICK_DATA = 'T'\n",
    "    TICK_DATA_LAST = 'T_LAST'\n",
    "    TICK_DATA_BID = 'T_BID'\n",
    "    TICK_DATA_ASK = 'T_ASK'\n",
    "\n",
    "\n",
    "class Platform:\n",
    "    META_TRADER = 'MT'\n",
    "    GENERIC_ASCII = 'ASCII'\n",
    "    EXCEL = 'XLSX'\n",
    "    NINJA_TRADER = 'NT'\n",
    "    META_STOCK = 'MS'\n",
    "\n",
    "\n",
    "class URL:\n",
    "    META_TRADER = 'https://www.histdata.com/download-free-forex-historical-data/?/metatrader/1-minute-bar-quotes/'\n",
    "    ASCII_1M = 'https://www.histdata.com/download-free-forex-historical-data/?/ascii/1-minute-bar-quotes/'\n",
    "    ASCII_TICK_DATA = 'https://www.histdata.com/download-free-forex-historical-data/?/ascii/tick-data-quotes/'\n",
    "    EXCEL = 'https://www.histdata.com/download-free-forex-historical-data/?/excel/1-minute-bar-quotes/'\n",
    "    NINJA_TRADER = 'https://www.histdata.com/download-free-forex-historical-data/?/ninjatrader/1-minute-bar-quotes/'\n",
    "    NINJA_TRADER_LAST_QUOTES = 'https://www.histdata.com/download-free-forex-historical-data/?/ninjatrader/tick-last-quotes/'\n",
    "    NINJA_TRADER_BID_QUOTES = 'https://www.histdata.com/download-free-forex-historical-data/?/ninjatrader/tick-bid-quotes/'\n",
    "    NINJA_TRADER_ASK_QUOTES = 'https://www.histdata.com/download-free-forex-historical-data/?/ninjatrader/tick-ask-quotes/'\n",
    "    META_STOCK = 'https://www.histdata.com/download-free-forex-historical-data/?/metastock/1-minute-bar-quotes/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_referer(time_frame, platform):\n",
    "    if time_frame == TimeFrame.TICK_DATA and platform == Platform.GENERIC_ASCII:\n",
    "        return URL.ASCII_TICK_DATA\n",
    "    elif time_frame == TimeFrame.TICK_DATA_LAST and platform == Platform.NINJA_TRADER:\n",
    "        return URL.NINJA_TRADER_LAST_QUOTES\n",
    "    elif time_frame == TimeFrame.TICK_DATA_BID and platform == Platform.NINJA_TRADER:\n",
    "        return URL.NINJA_TRADER_BID_QUOTES\n",
    "    elif time_frame == TimeFrame.TICK_DATA_ASK and platform == Platform.NINJA_TRADER:\n",
    "        return URL.NINJA_TRADER_ASK_QUOTES\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.GENERIC_ASCII:\n",
    "        return URL.ASCII_1M\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.META_TRADER:\n",
    "        return URL.META_TRADER\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.EXCEL:\n",
    "        return URL.EXCEL\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.NINJA_TRADER:\n",
    "        return URL.NINJA_TRADER\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.META_STOCK:\n",
    "        return URL.META_STOCK\n",
    "    else:\n",
    "        raise Exception('Invalid combination of time_frame and platform.')\n",
    "\n",
    "\n",
    "def get_referer(referer_prefix, pair, year, month):\n",
    "    if month is not None:\n",
    "        return referer_prefix + '{}/{}/{}'.format(pair.lower(), year, month)\n",
    "    return referer_prefix + '{}/{}'.format(pair.lower(), year)\n",
    "\n",
    "\n",
    "def download_hist_data(year='2016',\n",
    "                       month=None,\n",
    "                       pair='eurusd',\n",
    "                       time_frame=TimeFrame.ONE_MINUTE,\n",
    "                       platform=Platform.GENERIC_ASCII,\n",
    "                       output_directory='.',\n",
    "                       verbose=True):\n",
    "    \"\"\"\n",
    "    Download 1-Minute FX data per month.\n",
    "    :param year: Trading year. Format is 2016.\n",
    "    :param month: Trading month. Format is 7 or 12.\n",
    "    :param pair: Currency pair. Example: eurgbp.\n",
    "    :param time_frame: M1 (one minute) or T (tick data)\n",
    "    :param platform: MT, ASCII, XLSX, NT, MS\n",
    "    :param output_directory: Where to dump the data.\n",
    "    :return: ZIP Filename.\n",
    "    \"\"\"\n",
    "\n",
    "    tick_data = time_frame.startswith('T')\n",
    "    if (not tick_data) and ((int(year) >= datetime.now().year and month is None) or\n",
    "                            (int(year) <= datetime.now().year - 1 and month is not None)):\n",
    "        msg = 'For the current year, please specify month=7 for example.\\n'\n",
    "        msg += 'For the past years, please query per year with month=None.'\n",
    "        raise AssertionError(msg)\n",
    "\n",
    "    prefix_referer = get_prefix_referer(time_frame, platform)\n",
    "    referer = get_referer(prefix_referer, pair.lower(), year, month)\n",
    "\n",
    "    # Referer is the most important thing here.\n",
    "    headers = {'Host': 'www.histdata.com',\n",
    "               'Connection': 'keep-alive',\n",
    "               'Content-Length': '104',\n",
    "               'Cache-Control': 'max-age=0',\n",
    "               'Origin': 'https://www.histdata.com',\n",
    "               'Upgrade-Insecure-Requests': '1',\n",
    "               'Content-Type': 'application/x-www-form-urlencoded',\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "               'Referer': referer}\n",
    "\n",
    "    if verbose:\n",
    "        print(referer)\n",
    "    r1 = requests.get(referer, allow_redirects=True)\n",
    "    assert r1.status_code == 200, 'Make sure the website www.histdata.com is up.'\n",
    "\n",
    "    soup = BeautifulSoup(r1.content, 'html.parser')\n",
    "    try:\n",
    "        token = soup.find('input', {'id': 'tk'}).attrs['value']\n",
    "        assert len(token) > 0\n",
    "    except:\n",
    "        raise AssertionError('There is no token. Please make sure your year/month/pair is correct.'\n",
    "                             'Example is year=2016, month=7, pair=eurgbp')\n",
    "\n",
    "    data = {'tk': token,\n",
    "            'date': str(year),\n",
    "            'datemonth': '{}{}'.format(year, str(month).zfill(2)) if month is not None else str(year),\n",
    "            'platform': platform,\n",
    "            'timeframe': time_frame,\n",
    "            'fxpair': pair.upper()}\n",
    "    r = requests.post(url='https://www.histdata.com/get.php',\n",
    "                      data=data,\n",
    "                      headers=headers)\n",
    "\n",
    "    assert len(r.content) > 0, 'No data could be found here.'\n",
    "    if verbose:\n",
    "        print(data)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    if month is None:\n",
    "        output_filename = 'DAT_{}_{}_{}_{}.zip'.format(platform, pair.upper(), time_frame, str(year))\n",
    "    else:\n",
    "        output_filename = 'DAT_{}_{}_{}_{}.zip'.format(platform, pair.upper(), time_frame,\n",
    "                                                       '{}{}'.format(year, str(month).zfill(2)))\n",
    "    output_filename = os.path.join(output_directory, output_filename)\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    if verbose:\n",
    "        print('Wrote to {}'.format(output_filename))\n",
    "    return output_filename\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # print(download_hist_data(year='2019', month='6', platform=Platform.NINJA_TRADER, time_frame=TimeFrame.TICK_DATA_LAST))\n",
    "    # print(download_hist_data(year='2019', month='6', platform=Platform.NINJA_TRADER, time_frame=TimeFrame.TICK_DATA_ASK))\n",
    "    # print(download_hist_data(year='2019', month='6', platform=Platform.NINJA_TRADER, time_frame=TimeFrame.TICK_DATA_BID))\n",
    "    # print(download_hist_data(year='2019', month='6', platform=Platform.NINJA_TRADER, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    # print(download_hist_data(year='2019', month='6', platform=Platform.GENERIC_ASCII, time_frame=TimeFrame.TICK_DATA))\n",
    "    # print(download_hist_data(year='2019', month='6', platform=Platform.EXCEL, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    # print(download_hist_data(year='2019', month='6', platform=Platform.META_TRADER, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    # print(download_hist_data(year='2019', month='6', platform=Platform.META_STOCK, time_frame=TimeFrame.ONE_MINUTE))\n",
    "\n",
    "    # print(\n",
    "    #     download_hist_data(year='2018', month='6', platform=Platform.NINJA_TRADER, time_frame=TimeFrame.TICK_DATA_LAST))\n",
    "    # print(\n",
    "    #     download_hist_data(year='2018', month='6', platform=Platform.NINJA_TRADER, time_frame=TimeFrame.TICK_DATA_ASK))\n",
    "    # print(\n",
    "    #     download_hist_data(year='2018', month='6', platform=Platform.NINJA_TRADER, time_frame=TimeFrame.TICK_DATA_BID))\n",
    "    # print(download_hist_data(year='2018', month=None, platform=Platform.NINJA_TRADER, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    # print(download_hist_data(year='2018', month='2', platform=Platform.GENERIC_ASCII, time_frame=TimeFrame.TICK_DATA))\n",
    "    # print(download_hist_data(year='2018', month=None, platform=Platform.EXCEL, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    # print(download_hist_data(year='2018', month=None, platform=Platform.META_TRADER, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    # print(download_hist_data(year='2018', month=None, platform=Platform.META_STOCK, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data_bid, first):\n",
    "\n",
    "    N = data_bid.shape[0]\n",
    "    \n",
    "    Hour = []\n",
    "    Min = []\n",
    "    Time = []\n",
    "    Date = []\n",
    "    Open = []\n",
    "    High = []\n",
    "    Low = []\n",
    "    Close = []\n",
    "    Ask = []\n",
    "    Volume = []\n",
    "    \n",
    "    Hour.append(int(data_bid[\"Time\"][first].split(':')[0]))\n",
    "    Min.append(int(data_bid[\"Time\"][first].split(':')[1]))\n",
    "    Time.append(data_bid[\"Time\"][first])\n",
    "    Date.append(data_bid[\"Date\"][first])\n",
    "    Open.append(data_bid[\"Open\"][first])\n",
    "    Close.append(data_bid[\"Close\"][first])\n",
    "    High.append(data_bid[\"High\"][first])\n",
    "    Low.append(data_bid[\"Low\"][first])\n",
    "    Volume.append(data_bid[\"Volume\"][first])\n",
    "    \n",
    "    \n",
    "    for i in range(first+1,N):\n",
    "        H = int(data_bid[\"Time\"][i].split(':')[0])\n",
    "        M = int(data_bid[\"Time\"][i].split(':')[1])\n",
    "        if Min[-1] == 59:\n",
    "            M = M+60\n",
    "        dis = M - Min[-1]\n",
    "        for j in range(dis):\n",
    "            Hour.append(int(data_bid[\"Time\"][i].split(':')[0]))\n",
    "            Min.append(int(data_bid[\"Time\"][i].split(':')[1]))\n",
    "            Time.append(data_bid[\"Time\"][i])\n",
    "            Date.append(data_bid[\"Date\"][i])\n",
    "            Open.append(data_bid[\"Open\"][i])\n",
    "            Close.append(data_bid[\"Close\"][i])\n",
    "            High.append(data_bid[\"High\"][i])\n",
    "            Low.append(data_bid[\"Low\"][i])\n",
    "            Volume.append(data_bid[\"Volume\"][i])\n",
    "            \n",
    "    d = pd.DataFrame(list(zip(Date, Time, Open, High, Low, Close, Volume)),\n",
    "            columns=['Date','Time','Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "    \n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convertor(data_bid, period):\n",
    "    N = data_bid.shape[0]\n",
    "    Time = []\n",
    "    Date = []\n",
    "    Open = []\n",
    "    High = []\n",
    "    Low = []\n",
    "    Close = []\n",
    "    Ask = []\n",
    "    Volume = []\n",
    "    for i in range(0,N - period,period):\n",
    "        Time.append(data_bid[\"Date\"][i] + ' ' + data_bid[\"Time\"][i])\n",
    "        Date.append(data_bid[\"Date\"][i])\n",
    "        Open.append(data_bid[\"Open\"][i])\n",
    "        Close.append(data_bid[\"Close\"][i+period-1])\n",
    "        High.append(max(data_bid[\"High\"][i:i+period]))\n",
    "        Low.append(min(data_bid[\"Low\"][i:i+period]))\n",
    "        Volume.append(sum(data_bid[\"Volume\"][i:i+period]))\n",
    "    return(Time, Date, Open, High, Low, Close, Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data,period):    \n",
    "    Time, Date, Open, High, Low, Close, Volume = time_convertor(data,period)\n",
    "\n",
    "    week_day = []\n",
    "    for i in range(len(Time)):\n",
    "        day = Date[i].split('.')[2]\n",
    "        month = Date[i].split('.')[1]\n",
    "        year = Date[i].split('.')[0]\n",
    "        week_day.append(calendar.weekday(int(year), int(month), int(day)))\n",
    "\n",
    "    Time = np.array(Time)\n",
    "    Open = np.array(Open)  \n",
    "    High =  np.array (High)\n",
    "    Low =  np.array(Low)\n",
    "    Close =  np.array(Close)\n",
    "    #Ask = np.array(Ask)\n",
    "    week_day = np.array(week_day)\n",
    "\n",
    "    l = np.where(np.logical_or(week_day == 5, week_day == 6))\n",
    "\n",
    "    Time = np.delete(Time, l) \n",
    "    Date = np.delete(Date, l)  \n",
    "    Open = np.delete(Open, l)  \n",
    "    High =  np.delete (High, l)\n",
    "    Low =  np.delete(Low, l)\n",
    "    Close =  np.delete(Close, l)\n",
    "    Volume = np.delete(Volume, l)\n",
    "    #Ask = np.delete(Ask, l)\n",
    "\n",
    "    data = pd.DataFrame(list(zip(Time, Open, High, Low, Close, Volume)),\n",
    "                columns=['Time','Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "    \n",
    "    #return(data, Time, Date, Open, High, Low, Close, Volume)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_data(pair, start_year, end_year, period):    \n",
    "    time_frame = \"M1\"\n",
    "    years = np.arange(start_year,end_year + 1)\n",
    "    df = pd.DataFrame(columns=['Time','Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "    now = datetime.now()\n",
    "    curr = os.getcwd()\n",
    "    if not os.path.split(curr)[1]=='FX_data': os.chdir(\"./FX_data/\")   \n",
    "    for year in years:\n",
    "        first = 0\n",
    "        if year == now.year:\n",
    "            for month in np.arange(1, now.month):\n",
    "                yearmonth = str(year) + str(month) if month > 9 else str(year) + '0' + str(month)\n",
    "                file_name ='DAT_MT_{}_{}_{}.zip'.format(pair.upper(), time_frame, yearmonth)\n",
    "                file_name_csv = 'DAT_MT_{}_{}_{}.csv'.format(pair.upper(), time_frame, yearmonth)\n",
    "                if not os.path.exists(file_name):\n",
    "                    download_hist_data(year=year, month=month,pair=pair, platform=Platform.META_TRADER, time_frame=TimeFrame.ONE_MINUTE, verbose=False)\n",
    "                archive = zipfile.ZipFile(file_name, 'r')\n",
    "                data = pd.read_csv(archive.open(file_name_csv), header=None)\n",
    "                data.columns = ['Date','Time','Open','High','Low','Close','Volume']\n",
    "                if year == start_year and month == 1:\n",
    "                    while not int(data[\"Time\"][first].split(':')[1]) == 0:\n",
    "                        first+=1\n",
    "                data = clean_data(data,first)\n",
    "                data = preprocess(data,period)\n",
    "                df = pd.concat([df,data],ignore_index=True,sort=False, axis=0)            \n",
    "        else:\n",
    "            file_name = 'DAT_MT_{}_{}_{}.zip'.format(pair.upper(), time_frame,year)\n",
    "            file_name_csv = 'DAT_MT_{}_{}_{}.csv'.format(pair.upper(), time_frame,year)\n",
    "            if not os.path.exists(file_name):\n",
    "                download_hist_data(year=year,pair=pair, platform=Platform.META_TRADER, time_frame=TimeFrame.ONE_MINUTE, verbose=False)\n",
    "            archive = zipfile.ZipFile(file_name, 'r')\n",
    "            data = pd.read_csv(archive.open(file_name_csv), header=None)\n",
    "            data.columns = ['Date','Time','Open','High','Low','Close','Volume']\n",
    "            #if year == start_year:\n",
    "            while not int(data[\"Time\"][first].split(':')[1]) == 0:\n",
    "                first+=1\n",
    "            data = clean_data(data,first)\n",
    "            data = preprocess(data,period)\n",
    "            df = pd.concat([df,data],ignore_index=True,sort=False, axis=0)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"gbpjpy\"\n",
    "start_year = 2017\n",
    "year = 2018\n",
    "period = 30\n",
    "first = 0\n",
    "time_frame = \"M5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"gbpjpy\"\n",
    "start_date = 2009\n",
    "end_date = 2018\n",
    "freq = 5\n",
    "\n",
    "file_csv = '{}_{}_{}_{}.csv'.format(pair.upper(), freq, start_date, end_date)\n",
    "file_csv_temp = '{}_{}_{}_{}Temp.csv'.format(pair.upper(), freq, start_date, end_date)\n",
    "file_csv_clean = '{}_{}_{}_{}Clean.csv'.format(pair.upper(), freq, start_date, end_date)\n",
    "\n",
    "curr = os.getcwd()\n",
    "if not os.path.split(curr)[1]=='FX_data': os.chdir(\"../FX_data/\")\n",
    "if os.path.exists(file_csv_clean):\n",
    "    data = pd.read_csv(file_csv_clean)\n",
    "else:\n",
    "    data = construct_data(pair,start_date,end_date,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Close = data[\"Close\"]\n",
    "High = data[\"High\"]\n",
    "Low = data[\"Low\"]\n",
    "Time = data[\"Time\"]\n",
    "Volume = data[\"Volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.sample(list(Close.values), 1000)\n",
    "\n",
    "pip_list = []\n",
    "for i in range(1000):\n",
    "    pip_list.append(math.pow(10,-len(str(sample[i]).split('.')[1])+1))\n",
    "\n",
    "c = Counter(pip_list)\n",
    "PIP_RATIO, count = c.most_common()[0]\n",
    "INVERSE_PIP_RATIO = 1/PIP_RATIO\n",
    "MARGIN = 4\n",
    "\n",
    "def sma(series, window=50, min_periods=0):\n",
    "    # Center must always be False to circumvent look-ahead bias\n",
    "    sma = series.rolling(window=window, min_periods=min_periods,\n",
    "                         center=False).mean()\n",
    "    sma.rename(index='SMA', inplace=True)\n",
    "    return(sma)\n",
    "\n",
    "def stoc(df, col_labels=('Low', 'High', 'Close'),\n",
    "         k_smooth=5, d_smooth=5, window=15, min_periods=0):\n",
    "    # Should col_labels be a dictionary? i.e. {'low':'Low', ...}\n",
    "    low = df[col_labels[0]]\n",
    "    high = df[col_labels[1]]\n",
    "    close = df[col_labels[2]]\n",
    "\n",
    "    # min_periods should always be 0 for this\n",
    "    lowest_low = low.rolling(window=window, min_periods=window).min()\n",
    "    highest_high = high.rolling(window=window, min_periods=window).max()\n",
    "\n",
    "    k = (close - lowest_low) / (highest_high - lowest_low) * 100\n",
    "\n",
    "    if min_periods > 0:\n",
    "        k[:min_periods] = np.NaN\n",
    "\n",
    "    if k_smooth != 0:\n",
    "        k = sma(k, window=k_smooth)\n",
    "    d = sma(k, window=d_smooth)\n",
    "   # return pd.DataFrame({'%K': k, '%D': d})\n",
    "\n",
    "    return(k)\n",
    "\n",
    "def sstoc(df, col_labels=('Low', 'High', 'Close'),\n",
    "          k_smooth=5, d_smooth=5, window=15):\n",
    "    return stoc(df, col_labels=col_labels, k_smooth=k_smooth,\n",
    "    d_smooth=d_smooth, window=window, min_periods=0)\n",
    "\n",
    "def slow_stochastic(data,Kperiod,Dperiod): \n",
    "    not_null = 0\n",
    "    l, h = pd.rolling_min(data[\"Low\"], Kperiod), pd.rolling_max(data[\"High\"], Kperiod)\n",
    "    k = 100 * (data[\"Close\"] - l) / (h - l) \n",
    "    #k = pd.rolling_mean(k, Dperiod)\n",
    "    #if k_smooth != 0:\n",
    "    k = sma(k, window=Dperiod)\n",
    " #   d = sma(k, window=d_smooth)\n",
    "    for i in range(19,k.shape[0]):\n",
    "        if not pd.isnull(k[i]):\n",
    "            not_null = k[i]\n",
    "        else:\n",
    "            k[i] = not_null    \n",
    "    return(k)\n",
    "\n",
    "def stochastic_crossover(i, stochastic):\n",
    "    if stochastic[i]>=50.0 and stochastic[i-1]<50.0:\n",
    "        return(1)\n",
    "    elif stochastic[i]<50.0 and stochastic[i-1]>=50.0:\n",
    "        return(2)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "def distant(first,second, Distance = 50):\n",
    "    if((first-second)> Distance * PIP_RATIO):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "class position:\n",
    "    def __init__(self):\n",
    "        self.have_position = False\n",
    "        self.open_t = []\n",
    "        self.profitloss = []\n",
    "        self.max_profit = []\n",
    "        self.max_loss = []\n",
    "        self.shooting_d = []\n",
    "        self.trigger_d = []\n",
    "        self.returns = []\n",
    "        self.accumPL = []\n",
    "        self.volume = []\n",
    "        self.index = []\n",
    "    def take_position(self, get_positopn_type, uptrend, cum_pips, price, shooting_delta, trigger_delta, time, limit, stop, trailing_stop, i):\n",
    "        if (self.have_position):\n",
    "            if get_positopn_type == \"Buy\" and self.position_type == \"Short\":\n",
    "                profit = (self.open_price - price) * INVERSE_PIP_RATIO\n",
    "                cum_pips += profit\n",
    "                \n",
    "                self.accumPL.append(cum_pips)\n",
    "                self.open_t.append(self.open_time)\n",
    "                self.profitloss.append(profit)\n",
    "                self.max_profit.append((self.open_price - self.low)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.max_loss.append((self.open_price - self.high)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.shooting_d.append(self.shooting_delta)\n",
    "                self.trigger_d.append(self.trigger_delta)\n",
    "                self.returns.append(list((Close[i-31:i-1] - Close[i-30:i])*INVERSE_PIP_RATIO/Close[i-31:i-1]))\n",
    "                \n",
    "               # self.volume.append(list((Volume[i-31:i-1] - Volume[i-30:i])*INVERSE_PIP_RATIO/Volume[i-31:i-1]))\n",
    "                \n",
    "                \n",
    "                print(\"Short position opened %s price %.5f closed %s profit %.5f pips\"%(self.open_time, self.open_price, time, profit))\n",
    "                print(\"Maximum Profit: \", (self.open_price - self.low)*INVERSE_PIP_RATIO)\n",
    "                print(\"Maximum Loss: \", (self.open_price - self.high)*INVERSE_PIP_RATIO)\n",
    "               # print(\"Shooting Delta: \", self.shooting_delta)\n",
    "               # print(\"Trigger Delta: \", self.trigger_delta)\n",
    "               # print(\"Ratio of Deltas: \", self.shooting_delta/self.trigger_delta)\n",
    "                print(\"Cumulative Pips is :\",cum_pips)\n",
    "                print(\"*************************************************\")\n",
    "                self.open_price = price\n",
    "                self.position_type = \"Long\"\n",
    "                self.open_time = time\n",
    "                self.limit_price = limit\n",
    "                self.stop_loss = stop\n",
    "                self.trailing_stop = trailing_stop\n",
    "                self.trailing_price = price\n",
    "                self.high = 0\n",
    "                self.low = 10000\n",
    "                self.shooting_delta = shooting_delta\n",
    "                self.trigger_delta = trigger_delta\n",
    "                uptrend = True\n",
    "                self.index.append(i)\n",
    "                #print(\"Buy at %s price %.5f, limit order at %.5f, stop loss at %.5f with volume difference of %.2f\"%(time, price,self.limit_price, self.stop_loss,(Volume[i] - Volume[i-1])*INVERSE_PIP_RATIO/Volume[i-1]))\n",
    "                print(\"Buy at %s price %.5f, limit order at %.5f, stop loss at %.5f\"%(time, price,self.limit_price, self.stop_loss))\n",
    "                #print(\"*************************************************\")\n",
    "            elif get_positopn_type == \"Sell\" and self.position_type == \"Long\":\n",
    "                profit = (price - self.open_price) * INVERSE_PIP_RATIO\n",
    "                cum_pips += profit\n",
    "               \n",
    "                self.accumPL.append(cum_pips)\n",
    "                self.open_t.append(self.open_time)\n",
    "                self.profitloss.append(profit)\n",
    "                self.max_profit.append((self.high - self.open_price)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.max_loss.append((self.low - self.open_price)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.shooting_d.append(self.shooting_delta)\n",
    "                self.trigger_d.append(self.trigger_delta)\n",
    "                self.returns.append(list((Close[i-31:i-1] - Close[i-30:i])*INVERSE_PIP_RATIO/Close[i-31:i-1]))\n",
    "              #  self.volume.append(list((Volume[i-31:i-1] - Volume[i-30:i])*INVERSE_PIP_RATIO/Volume[i-31:i-1]))\n",
    "                \n",
    "                print(\"Long position opened %s price %.5f closed %s profit %.5f pips\"%(self.open_time, self.open_price, time, profit))\n",
    "                print(\"Maximum Profit: \", (self.high - self.open_price)*INVERSE_PIP_RATIO)\n",
    "                print(\"Maximum Loss: \", (self.low - self.open_price)*INVERSE_PIP_RATIO)\n",
    "               # print(\"Shooting Delta: \", self.shooting_delta)\n",
    "               # print(\"Trigger Delta: \", self.trigger_delta)\n",
    "               # print(\"Ratio of Deltas: \", self.shooting_delta/self.trigger_delta)\n",
    "                print(\"Cumulative Pips is :\",cum_pips)\n",
    "                print(\"*************************************************\")\n",
    "                self.open_price = price\n",
    "                self.position_type = \"Short\"\n",
    "                self.open_time = time\n",
    "                self.limit_price = limit\n",
    "                self.stop_loss = stop\n",
    "                self.trailing_stop = trailing_stop\n",
    "                self.trailing_price = price\n",
    "                self.high = 0\n",
    "                self.low = 10000\n",
    "                self.shooting_delta = shooting_delta\n",
    "                self.trigger_delta = trigger_delta\n",
    "                uptrend = False\n",
    "                self.index.append(i)\n",
    "                #print(\"Sell at %s price %.5f, limit order at %.5f, stop loss at %.5f with volume difference of %.2f\"%(time, price, self.limit_price, self.stop_loss, (Volume[i] - Volume[i-1])*INVERSE_PIP_RATIO/Volume[i-1]))\n",
    "                print(\"Sell at %s price %.5f, limit order at %.5f, stop loss at %.5f\"%(time, price, self.limit_price, self.stop_loss))\n",
    "                #print(\"************************************************\")\n",
    "        else:\n",
    "            if get_positopn_type == \"Buy\":\n",
    "                self.open_price = price\n",
    "                self.have_position = True;\n",
    "                self.position_type = \"Long\"\n",
    "                self.open_time = time\n",
    "                self.limit_price = limit\n",
    "                self.stop_loss = stop\n",
    "                self.trailing_stop = trailing_stop\n",
    "                self.trailing_price = price\n",
    "                self.high = 0\n",
    "                self.low = 10000\n",
    "                self.shooting_delta = shooting_delta\n",
    "                self.trigger_delta = trigger_delta\n",
    "                self.returns.append(list((Close[i-31:i-1] - Close[i-30:i])*INVERSE_PIP_RATIO/Close[i-31:i-1]))\n",
    "            #    self.volume.append(list((Volume[i-31:i-1] - Volume[i-30:i])*INVERSE_PIP_RATIO/Volume[i-31:i-1]))\n",
    "                uptrend = True\n",
    "                self.index.append(i)\n",
    "                #print(\"Buy at %s price %.5f, limit order at %.5f, stop loss at %.5f with volume difference of %.2f\"%(time, price, self.limit_price, self.stop_loss, (Volume[i] - Volume[i-1])*INVERSE_PIP_RATIO/Volume[i-1]))\n",
    "                print(\"Buy at %s price %.5f, limit order at %.5f, stop loss at %.5f\"%(time, price, self.limit_price, self.stop_loss))\n",
    "                \n",
    "                #print(\"*************************************************\")\n",
    "            elif get_positopn_type == \"Sell\":\n",
    "                self.open_price = price\n",
    "                self.have_position=True; \n",
    "                self.position_type = \"Short\"\n",
    "                self.open_time = time\n",
    "                self.limit_price = limit\n",
    "                self.stop_loss = stop\n",
    "                self.trailing_stop = trailing_stop\n",
    "                self.trailing_price = price\n",
    "                self.high = 0\n",
    "                self.low = 10000\n",
    "                self.shooting_delta = shooting_delta\n",
    "                self.trigger_delta = trigger_delta\n",
    "                self.returns.append(list((Close[i-31:i-1] - Close[i-30:i])*INVERSE_PIP_RATIO/Close[i-31:i-1]))\n",
    "            #    self.volume.append(list((Volume[i-31:i-1] - Volume[i-30:i])*INVERSE_PIP_RATIO/Volume[i-31:i-1]))\n",
    "                uptrend = False \n",
    "                self.index.append(i)\n",
    "                #print(\"Sell at %s price %.5f, limit order at %.5f, stop loss at %.5f  with volume difference of %.2f\"%(time, price, self.limit_price, self.stop_loss, (Volume[i] - Volume[i-1])*INVERSE_PIP_RATIO/Volume[i-1]))\n",
    "                print(\"Sell at %s price %.5f, limit order at %.5f, stop loss at %.5f\"%(time, price, self.limit_price, self.stop_loss))\n",
    "                \n",
    "                #print(\"*************************************************\")\n",
    "        return uptrend, cum_pips \n",
    "    \n",
    "    def close_position(self, cum_pips, time, Low, High, state):\n",
    "        if self.position_type == \"Short\":\n",
    "            if High > self.high: self.high = High\n",
    "            if Low < self.low: self.low = Low\n",
    "            \n",
    "            if Low + MARGIN * PIP_RATIO < self.limit_price:\n",
    "                profit = (self.open_price - self.limit_price)*INVERSE_PIP_RATIO\n",
    "                cum_pips += profit\n",
    "                \n",
    "                self.accumPL.append(cum_pips)\n",
    "                self.open_t.append(self.open_time)\n",
    "                self.profitloss.append(profit)\n",
    "                self.max_profit.append((self.open_price - self.low)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.max_loss.append((self.open_price - self.high)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.shooting_d.append(self.shooting_delta)\n",
    "                self.trigger_d.append(self.trigger_delta)\n",
    "                \n",
    "                \n",
    "                print(\"Short position opened %s price %.5f closed %s profit %d pips\"%(self.open_time, self.open_price, time, profit))\n",
    "                print(\"Maximum Profit: \", (self.open_price - self.low)*INVERSE_PIP_RATIO)\n",
    "                print(\"Maximum Loss: \", (self.open_price - self.high)*INVERSE_PIP_RATIO)\n",
    "               # print(\"Shooting Delta: \", self.shooting_delta)\n",
    "               # print(\"Trigger Delta: \", self.trigger_delta)\n",
    "               # print(\"Ratio of Deltas: \", self.shooting_delta/self.trigger_delta)\n",
    "                print(\"Cumulative Pips is :\",cum_pips)\n",
    "                print(\"*************************************************\")\n",
    "                self.low = 10000\n",
    "                self.high = 0\n",
    "                if state == 3:\n",
    "                    state = 0\n",
    "                elif state == 13:\n",
    "                    state = 10\n",
    "                self.have_position = False\n",
    "            elif High + MARGIN * PIP_RATIO > self.stop_loss:\n",
    "                profit = (self.open_price - self.stop_loss) * INVERSE_PIP_RATIO\n",
    "                cum_pips += profit\n",
    "                \n",
    "                self.accumPL.append(cum_pips)\n",
    "                self.open_t.append(self.open_time)\n",
    "                self.profitloss.append(profit)\n",
    "                self.max_profit.append((self.open_price - self.low)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.max_loss.append((self.open_price - self.high)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.shooting_d.append(self.shooting_delta)\n",
    "                self.trigger_d.append(self.trigger_delta)\n",
    "                \n",
    "                \n",
    "                print(\"Short position opened %s price %.5f closed %s profit %d pips\"%(self.open_time, self.open_price, time, profit))\n",
    "                print(\"Maximum Profit: \", (self.open_price - self.low)*INVERSE_PIP_RATIO)\n",
    "                print(\"Maximum Loss: \", (self.open_price - self.high)*INVERSE_PIP_RATIO)\n",
    "               # print(\"Shooting Delta: \", self.shooting_delta)\n",
    "               # print(\"Trigger Delta: \", self.trigger_delta)\n",
    "               # print(\"Ratio of Deltas: \", self.shooting_delta/self.trigger_delta)\n",
    "                print(\"Cumulative Pips is :\",cum_pips)\n",
    "                print(\"*************************************************\")\n",
    "                self.low = 10000\n",
    "                self.high = 0\n",
    "                if state == 3:\n",
    "                    state = 0\n",
    "                elif state == 13:\n",
    "                    state = 10\n",
    "                self.have_position = False\n",
    "                \n",
    "            if self.trailing_stop > 0:\n",
    "                if self.trailing_price - Low > self.trailing_stop * PIP_RATIO:\n",
    "                    self.stop_loss = self.stop_loss - self.trailing_stop * PIP_RATIO\n",
    "                    self.trailing_price = self.trailing_price - self.trailing_stop * PIP_RATIO\n",
    "                \n",
    "        else:\n",
    "            if High > self.high: self.high = High\n",
    "            if Low < self.low: self.low = Low\n",
    "            \n",
    "            if High > self.limit_price:\n",
    "                profit = (self.limit_price - self.open_price) * INVERSE_PIP_RATIO\n",
    "                cum_pips += profit\n",
    "                \n",
    "                self.accumPL.append(cum_pips)\n",
    "                self.open_t.append(self.open_time)\n",
    "                self.profitloss.append(profit)\n",
    "                self.max_profit.append((self.high - self.open_price)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.max_loss.append((self.low - self.open_price)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.shooting_d.append(self.shooting_delta)\n",
    "                self.trigger_d.append(self.trigger_delta)\n",
    "                \n",
    "                \n",
    "                print(\"Long position opened %s price %.5f closed %s profit %d pips\"%(self.open_time, self.open_price, time, profit))\n",
    "                print(\"Maximum Profit: \", (self.high - self.open_price)*INVERSE_PIP_RATIO)\n",
    "                print(\"Maximum Loss: \", (self.low - self.open_price)*INVERSE_PIP_RATIO)\n",
    "               # print(\"Shooting Delta: \", self.shooting_delta)\n",
    "               # print(\"Trigger Delta: \", self.trigger_delta)\n",
    "               # print(\"Ratio of Deltas: \", self.shooting_delta/self.trigger_delta)\n",
    "                print(\"Cumulative Pips is :\",cum_pips)\n",
    "                print(\"************************************************\")\n",
    "                self.low = 10000\n",
    "                self.high = 0\n",
    "                if state == 3:\n",
    "                    state = 0\n",
    "                elif state == 13:\n",
    "                    state = 10\n",
    "                self.have_position = False\n",
    "            elif Low < self.stop_loss:\n",
    "                profit = (self.stop_loss - self.open_price) * INVERSE_PIP_RATIO\n",
    "                cum_pips += profit\n",
    "                \n",
    "                self.accumPL.append(cum_pips)\n",
    "                self.open_t.append(self.open_time)\n",
    "                self.profitloss.append(profit)\n",
    "                self.max_profit.append((self.high - self.open_price)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.max_loss.append((self.low - self.open_price)*INVERSE_PIP_RATIO/self.open_price)\n",
    "                self.shooting_d.append(self.shooting_delta)\n",
    "                self.trigger_d.append(self.trigger_delta)\n",
    "                #print(\"low\")\n",
    "                #print(Low)\n",
    "                #print(\"stop loss\")\n",
    "                #print(self.stop_loss)\n",
    "            \n",
    "                print(\"Long position opened %s price %.5f closed %s profit %d pips\"%(self.open_time, self.open_price, time, profit))\n",
    "                print(\"Maximum Profit: \", (self.high - self.open_price)*INVERSE_PIP_RATIO)\n",
    "                print(\"Maximum Loss: \", (self.low - self.open_price)*INVERSE_PIP_RATIO)\n",
    "               # print(\"Shooting Delta: \", self.shooting_delta)\n",
    "               # print(\"Trigger Delta: \", self.trigger_delta)\n",
    "               # print(\"Ratio of Deltas: \", self.shooting_delta/self.trigger_delta)\n",
    "                print(\"Cumulative Pips is :\",cum_pips)\n",
    "                print(\"*************************************************\")\n",
    "                self.low = 10000\n",
    "                self.high = 0\n",
    "                if state == 3:\n",
    "                    state = 0\n",
    "                elif state == 13:\n",
    "                    state = 10\n",
    "                self.have_position = False\n",
    "                \n",
    "            if self.trailing_stop > 0:                \n",
    "                if High - self.trailing_price > self.trailing_stop * PIP_RATIO:\n",
    "                    self.stop_loss =  self.stop_loss + self.trailing_stop * PIP_RATIO\n",
    "                    self.trailing_price = self.trailing_price + self.trailing_stop * PIP_RATIO     \n",
    "        return cum_pips, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sell at 2009.01.12 03:50 price 134.72000, limit order at 130.72000, stop loss at 140.72000\n",
      "Short position opened 2009.01.12 03:50 price 134.72000 closed 2009.01.13 02:30 profit 400 pips\n",
      "Maximum Profit:  421.9999999999999\n",
      "Maximum Loss:  -47.99999999999898\n",
      "Cumulative Pips is : 400.0\n",
      "*************************************************\n",
      "Buy at 2009.01.15 21:55 price 133.38000, limit order at 137.38000, stop loss at 127.34000\n",
      "Long position opened 2009.01.15 21:55 price 133.38000 closed 2009.01.19 08:45 profit -220.00000 pips\n",
      "Maximum Profit:  240.99999999999966\n",
      "Maximum Loss:  -222.99999999999898\n",
      "Cumulative Pips is : 180.00000000000114\n",
      "*************************************************\n",
      "Sell at 2009.01.19 08:45 price 131.18000, limit order at 127.18000, stop loss at 137.18000\n",
      "Short position opened 2009.01.19 08:45 price 131.18000 closed 2009.01.20 03:35 profit 400 pips\n",
      "Maximum Profit:  411.00000000000136\n",
      "Maximum Loss:  -43.00000000000068\n",
      "Cumulative Pips is : 580.0000000000011\n",
      "*************************************************\n",
      "Buy at 2009.01.28 11:25 price 128.77000, limit order at 132.77000, stop loss at 122.73000\n",
      "Long position opened 2009.01.28 11:25 price 128.77000 closed 2009.02.05 11:20 profit 400 pips\n",
      "Maximum Profit:  410.9999999999985\n",
      "Maximum Loss:  -340.00000000000057\n",
      "Cumulative Pips is : 980.0000000000011\n",
      "************************************************\n",
      "Sell at 2009.02.11 05:50 price 129.40000, limit order at 125.40000, stop loss at 135.40000\n",
      "Short position opened 2009.02.11 05:50 price 129.40000 closed 2009.02.13 04:45 profit -400 pips\n",
      "Maximum Profit:  221.9999999999999\n",
      "Maximum Loss:  -400.9999999999991\n",
      "Cumulative Pips is : 580.0000000000011\n",
      "*************************************************\n",
      "Buy at 2009.02.23 00:00 price 134.99000, limit order at 138.99000, stop loss at 128.95000\n",
      "Long position opened 2009.02.23 00:00 price 134.99000 closed 2009.02.23 05:30 profit 400 pips\n",
      "Maximum Profit:  406.00000000000307\n",
      "Maximum Loss:  -24.999999999997158\n",
      "Cumulative Pips is : 980.0000000000011\n",
      "************************************************\n",
      "Sell at 2009.02.27 08:20 price 137.55000, limit order at 133.55000, stop loss at 143.55000\n",
      "Short position opened 2009.02.27 08:20 price 137.55000 closed 2009.03.11 23:30 profit 400 pips\n",
      "Maximum Profit:  409.00000000000034\n",
      "Maximum Loss:  -398.99999999999807\n",
      "Cumulative Pips is : 1380.0000000000011\n",
      "*************************************************\n",
      "Buy at 2009.03.12 15:10 price 136.61000, limit order at 140.61000, stop loss at 130.57000\n",
      "Long position opened 2009.03.12 15:10 price 136.61000 closed 2009.03.23 05:00 profit 400 pips\n",
      "Maximum Profit:  410.0000000000023\n",
      "Maximum Loss:  -161.9999999999976\n",
      "Cumulative Pips is : 1780.0000000000011\n",
      "************************************************\n",
      "Sell at 2009.03.25 14:05 price 141.19000, limit order at 137.19000, stop loss at 147.19000\n",
      "Short position opened 2009.03.25 14:05 price 141.19000 closed 2009.03.30 02:10 profit 400 pips\n",
      "Maximum Profit:  418.0000000000007\n",
      "Maximum Loss:  -243.99999999999977\n",
      "Cumulative Pips is : 2180.000000000001\n",
      "*************************************************\n",
      "Buy at 2009.04.01 22:10 price 143.35000, limit order at 147.35000, stop loss at 137.31000\n",
      "Long position opened 2009.04.01 22:10 price 143.35000 closed 2009.04.02 20:10 profit 400 pips\n",
      "Maximum Profit:  409.00000000000034\n",
      "Maximum Loss:  -41.99999999999875\n",
      "Cumulative Pips is : 2580.000000000001\n",
      "************************************************\n",
      "Sell at 2009.04.20 03:55 price 144.85000, limit order at 140.85000, stop loss at 150.85000\n",
      "Short position opened 2009.04.20 03:55 price 144.85000 closed 2009.04.22 09:05 profit 400 pips\n",
      "Maximum Profit:  419.99999999999886\n",
      "Maximum Loss:  -37.999999999999545\n",
      "Cumulative Pips is : 2980.000000000001\n",
      "*************************************************\n",
      "Buy at 2009.05.01 04:20 price 147.10000, limit order at 151.10000, stop loss at 141.06000\n",
      "Long position opened 2009.05.01 04:20 price 147.10000 closed 2009.05.13 19:50 profit -303 pips\n",
      "Maximum Profit:  384.00000000000034\n",
      "Maximum Loss:  -312.99999999999955\n",
      "Cumulative Pips is : 2676.000000000002\n",
      "*************************************************\n",
      "Sell at 2009.05.13 19:50 price 144.12000, limit order at 140.12000, stop loss at 150.12000\n",
      "Short position opened 2009.05.13 19:50 price 144.12000 closed 2009.05.19 02:35 profit -463.00000 pips\n",
      "Maximum Profit:  71.0000000000008\n",
      "Maximum Loss:  -488.99999999999864\n",
      "Cumulative Pips is : 2213.0000000000023\n",
      "*************************************************\n",
      "Buy at 2009.05.19 02:35 price 148.75000, limit order at 152.75000, stop loss at 142.71000\n",
      "Long position opened 2009.05.19 02:35 price 148.75000 closed 2009.05.27 04:50 profit 400 pips\n",
      "Maximum Profit:  408.00000000000125\n",
      "Maximum Loss:  -187.99999999999955\n",
      "Cumulative Pips is : 2613.0000000000023\n",
      "************************************************\n",
      "Sell at 2009.07.06 04:05 price 153.36000, limit order at 149.36000, stop loss at 159.36000\n",
      "Short position opened 2009.07.06 04:05 price 153.36000 closed 2009.07.08 11:20 profit 400 pips\n",
      "Maximum Profit:  437.00000000000045\n",
      "Maximum Loss:  -200.0\n",
      "Cumulative Pips is : 3013.0000000000023\n",
      "*************************************************\n",
      "Buy at 2009.07.15 10:25 price 154.62000, limit order at 158.62000, stop loss at 148.58000\n",
      "Long position opened 2009.07.15 10:25 price 154.62000 closed 2009.08.03 00:40 profit 400 pips\n",
      "Maximum Profit:  400.9999999999991\n",
      "Maximum Loss:  -231.00000000000023\n",
      "Cumulative Pips is : 3413.0000000000023\n",
      "************************************************\n",
      "Sell at 2009.08.12 02:45 price 156.82000, limit order at 152.82000, stop loss at 162.82000\n",
      "Short position opened 2009.08.12 02:45 price 156.82000 closed 2009.08.26 09:15 profit 400 pips\n",
      "Maximum Profit:  425.9999999999991\n",
      "Maximum Loss:  -354.00000000000205\n",
      "Cumulative Pips is : 3813.0000000000023\n",
      "*************************************************\n",
      "Buy at 2009.10.15 19:30 price 148.01000, limit order at 152.01000, stop loss at 141.97000\n",
      "Long position opened 2009.10.15 19:30 price 148.01000 closed 2009.10.22 19:55 profit 400 pips\n",
      "Maximum Profit:  402.000000000001\n",
      "Maximum Loss:  -92.99999999999784\n",
      "Cumulative Pips is : 4213.000000000002\n",
      "************************************************\n",
      "Sell at 2009.10.28 20:05 price 148.21000, limit order at 144.21000, stop loss at 154.21000\n",
      "Short position opened 2009.10.28 20:05 price 148.21000 closed 2009.11.25 23:50 profit 400 pips\n",
      "Maximum Profit:  436.00000000000136\n",
      "Maximum Loss:  -351.9999999999982\n",
      "Cumulative Pips is : 4613.000000000002\n",
      "*************************************************\n",
      "Buy at 2009.12.02 04:50 price 145.47000, limit order at 149.47000, stop loss at 139.43000\n",
      "Long position opened 2009.12.02 04:50 price 145.47000 closed 2009.12.09 02:00 profit -303 pips\n",
      "Maximum Profit:  368.9999999999998\n",
      "Maximum Loss:  -312.00000000000045\n",
      "Cumulative Pips is : 4309.000000000003\n",
      "*************************************************\n",
      "Sell at 2009.12.09 02:00 price 142.59000, limit order at 138.59000, stop loss at 148.59000\n",
      "Short position opened 2009.12.09 02:00 price 142.59000 closed 2009.12.16 05:20 profit -411.00000 pips\n",
      "Maximum Profit:  59.00000000000034\n",
      "Maximum Loss:  -409.99999999999943\n",
      "Cumulative Pips is : 3898.000000000004\n",
      "*************************************************\n",
      "Buy at 2009.12.16 05:20 price 146.70000, limit order at 150.70000, stop loss at 140.66000\n",
      "Long position opened 2009.12.16 05:20 price 146.70000 closed 2010.01.05 19:46 profit -67.00000 pips\n",
      "Maximum Profit:  400.0\n",
      "Maximum Loss:  -308.9999999999975\n",
      "Cumulative Pips is : 3831.0000000000055\n",
      "*************************************************\n",
      "Sell at 2010.01.05 19:46 price 146.03000, limit order at 142.03000, stop loss at 152.03000\n",
      "Short position opened 2010.01.05 19:46 price 146.03000 closed 2010.01.14 02:31 profit -362.00000 pips\n",
      "Maximum Profit:  -9.000000000000341\n",
      "Maximum Loss:  -359.99999999999943\n",
      "Cumulative Pips is : 3469.000000000005\n",
      "*************************************************\n",
      "Buy at 2010.01.14 02:31 price 149.65000, limit order at 153.65000, stop loss at 143.61000\n",
      "Long position opened 2010.01.14 02:31 price 149.65000 closed 2010.01.26 04:36 profit -525.00000 pips\n",
      "Maximum Profit:  34.99999999999943\n",
      "Maximum Loss:  -533.0000000000013\n",
      "Cumulative Pips is : 2944.000000000005\n",
      "*************************************************\n",
      "Sell at 2010.01.26 04:36 price 144.40000, limit order at 140.40000, stop loss at 150.40000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short position opened 2010.01.26 04:36 price 144.40000 closed 2010.02.04 11:41 profit 400 pips\n",
      "Maximum Profit:  506.9999999999993\n",
      "Maximum Loss:  -281.0000000000002\n",
      "Cumulative Pips is : 3344.000000000005\n",
      "*************************************************\n",
      "Buy at 2010.02.17 08:06 price 143.61000, limit order at 147.61000, stop loss at 137.57000\n",
      "Long position opened 2010.02.17 08:06 price 143.61000 closed 2010.02.23 07:41 profit -365.00000 pips\n",
      "Maximum Profit:  2.8421709430404007e-12\n",
      "Maximum Loss:  -379.9999999999983\n",
      "Cumulative Pips is : 2979.0000000000073\n",
      "*************************************************\n",
      "Sell at 2010.02.23 07:41 price 139.96000, limit order at 135.96000, stop loss at 145.96000\n",
      "Short position opened 2010.02.23 07:41 price 139.96000 closed 2010.02.25 08:36 profit 400 pips\n",
      "Maximum Profit:  411.00000000000136\n",
      "Maximum Loss:  -31.999999999999318\n",
      "Cumulative Pips is : 3379.0000000000073\n",
      "*************************************************\n",
      "Buy at 2010.03.12 11:16 price 138.09000, limit order at 142.09000, stop loss at 132.05000\n",
      "Long position opened 2010.03.12 11:16 price 138.09000 closed 2010.03.31 18:56 profit 400 pips\n",
      "Maximum Profit:  409.99999999999943\n",
      "Maximum Loss:  -355.00000000000114\n",
      "Cumulative Pips is : 3779.0000000000073\n",
      "************************************************\n",
      "Sell at 2010.05.06 11:41 price 138.37000, limit order at 134.37000, stop loss at 144.37000\n",
      "Short position opened 2010.05.06 11:41 price 138.37000 closed 2010.05.06 14:11 profit 400 pips\n",
      "Maximum Profit:  492.0000000000016\n",
      "Maximum Loss:  9.999999999999432\n",
      "Cumulative Pips is : 4179.000000000007\n",
      "*************************************************\n",
      "Buy at 2011.04.05 13:56 price 138.00000, limit order at 142.00000, stop loss at 131.96000\n",
      "Long position opened 2011.04.05 13:56 price 138.00000 closed 2011.04.18 01:31 profit -304.00000 pips\n",
      "Maximum Profit:  199.0000000000009\n",
      "Maximum Loss:  -306.0000000000002\n",
      "Cumulative Pips is : 3875.000000000008\n",
      "*************************************************\n",
      "Sell at 2011.04.18 01:31 price 134.96000, limit order at 130.96000, stop loss at 140.96000\n",
      "Short position opened 2011.04.18 01:31 price 134.96000 closed 2011.05.05 15:21 profit 400 pips\n",
      "Maximum Profit:  407.00000000000216\n",
      "Maximum Loss:  -206.99999999999932\n",
      "Cumulative Pips is : 4275.000000000008\n",
      "*************************************************\n",
      "Buy at 2011.10.12 08:46 price 121.39000, limit order at 125.39000, stop loss at 115.35000\n",
      "Long position opened 2011.10.12 08:46 price 121.39000 closed 2011.10.31 00:01 profit 400 pips\n",
      "Maximum Profit:  509.99999999999943\n",
      "Maximum Loss:  -142.00000000000017\n",
      "Cumulative Pips is : 4675.000000000008\n",
      "************************************************\n",
      "Sell at 2012.01.11 11:11 price 117.96700, limit order at 113.96700, stop loss at 123.96700\n",
      "Short position opened 2012.01.11 11:11 price 117.96700 closed 2012.02.07 20:01 profit -435.60000 pips\n",
      "Maximum Profit:  69.0000000000012\n",
      "Maximum Loss:  -439.0999999999977\n",
      "Cumulative Pips is : 4239.400000000011\n",
      "*************************************************\n",
      "Buy at 2012.02.07 20:01 price 122.32300, limit order at 126.32300, stop loss at 116.28300\n",
      "Long position opened 2012.02.07 20:01 price 122.32300 closed 2012.02.20 21:46 profit 400 pips\n",
      "Maximum Profit:  413.40000000000146\n",
      "Maximum Loss:  -93.39999999999975\n",
      "Cumulative Pips is : 4639.400000000011\n",
      "************************************************\n",
      "Sell at 2012.04.06 08:41 price 129.41900, limit order at 125.41900, stop loss at 135.41900\n",
      "Short position opened 2012.04.06 08:41 price 129.41900 closed 2012.05.17 11:36 profit 400 pips\n",
      "Maximum Profit:  411.89999999999856\n",
      "Maximum Loss:  -237.9000000000019\n",
      "Cumulative Pips is : 5039.400000000011\n",
      "*************************************************\n",
      "Buy at 2012.06.07 08:11 price 123.80000, limit order at 127.80000, stop loss at 117.76000\n",
      "Long position opened 2012.06.07 08:11 price 123.80000 closed 2012.09.17 09:06 profit 400 pips\n",
      "Maximum Profit:  411.99999999999903\n",
      "Maximum Loss:  -299.1000000000014\n",
      "Cumulative Pips is : 5439.400000000011\n",
      "************************************************\n",
      "Sell at 2013.02.20 15:56 price 142.55800, limit order at 138.55800, stop loss at 148.55800\n",
      "Short position opened 2013.02.20 15:56 price 142.55800 closed 2013.02.25 15:26 profit 400 pips\n",
      "Maximum Profit:  420.79999999999984\n",
      "Maximum Loss:  -48.500000000001364\n",
      "Cumulative Pips is : 5839.400000000011\n",
      "*************************************************\n",
      "Buy at 2013.03.08 03:46 price 143.47100, limit order at 147.47100, stop loss at 137.43100\n",
      "Long position opened 2013.03.08 03:46 price 143.47100 closed 2013.04.04 20:26 profit 400 pips\n",
      "Maximum Profit:  409.19999999999845\n",
      "Maximum Loss:  -310.30000000000086\n",
      "Cumulative Pips is : 6239.400000000011\n",
      "************************************************\n",
      "Sell at 2013.04.15 14:11 price 148.55600, limit order at 144.55600, stop loss at 154.55600\n",
      "Short position opened 2013.04.15 14:11 price 148.55600 closed 2013.04.25 04:26 profit -400 pips\n",
      "Maximum Profit:  210.9000000000009\n",
      "Maximum Loss:  -425.6\n",
      "Cumulative Pips is : 5839.400000000011\n",
      "*************************************************\n",
      "Buy at 2013.04.25 08:31 price 153.54300, limit order at 157.54300, stop loss at 147.50300\n",
      "Long position opened 2013.04.25 08:31 price 153.54300 closed 2013.06.06 12:26 profit -303 pips\n",
      "Maximum Profit:  317.10000000000207\n",
      "Maximum Loss:  -322.39999999999895\n",
      "Cumulative Pips is : 5535.4000000000115\n",
      "*************************************************\n",
      "Sell at 2013.06.07 00:16 price 149.31900, limit order at 145.31900, stop loss at 155.31900\n",
      "Short position opened 2013.06.07 00:16 price 149.31900 closed 2013.06.10 09:31 profit -457.50000 pips\n",
      "Maximum Profit:  113.10000000000002\n",
      "Maximum Loss:  -464.3000000000029\n",
      "Cumulative Pips is : 5077.900000000012\n",
      "*************************************************\n",
      "Buy at 2013.06.10 09:31 price 153.89400, limit order at 157.89400, stop loss at 147.85400\n",
      "Long position opened 2013.06.10 09:31 price 153.89400 closed 2013.06.12 21:01 profit -482.40000 pips\n",
      "Maximum Profit:  32.40000000000123\n",
      "Maximum Loss:  -498.99999999999807\n",
      "Cumulative Pips is : 4595.500000000014\n",
      "*************************************************\n",
      "Sell at 2013.06.12 21:01 price 149.07000, limit order at 145.07000, stop loss at 155.07000\n",
      "Short position opened 2013.06.12 21:01 price 149.07000 closed 2013.06.20 04:01 profit -253.00000 pips\n",
      "Maximum Profit:  198.49999999999852\n",
      "Maximum Loss:  -258.2000000000022\n",
      "Cumulative Pips is : 4342.500000000014\n",
      "*************************************************\n",
      "Buy at 2013.06.20 04:01 price 151.60000, limit order at 155.60000, stop loss at 145.56000\n",
      "Long position opened 2013.06.20 04:01 price 151.60000 closed 2013.09.04 06:01 profit 400 pips\n",
      "Maximum Profit:  401.400000000001\n",
      "Maximum Loss:  -401.20000000000005\n",
      "Cumulative Pips is : 4742.500000000014\n",
      "************************************************\n",
      "Sell at 2014.01.13 08:27 price 169.50900, limit order at 165.50900, stop loss at 175.50900\n",
      "Short position opened 2014.01.13 08:27 price 169.50900 closed 2014.02.03 10:22 profit 400 pips\n",
      "Maximum Profit:  404.3000000000035\n",
      "Maximum Loss:  -412.29999999999905\n",
      "Cumulative Pips is : 5142.500000000014\n",
      "*************************************************\n",
      "Buy at 2014.02.11 11:47 price 169.06200, limit order at 173.06200, stop loss at 163.02200\n",
      "Long position opened 2014.02.11 11:47 price 169.06200 closed 2014.03.07 08:27 profit 400 pips\n",
      "Maximum Profit:  435.499999999999\n",
      "Maximum Loss:  -76.50000000000148\n",
      "Cumulative Pips is : 5542.500000000014\n",
      "************************************************\n",
      "Sell at 2014.10.01 15:17 price 176.53700, limit order at 172.53700, stop loss at 182.53700\n",
      "Short position opened 2014.10.01 15:17 price 176.53700 closed 2014.10.13 08:12 profit 400 pips\n",
      "Maximum Profit:  407.6000000000022\n",
      "Maximum Loss:  -9.499999999999886\n",
      "Cumulative Pips is : 5942.500000000014\n",
      "*************************************************\n",
      "Buy at 2014.10.24 11:12 price 174.02200, limit order at 178.02200, stop loss at 167.98200\n",
      "Long position opened 2014.10.24 11:12 price 174.02200 closed 2014.10.31 03:22 profit 400 pips\n",
      "Maximum Profit:  400.39999999999907\n",
      "Maximum Loss:  -63.2000000000005\n",
      "Cumulative Pips is : 6342.500000000014\n",
      "************************************************\n",
      "Sell at 2014.12.15 11:22 price 184.19300, limit order at 180.19300, stop loss at 190.19300\n",
      "Short position opened 2014.12.15 11:22 price 184.19300 closed 2015.01.06 10:01 profit 400 pips\n",
      "Maximum Profit:  411.2999999999971\n",
      "Maximum Loss:  -339.10000000000196\n",
      "Cumulative Pips is : 6742.500000000014\n",
      "*************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy at 2015.02.11 03:01 price 182.80300, limit order at 186.80300, stop loss at 176.76300\n",
      "Long position opened 2015.02.11 03:01 price 182.80300 closed 2015.03.13 09:56 profit -403 pips\n",
      "Maximum Profit:  222.60000000000275\n",
      "Maximum Loss:  -408.3999999999975\n",
      "Cumulative Pips is : 6338.500000000015\n",
      "*************************************************\n",
      "Sell at 2015.03.18 07:41 price 177.51300, limit order at 173.51300, stop loss at 183.51300\n",
      "Short position opened 2015.03.18 07:41 price 177.51300 closed 2015.04.21 12:11 profit -134.50000 pips\n",
      "Maximum Profit:  263.3999999999986\n",
      "Maximum Loss:  -352.1000000000015\n",
      "Cumulative Pips is : 6204.000000000017\n",
      "*************************************************\n",
      "Buy at 2015.04.21 12:11 price 178.85800, limit order at 182.85800, stop loss at 172.81800\n",
      "Long position opened 2015.04.21 12:11 price 178.85800 closed 2015.04.29 03:16 profit 400 pips\n",
      "Maximum Profit:  415.50000000000296\n",
      "Maximum Loss:  -39.39999999999486\n",
      "Cumulative Pips is : 6604.000000000017\n",
      "************************************************\n",
      "Sell at 2015.07.03 16:56 price 189.90300, limit order at 185.90300, stop loss at 195.90300\n",
      "Short position opened 2015.07.03 16:56 price 189.90300 closed 2015.07.08 10:01 profit 400 pips\n",
      "Maximum Profit:  404.20000000000016\n",
      "Maximum Loss:  -175.49999999999955\n",
      "Cumulative Pips is : 7004.000000000017\n",
      "*************************************************\n",
      "Buy at 2015.07.13 03:16 price 191.41100, limit order at 195.41100, stop loss at 185.37100\n",
      "Long position opened 2015.07.13 03:16 price 191.41100 closed 2015.08.24 07:41 profit -303 pips\n",
      "Maximum Profit:  386.2000000000023\n",
      "Maximum Loss:  -325.5999999999972\n",
      "Cumulative Pips is : 6700.000000000018\n",
      "*************************************************\n",
      "Sell at 2015.08.24 07:41 price 188.37800, limit order at 184.37800, stop loss at 194.37800\n",
      "Short position opened 2015.08.24 07:41 price 188.37800 closed 2015.08.24 09:11 profit 400 pips\n",
      "Maximum Profit:  514.0999999999991\n",
      "Maximum Loss:  -82.60000000000218\n",
      "Cumulative Pips is : 7100.000000000018\n",
      "*************************************************\n",
      "Buy at 2016.01.28 22:21 price 171.39800, limit order at 175.39800, stop loss at 165.35800\n",
      "Long position opened 2016.01.28 22:21 price 171.39800 closed 2016.02.08 06:06 profit -303 pips\n",
      "Maximum Profit:  360.79999999999757\n",
      "Maximum Loss:  -309.099999999998\n",
      "Cumulative Pips is : 6796.000000000019\n",
      "*************************************************\n",
      "Sell at 2016.02.08 22:16 price 164.96300, limit order at 160.96300, stop loss at 170.96300\n",
      "Short position opened 2016.02.08 22:16 price 164.96300 closed 2016.02.11 03:36 profit 400 pips\n",
      "Maximum Profit:  489.0000000000015\n",
      "Maximum Loss:  -267.1999999999997\n",
      "Cumulative Pips is : 7196.000000000019\n",
      "*************************************************\n",
      "Buy at 2016.03.01 13:16 price 159.35700, limit order at 163.35700, stop loss at 153.31700\n",
      "Long position opened 2016.03.01 13:16 price 159.35700 closed 2016.03.11 10:56 profit 400 pips\n",
      "Maximum Profit:  407.4000000000012\n",
      "Maximum Loss:  -60.99999999999852\n",
      "Cumulative Pips is : 7596.000000000019\n",
      "************************************************\n",
      "Sell at 2016.04.05 02:36 price 157.44100, limit order at 153.44100, stop loss at 163.44100\n",
      "Short position opened 2016.04.05 02:36 price 157.44100 closed 2016.04.07 03:01 profit 400 pips\n",
      "Maximum Profit:  408.00000000000125\n",
      "Maximum Loss:  -10.099999999999909\n",
      "Cumulative Pips is : 7996.000000000019\n",
      "*************************************************\n",
      "Buy at 2016.04.21 08:41 price 158.39100, limit order at 162.39100, stop loss at 152.35100\n",
      "Long position opened 2016.04.21 08:41 price 158.39100 closed 2016.04.26 09:51 profit 400 pips\n",
      "Maximum Profit:  407.9000000000008\n",
      "Maximum Loss:  -187.19999999999857\n",
      "Cumulative Pips is : 8396.000000000018\n",
      "************************************************\n",
      "Sell at 2016.04.28 07:26 price 157.07700, limit order at 153.07700, stop loss at 163.07700\n",
      "Short position opened 2016.04.28 07:26 price 157.07700 closed 2016.05.17 03:26 profit -188.60000 pips\n",
      "Maximum Profit:  344.4000000000017\n",
      "Maximum Loss:  -189.40000000000055\n",
      "Cumulative Pips is : 8207.400000000018\n",
      "*************************************************\n",
      "Buy at 2016.05.17 03:26 price 158.96300, limit order at 162.96300, stop loss at 152.92300\n",
      "Long position opened 2016.05.17 03:26 price 158.96300 closed 2016.05.30 21:16 profit 400 pips\n",
      "Maximum Profit:  418.10000000000116\n",
      "Maximum Loss:  -194.70000000000027\n",
      "Cumulative Pips is : 8607.400000000018\n",
      "************************************************\n",
      "Sell at 2016.06.01 01:06 price 159.38900, limit order at 155.38900, stop loss at 165.38900\n",
      "Short position opened 2016.06.01 01:06 price 159.38900 closed 2016.06.03 10:16 profit 400 pips\n",
      "Maximum Profit:  404.00000000000205\n",
      "Maximum Loss:  -33.9999999999975\n",
      "Cumulative Pips is : 9007.400000000018\n",
      "*************************************************\n",
      "Buy at 2016.06.17 16:56 price 150.82500, limit order at 154.82500, stop loss at 144.78500\n",
      "Long position opened 2016.06.17 16:56 price 150.82500 closed 2016.06.22 17:26 profit 400 pips\n",
      "Maximum Profit:  449.2999999999995\n",
      "Maximum Loss:  85.50000000000182\n",
      "Cumulative Pips is : 9407.400000000018\n",
      "************************************************\n",
      "Sell at 2016.06.23 21:06 price 147.11700, limit order at 143.11700, stop loss at 153.11700\n",
      "Short position opened 2016.06.23 21:06 price 147.11700 closed 2016.06.23 22:41 profit 400 pips\n",
      "Maximum Profit:  1045.0000000000018\n",
      "Maximum Loss:  -582.9999999999984\n",
      "Cumulative Pips is : 9807.400000000018\n",
      "*************************************************\n",
      "Buy at 2016.07.11 21:16 price 134.36600, limit order at 138.36600, stop loss at 128.32600\n",
      "Long position opened 2016.07.11 21:16 price 134.36600 closed 2016.07.12 11:26 profit 400 pips\n",
      "Maximum Profit:  415.10000000000105\n",
      "Maximum Loss:  -26.499999999998636\n",
      "Cumulative Pips is : 10207.400000000018\n",
      "************************************************\n",
      "Sell at 2016.07.25 20:56 price 137.23200, limit order at 133.23200, stop loss at 143.23200\n",
      "Short position opened 2016.07.25 20:56 price 137.23200 closed 2016.08.04 07:31 profit 400 pips\n",
      "Maximum Profit:  435.9999999999985\n",
      "Maximum Loss:  -267.7999999999997\n",
      "Cumulative Pips is : 10607.400000000018\n",
      "*************************************************\n",
      "Buy at 2016.08.24 09:56 price 133.30100, limit order at 137.30100, stop loss at 127.26100\n",
      "Long position opened 2016.08.24 09:56 price 133.30100 closed 2016.09.01 04:41 profit 400 pips\n",
      "Maximum Profit:  401.6999999999996\n",
      "Maximum Loss:  -92.4999999999983\n",
      "Cumulative Pips is : 11007.400000000018\n",
      "************************************************\n",
      "Sell at 2016.09.13 10:01 price 134.80800, limit order at 130.80800, stop loss at 140.80800\n",
      "Short position opened 2016.09.13 10:01 price 134.80800 closed 2016.09.21 08:31 profit 400 pips\n",
      "Maximum Profit:  406.2999999999988\n",
      "Maximum Loss:  -181.30000000000166\n",
      "Cumulative Pips is : 11407.400000000018\n",
      "*************************************************\n",
      "Buy at 2016.11.10 07:06 price 132.75900, limit order at 136.75900, stop loss at 126.71900\n",
      "Long position opened 2016.11.10 07:06 price 132.75900 closed 2016.11.17 16:41 profit 400 pips\n",
      "Maximum Profit:  413.300000000001\n",
      "Maximum Loss:  -41.799999999997794\n",
      "Cumulative Pips is : 11807.400000000018\n",
      "************************************************\n",
      "Sell at 2016.12.23 03:56 price 143.78200, limit order at 139.78200, stop loss at 149.78200\n",
      "Short position opened 2016.12.23 03:56 price 143.78200 closed 2017.01.11 22:46 profit 400 pips\n",
      "Maximum Profit:  414.0000000000015\n",
      "Maximum Loss:  -161.19999999999948\n",
      "Cumulative Pips is : 12207.400000000018\n",
      "*************************************************\n",
      "Buy at 2017.01.24 17:41 price 142.61300, limit order at 146.61300, stop loss at 136.57300\n",
      "Long position opened 2017.01.24 17:41 price 142.61300 closed 2017.02.06 13:36 profit -317.40000 pips\n",
      "Maximum Profit:  216.80000000000348\n",
      "Maximum Loss:  -333.9999999999975\n",
      "Cumulative Pips is : 11890.00000000002\n",
      "*************************************************\n",
      "Sell at 2017.02.06 13:36 price 139.43900, limit order at 135.43900, stop loss at 145.43900\n",
      "Short position opened 2017.02.06 13:36 price 139.43900 closed 2017.04.25 11:21 profit -300 pips\n",
      "Maximum Profit:  374.2999999999995\n",
      "Maximum Loss:  -337.00000000000045\n",
      "Cumulative Pips is : 11590.00000000002\n",
      "*************************************************\n",
      "Buy at 2017.04.25 12:16 price 142.57000, limit order at 146.57000, stop loss at 136.53000\n",
      "Long position opened 2017.04.25 12:16 price 142.57000 closed 2017.05.05 16:56 profit 400 pips\n",
      "Maximum Profit:  402.79999999999916\n",
      "Maximum Loss:  -30.400000000000205\n",
      "Cumulative Pips is : 11990.00000000002\n",
      "************************************************\n",
      "Sell at 2017.05.26 02:46 price 143.30700, limit order at 139.30700, stop loss at 149.30700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short position opened 2017.05.26 02:46 price 143.30700 closed 2017.06.12 08:01 profit 400 pips\n",
      "Maximum Profit:  404.800000000003\n",
      "Maximum Loss:  -64.09999999999627\n",
      "Cumulative Pips is : 12390.00000000002\n",
      "*************************************************\n",
      "Buy at 2017.06.28 09:31 price 144.89800, limit order at 148.89800, stop loss at 138.85800\n",
      "Long position opened 2017.06.28 09:31 price 144.89800 closed 2017.08.08 18:31 profit -184.20000 pips\n",
      "Maximum Profit:  287.2000000000014\n",
      "Maximum Loss:  -185.59999999999945\n",
      "Cumulative Pips is : 12205.800000000021\n",
      "*************************************************\n",
      "Sell at 2017.08.08 18:31 price 143.05600, limit order at 139.05600, stop loss at 149.05600\n",
      "Short position opened 2017.08.08 18:31 price 143.05600 closed 2017.09.12 04:26 profit -221.80000 pips\n",
      "Maximum Profit:  374.20000000000186\n",
      "Maximum Loss:  -224.60000000000093\n",
      "Cumulative Pips is : 11984.000000000022\n",
      "*************************************************\n",
      "Buy at 2017.09.12 04:26 price 145.27400, limit order at 149.27400, stop loss at 139.23400\n",
      "Long position opened 2017.09.12 04:26 price 145.27400 closed 2017.09.15 04:46 profit 400 pips\n",
      "Maximum Profit:  414.7999999999996\n",
      "Maximum Loss:  -11.699999999999022\n",
      "Cumulative Pips is : 12384.000000000022\n",
      "************************************************\n",
      "Sell at 2017.10.05 08:21 price 148.03500, limit order at 144.03500, stop loss at 154.03500\n",
      "Short position opened 2017.10.05 08:21 price 148.03500 closed 2017.11.30 16:31 profit -439.50000 pips\n",
      "Maximum Profit:  106.3999999999993\n",
      "Maximum Loss:  -437.29999999999905\n",
      "Cumulative Pips is : 11944.500000000024\n",
      "*************************************************\n",
      "Buy at 2017.11.30 16:31 price 152.43000, limit order at 156.43000, stop loss at 146.39000\n",
      "Long position opened 2017.11.30 16:31 price 152.43000 closed 2018.02.01 04:22 profit 400 pips\n",
      "Maximum Profit:  400.90000000000146\n",
      "Maximum Loss:  -301.8999999999977\n",
      "Cumulative Pips is : 12344.500000000024\n",
      "************************************************\n",
      "Sell at 2018.02.08 12:52 price 150.97100, limit order at 146.97100, stop loss at 156.97100\n",
      "Short position opened 2018.02.08 12:52 price 150.97100 closed 2018.02.28 14:52 profit 400 pips\n",
      "Maximum Profit:  405.5000000000007\n",
      "Maximum Loss:  -178.19999999999823\n",
      "Cumulative Pips is : 12744.500000000024\n",
      "*************************************************\n",
      "Buy at 2018.03.19 08:12 price 149.58300, limit order at 153.58300, stop loss at 143.54300\n",
      "Long position opened 2018.03.19 08:12 price 149.58300 closed 2018.04.13 03:37 profit 400 pips\n",
      "Maximum Profit:  403.8000000000011\n",
      "Maximum Loss:  -191.2000000000006\n",
      "Cumulative Pips is : 13144.500000000024\n",
      "************************************************\n",
      "Sell at 2018.05.01 10:57 price 149.16400, limit order at 145.16400, stop loss at 155.16400\n",
      "Short position opened 2018.05.01 10:57 price 149.16400 closed 2018.05.28 21:07 profit 400 pips\n",
      "Maximum Profit:  414.19999999999675\n",
      "Maximum Loss:  -95.50000000000125\n",
      "Cumulative Pips is : 13544.500000000024\n",
      "*************************************************\n",
      "Buy at 2018.06.06 02:32 price 147.69200, limit order at 151.69200, stop loss at 141.65200\n",
      "Long position opened 2018.06.06 02:32 price 147.69200 closed 2018.08.08 20:12 profit -503 pips\n",
      "Maximum Profit:  161.5000000000009\n",
      "Maximum Loss:  -506.9000000000017\n",
      "Cumulative Pips is : 13040.500000000024\n",
      "*************************************************\n",
      "Sell at 2018.08.10 02:17 price 141.72500, limit order at 137.72500, stop loss at 147.72500\n",
      "Short position opened 2018.08.10 02:17 price 141.72500 closed 2018.08.29 09:57 profit -254.60000 pips\n",
      "Maximum Profit:  183.29999999999984\n",
      "Maximum Loss:  -305.00000000000114\n",
      "Cumulative Pips is : 12785.900000000025\n",
      "*************************************************\n",
      "Buy at 2018.08.29 09:57 price 144.27100, limit order at 148.27100, stop loss at 138.23100\n",
      "Long position opened 2018.08.29 09:57 price 144.27100 closed 2018.09.19 04:27 profit 400 pips\n",
      "Maximum Profit:  425.7000000000005\n",
      "Maximum Loss:  -168.29999999999927\n",
      "Cumulative Pips is : 13185.900000000025\n",
      "************************************************\n",
      "Sell at 2018.10.24 13:07 price 144.80500, limit order at 140.80500, stop loss at 150.80500\n",
      "Short position opened 2018.10.24 13:07 price 144.80500 closed 2018.11.05 17:37 profit -307.20000 pips\n",
      "Maximum Profit:  203.49999999999966\n",
      "Maximum Loss:  -305.5000000000007\n",
      "Cumulative Pips is : 12878.700000000024\n",
      "*************************************************\n",
      "Buy at 2018.11.05 17:37 price 147.87700, limit order at 151.87700, stop loss at 141.83700\n",
      "Long position opened 2018.11.05 17:37 price 147.87700 closed 2018.11.15 04:37 profit -278.50000 pips\n",
      "Maximum Profit:  160.3999999999985\n",
      "Maximum Loss:  -286.80000000000234\n",
      "Cumulative Pips is : 12600.200000000024\n",
      "*************************************************\n",
      "Sell at 2018.11.15 04:37 price 145.09200, limit order at 141.09200, stop loss at 151.09200\n",
      "Short position opened 2018.11.15 04:37 price 145.09200 closed 2018.12.20 10:27 profit 400 pips\n",
      "Maximum Profit:  408.5000000000008\n",
      "Maximum Loss:  -85.09999999999707\n",
      "Cumulative Pips is : 13000.200000000024\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "#stochastic = slow_stochastic(data, 15, 5)\n",
    "stochastic = sstoc(data)\n",
    "\n",
    "limit = 400\n",
    "stop = 600\n",
    "\n",
    "#limit = 30\n",
    "#stop = 80\n",
    "trailing_stop = 100\n",
    "\n",
    "first_min = 1000\n",
    "first_max = 0\n",
    "second_min = 1000\n",
    "second_max = 0\n",
    "\n",
    "distance = 100\n",
    "p = position()\n",
    "N = len(High)\n",
    "cumpips = 0\n",
    "state = -3\n",
    "uptrend = False\n",
    "max_value = 0\n",
    "min_value = 1000\n",
    "#trendprice = Close[0]\n",
    "#trendprice = 1.34517\n",
    "#triggerprice = Close[0]\n",
    "#triggerprice = 1.36082\n",
    "\n",
    "for i in range(N):\n",
    "    #print(\"%s: state: %d, trend: %.5f, trigger: %.5f, shooting: %.5f, min:%.5f, max:%.5f, high:%.5f, low: %.5f, uptrend: %r \"%(Time[i], state, trendprice, triggerprice, shootingprice, min_value, max_value, High[i], Low[i], uptrend))\n",
    "    if p.have_position:\n",
    "        cumpips, state = p.close_position(cumpips, Time[i], Low[i], High[i], state)\n",
    "                \n",
    "            \n",
    "            #if state == 3:\n",
    "            #        state = 0\n",
    "             #   elif state == 13:\n",
    "              #      state = 10\n",
    "                    \n",
    "                \n",
    "        #elif p.position_type == \"Long\":\n",
    "         #   if distant(High[i], p.open_price, (cap+2)*10):\n",
    "          #      cumpips = p.close_position(cumpips, Time[i], cap)\n",
    "           #     if state == 3:\n",
    "            #        state = 0\n",
    "             #   elif state == 13:\n",
    "              #      state = 10\n",
    "        \n",
    "        \n",
    "    if state == -3:\n",
    "            if first_max < High[i]: first_max = High[i]\n",
    "            if first_min > Low[i]: first_min = Low[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                state = -21\n",
    "                first_min = first_max\n",
    "            elif SC==1:\n",
    "                state = -20\n",
    "                first_max = first_min\n",
    "    \n",
    "    elif state == -20:\n",
    "            if first_max < High[i]: first_max = High[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                state = -22\n",
    "                first_min = first_max\n",
    "                \n",
    "    elif state == -22:\n",
    "            if first_min > Low[i]: first_min = Low[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==1: \n",
    "                state = -24\n",
    "                second_max = first_min\n",
    "                \n",
    "    elif state == -24:\n",
    "            if second_max < High[i]: second_max = High[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                if second_max <= first_max:\n",
    "                    uptrend = False\n",
    "                    triggerprice = first_max\n",
    "                    trendprice = first_min\n",
    "                    state = 0\n",
    "                else:\n",
    "                    uptrend = True\n",
    "                    triggerprice = first_min\n",
    "                    trendprice = second_max\n",
    "                    state = 0\n",
    "\n",
    "    elif state == -21:\n",
    "            if first_min > Low[i]: first_min = Low[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==1: \n",
    "                state = -23\n",
    "                first_max = first_min\n",
    "                \n",
    "    elif state == -23:\n",
    "            if first_max < High[i]: first_max = High[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                state = -25\n",
    "                second_min = first_max\n",
    "                \n",
    "    elif state == -25:\n",
    "            if second_min > Low[i]: second_min = Low[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                if second_min <= first_min:\n",
    "                    uptrend = False\n",
    "                    triggerprice = first_max\n",
    "                    trendprice = second_min\n",
    "                    state = 0\n",
    "                else:\n",
    "                    uptrend = True\n",
    "                    triggerprice = first_min\n",
    "                    trendprice = first_max\n",
    "                    state = 0        \n",
    "\n",
    "    elif state == 0:\n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            if distant(max_value,trendprice, distance):\n",
    "                triggerprice = min_value\n",
    "                #min_value = High[i]\n",
    "                state = 10\n",
    "              \n",
    "            if distant(triggerprice,min_value, distance):  \n",
    "                state = 1\n",
    "                max_value = min_value\n",
    "        else: \n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            if distant(trendprice, min_value, distance):\n",
    "                triggerprice = max_value\n",
    "                #max_value = Low[i]\n",
    "                state = 10\n",
    "            \n",
    "            if distant(max_value,triggerprice, distance):\n",
    "                state = 1\n",
    "                min_value = max_value\n",
    "    \n",
    "    elif state == 10:  \n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "\n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2:\n",
    "                trendprice = max_value \n",
    "               # triggerprice = min_value\n",
    "                min_value = High[i]\n",
    "                state = 0\n",
    "            \n",
    "            if distant(triggerprice,min_value, distance):\n",
    "                trendprice = max_value\n",
    "                state = 1\n",
    "        else:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC == 1:\n",
    "                trendprice = min_value\n",
    "              #  triggerprice = max_value\n",
    "                max_value = Low[i]\n",
    "                state = 0\n",
    "                \n",
    "            if distant(max_value,triggerprice, distance):\n",
    "                trendprice = min_value\n",
    "                state = 1\n",
    "\n",
    "    elif state == 1:\n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            if distant(max_value,trendprice, distance):\n",
    "                if p.have_position:\n",
    "                    state = 3\n",
    "                    continue                \n",
    "                else:\n",
    "                    state = 0\n",
    "                    continue\n",
    "            \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==1: \n",
    "                shootingprice = min_value\n",
    "                max_value = min_value\n",
    "                state = 2\n",
    "        else:\n",
    "            \n",
    "            if max_value < High[i]: max_value=High[i]\n",
    "            if min_value > Low[i]: min_value=Low[i]\n",
    "            \n",
    "            if distant(trendprice,min_value, distance):\n",
    "                if p.have_position:\n",
    "                    state = 3\n",
    "                    continue \n",
    "                else:\n",
    "                    state = 0\n",
    "                    continue\n",
    "            \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2:\n",
    "                shootingprice = max_value\n",
    "                min_value = max_value\n",
    "                state = 2 \n",
    "    \n",
    "    elif state == 2:\n",
    "        \n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value=High[i]\n",
    "            if min_value > Low[i]: min_value=Low[i]\n",
    "            \n",
    "            if distant(max_value,trendprice, distance):\n",
    "                if p.have_position:\n",
    "                    triggerprice = min_value\n",
    "                    state = 13\n",
    "                    min_value = High[i]\n",
    "                    continue\n",
    "                else:\n",
    "                    triggerprice = shootingprice\n",
    "                    state = 10\n",
    "                    min_value = High[i]\n",
    "                    continue\n",
    "            \n",
    "            if distant(shootingprice,min_value, distance):\n",
    "                limit_price = shootingprice - (distance + limit) * PIP_RATIO\n",
    "               # stop_price = max_value + distance * 0.00001\n",
    "                stop_price = shootingprice  - (distance - stop) * PIP_RATIO\n",
    "                uptrend, cumpips = p.take_position(\"Sell\",uptrend,cumpips,shootingprice - distance * PIP_RATIO, abs(shootingprice - trendprice)*100, abs(triggerprice - trendprice)*100, Time[i], limit_price, stop_price, trailing_stop, i)\n",
    "                state = 3\n",
    "                trendprice = shootingprice\n",
    "                triggerprice = max_value\n",
    "                continue\n",
    "        else:\n",
    "            if max_value<High[i]: max_value=High[i]\n",
    "            if min_value>Low[i]: min_value=Low[i];\n",
    "            \n",
    "            if distant(trendprice, min_value, distance):\n",
    "                if p.have_position:\n",
    "                    triggerprice = max_value\n",
    "                    state = 13\n",
    "                    max_value = Low[i]\n",
    "                    continue                 \n",
    "                else:\n",
    "                    triggerprice = shootingprice\n",
    "                    state = 10\n",
    "                    max_value = Low[i]\n",
    "                    continue\n",
    "            \n",
    "            if distant(max_value,shootingprice, distance):\n",
    "                limit_price = shootingprice + (distance + MARGIN + limit) * PIP_RATIO\n",
    "                #stop_price = min_value - distance * 0.00001\n",
    "                stop_price = shootingprice + (distance  - stop) * PIP_RATIO\n",
    "                uptrend, cumpips = p.take_position(\"Buy\",uptrend,cumpips,shootingprice + (distance + MARGIN) * PIP_RATIO, abs(shootingprice - trendprice)*100, abs(triggerprice - trendprice)*100, Time[i], limit_price, stop_price, trailing_stop, i)\n",
    "                state = 3\n",
    "                trendprice = shootingprice\n",
    "                triggerprice = min_value\n",
    "                continue\n",
    "    \n",
    "    elif state == 3:\n",
    "        if uptrend:\n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "                    \n",
    "            if distant(max_value,trendprice, distance):\n",
    "                triggerprice = min_value\n",
    "                #min_value = High[i]\n",
    "                state = 13\n",
    "              \n",
    "            if distant(triggerprice,min_value, distance):  \n",
    "                state = 1 \n",
    "        else: \n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            if distant(trendprice, min_value, distance):\n",
    "                triggerprice = max_value\n",
    "                #max_value = Low[i]\n",
    "                state = 13\n",
    "            \n",
    "            if distant(max_value,triggerprice, distance):\n",
    "                state = 1\n",
    "                continue\n",
    "    \n",
    "    elif state == 13:  \n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "\n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2:\n",
    "                trendprice = max_value \n",
    "               # triggerprice = min_value\n",
    "                min_value = High[i]\n",
    "                state = 3\n",
    "            \n",
    "            if distant(triggerprice,min_value, distance):\n",
    "                trendprice = max_value\n",
    "                state = 1\n",
    "                continue\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC == 1:\n",
    "                trendprice = min_value\n",
    "              #  triggerprice = max_value\n",
    "                max_value = Low[i]\n",
    "                state = 3\n",
    "                \n",
    "            if distant(max_value,triggerprice, distance):\n",
    "                trendprice = min_value\n",
    "                state = 1 \n",
    "                continue\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "pl = np.array(p.profitloss)\n",
    "n = len(pl)\n",
    "y = np.zeros(n)\n",
    "y[pl<0] = 0\n",
    "y[pl>0] = 1\n",
    "for i in p.index:\n",
    "    price = data.iloc[i-20:i,4]\n",
    "    r = (price[1:]/price[:-1].values -1).values\n",
    "    r = r*10000\n",
    "    X.append(list(r))\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 19)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape = n_steps * 2),\n",
    "    layers.Dense(16, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(8, activation=tf.nn.relu),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape = 19),\n",
    "    layers.Dense(8, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation=tf.nn.relu),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(16, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation=tf.nn.relu),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 19)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 1.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "18/18 [==============================] - 0s 3ms/sample - loss: 0.4782 - RootMeanSquaredError: 0.5111\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['RootMeanSquaredError'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, verbose=False) \n",
    "\n",
    "_, rmse = model.evaluate(x_test, y_test)\n",
    "\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS1 = hp.HParam('num_units 1', hp.Discrete([4,8,16])) \n",
    "HP_NUM_UNITS2 = hp.HParam('num_units 2', hp.Discrete([4,8]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd','RMSprop']))\n",
    "HP_L2 = hp.HParam('l2 regularizer', hp.RealInterval(.001,.01))\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS1,HP_NUM_UNITS2, HP_DROPOUT,HP_L2 ,HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape = 19),\n",
    "        layers.Dense(hparams[HP_NUM_UNITS1], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "        layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        layers.Dense(hparams[HP_NUM_UNITS2], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "        layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=100) \n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 6ms/sample - loss: 0.7517 - accuracy: 0.5070\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6668 - accuracy: 0.5352\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6879 - accuracy: 0.5352\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.6613 - accuracy: 0.6338\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6996 - accuracy: 0.5634\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6622 - accuracy: 0.6479\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.6549 - accuracy: 0.6479\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6792 - accuracy: 0.6620\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6479 - accuracy: 0.6338\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6860 - accuracy: 0.5352\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6316 - accuracy: 0.5352\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6371 - accuracy: 0.5352\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.6329 - accuracy: 0.5352\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6376 - accuracy: 0.5211\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.6881 - accuracy: 0.4789\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6432 - accuracy: 0.4930\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6375 - accuracy: 0.5634\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5987 - accuracy: 0.5352\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6428 - accuracy: 0.5493\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.6155 - accuracy: 0.6479\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6122 - accuracy: 0.6479\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6238 - accuracy: 0.6479\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6308 - accuracy: 0.6620\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6068 - accuracy: 0.6479\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6211 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6096 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6291 - accuracy: 0.6479\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6368 - accuracy: 0.4648\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5938 - accuracy: 0.5352\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5875 - accuracy: 0.5634\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.5969 - accuracy: 0.5493\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5827 - accuracy: 0.5352\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6226 - accuracy: 0.4930\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.6274 - accuracy: 0.5211\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6080 - accuracy: 0.5493\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6293 - accuracy: 0.5211\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5836 - accuracy: 0.5634\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6180 - accuracy: 0.5493\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5819 - accuracy: 0.5493\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5825 - accuracy: 0.5211\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6126 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5630 - accuracy: 0.5775\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5366 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.5769 - accuracy: 0.6761\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6099 - accuracy: 0.5775\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5693 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6099 - accuracy: 0.6620\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5590 - accuracy: 0.6761\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 107us/sample - loss: 0.5815 - accuracy: 0.6761\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.5374 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5666 - accuracy: 0.6620\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.5843 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5858 - accuracy: 0.6620\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 96us/sample - loss: 0.5720 - accuracy: 0.6761\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 100us/sample - loss: 0.6205 - accuracy: 0.6761\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 103us/sample - loss: 0.5844 - accuracy: 0.6620\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.5635 - accuracy: 0.6197\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.5559 - accuracy: 0.6761\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5645 - accuracy: 0.6056\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.5749 - accuracy: 0.5775\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 98us/sample - loss: 0.5805 - accuracy: 0.6761\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5696 - accuracy: 0.6056\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.5648 - accuracy: 0.5634\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.5461 - accuracy: 0.6197\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 101us/sample - loss: 0.5350 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 100us/sample - loss: 0.5804 - accuracy: 0.6056\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 98us/sample - loss: 0.5665 - accuracy: 0.6056\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5463 - accuracy: 0.6197\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5483 - accuracy: 0.6056\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5483 - accuracy: 0.5634\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.5545 - accuracy: 0.5915\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5442 - accuracy: 0.6197\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5637 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5580 - accuracy: 0.6056\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.5345 - accuracy: 0.6761\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.5266 - accuracy: 0.6338\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5309 - accuracy: 0.5915\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5174 - accuracy: 0.6338\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5890 - accuracy: 0.5775\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5200 - accuracy: 0.6479\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5274 - accuracy: 0.6197\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.5118 - accuracy: 0.6479\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5648 - accuracy: 0.5915\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.5300 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5300 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 102us/sample - loss: 0.5716 - accuracy: 0.6479\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5213 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5366 - accuracy: 0.6338\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5160 - accuracy: 0.6056\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5507 - accuracy: 0.6197\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5400 - accuracy: 0.6338\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5709 - accuracy: 0.5634\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5104 - accuracy: 0.6197\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5031 - accuracy: 0.6479\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4969 - accuracy: 0.7183\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5258 - accuracy: 0.5915\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5033 - accuracy: 0.6338\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5325 - accuracy: 0.6479\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5049 - accuracy: 0.6338\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5165 - accuracy: 0.6056\n",
      "18/18 [==============================] - 0s 5ms/sample - loss: 0.9899 - accuracy: 0.4444\n",
      "--- Starting trial: run-1\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 3.0230 - accuracy: 0.3803\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 3.1445 - accuracy: 0.3099\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 2.9258 - accuracy: 0.3662\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.8974 - accuracy: 0.3662\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 2.7668 - accuracy: 0.3521\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 2.6614 - accuracy: 0.3803\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.7225 - accuracy: 0.3662\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 2.7449 - accuracy: 0.3380\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 2.4031 - accuracy: 0.3239\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 2.6701 - accuracy: 0.3380\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 2.3992 - accuracy: 0.3662\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 2.4312 - accuracy: 0.2958\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 2.2113 - accuracy: 0.3239\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 2.3034 - accuracy: 0.3662\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 2.4580 - accuracy: 0.3239\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 2.1281 - accuracy: 0.3521\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 2.2858 - accuracy: 0.3521\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.9990 - accuracy: 0.3803\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.9944 - accuracy: 0.3803\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.9736 - accuracy: 0.3380\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 2.2727 - accuracy: 0.3662\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 2.3526 - accuracy: 0.3099\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 2.0590 - accuracy: 0.3380\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.8700 - accuracy: 0.4085\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.9350 - accuracy: 0.3803\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.8088 - accuracy: 0.4085\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 103us/sample - loss: 1.8052 - accuracy: 0.3944\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.8646 - accuracy: 0.3803\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 1.8374 - accuracy: 0.3944\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.8081 - accuracy: 0.3944\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.8007 - accuracy: 0.3944\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.4868 - accuracy: 0.4225\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.6195 - accuracy: 0.3662\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.7212 - accuracy: 0.3803\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.5986 - accuracy: 0.4085\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.5726 - accuracy: 0.4085\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.5796 - accuracy: 0.4225\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.5765 - accuracy: 0.3803\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 100us/sample - loss: 1.4576 - accuracy: 0.4366\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.4895 - accuracy: 0.3944\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.5201 - accuracy: 0.3662\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.4004 - accuracy: 0.4366\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.6137 - accuracy: 0.4085\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.4000 - accuracy: 0.4225\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.3620 - accuracy: 0.4085\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.2904 - accuracy: 0.4225\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.4823 - accuracy: 0.4225\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3552 - accuracy: 0.4507\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3353 - accuracy: 0.3944\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.2644 - accuracy: 0.4085\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.4632 - accuracy: 0.4225\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2050 - accuracy: 0.4648\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.2855 - accuracy: 0.4085\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.4355 - accuracy: 0.4085\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2420 - accuracy: 0.4507\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 75us/sample - loss: 1.2189 - accuracy: 0.4930\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.0967 - accuracy: 0.5211\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2584 - accuracy: 0.4789\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.1533 - accuracy: 0.4789\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.2867 - accuracy: 0.4648\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 1.1474 - accuracy: 0.4648\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0826 - accuracy: 0.5493\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1033 - accuracy: 0.4648\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.1345 - accuracy: 0.4648\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1066 - accuracy: 0.4648\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1343 - accuracy: 0.4930\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 1.0421 - accuracy: 0.4648\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1411 - accuracy: 0.5070\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2954 - accuracy: 0.4648\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 1.0154 - accuracy: 0.4930\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9508 - accuracy: 0.5352\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.2403 - accuracy: 0.4648\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0592 - accuracy: 0.4930\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 1.0438 - accuracy: 0.4930\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.9876 - accuracy: 0.5352\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.0059 - accuracy: 0.4930\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0146 - accuracy: 0.5493\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.0153 - accuracy: 0.5493\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.0429 - accuracy: 0.5352\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 110us/sample - loss: 0.9652 - accuracy: 0.5634\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.9337 - accuracy: 0.5070\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 1.0047 - accuracy: 0.5493\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 98us/sample - loss: 1.0768 - accuracy: 0.5070\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 1.0367 - accuracy: 0.5070\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.9928 - accuracy: 0.5493\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.0589 - accuracy: 0.5493\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 0.9337 - accuracy: 0.5352\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 113us/sample - loss: 0.9349 - accuracy: 0.5211\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 102us/sample - loss: 0.9462 - accuracy: 0.5352\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 111us/sample - loss: 0.9646 - accuracy: 0.5211\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 126us/sample - loss: 0.9364 - accuracy: 0.5634\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.0011 - accuracy: 0.5211\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.9375 - accuracy: 0.5493\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 99us/sample - loss: 1.0582 - accuracy: 0.4507\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 100us/sample - loss: 0.9805 - accuracy: 0.5352\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.9875 - accuracy: 0.4930\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8590 - accuracy: 0.5775\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.8367 - accuracy: 0.5634\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.8786 - accuracy: 0.5634\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.9058 - accuracy: 0.5211\n",
      "18/18 [==============================] - 0s 5ms/sample - loss: 1.8237 - accuracy: 0.5000\n",
      "--- Starting trial: run-2\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 0.7879 - accuracy: 0.4507\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7673 - accuracy: 0.5211\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7130 - accuracy: 0.5775\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7215 - accuracy: 0.5634\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6890 - accuracy: 0.6056\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 116us/sample - loss: 0.6641 - accuracy: 0.6197\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6997 - accuracy: 0.6056\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6815 - accuracy: 0.5775\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6740 - accuracy: 0.5493\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 104us/sample - loss: 0.6679 - accuracy: 0.6338\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6718 - accuracy: 0.6197\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6393 - accuracy: 0.6056\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6402 - accuracy: 0.6479\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6435 - accuracy: 0.6620\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6694 - accuracy: 0.6197\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6404 - accuracy: 0.6197\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6513 - accuracy: 0.6338\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6537 - accuracy: 0.5915\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6324 - accuracy: 0.6338\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6387 - accuracy: 0.6479\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6537 - accuracy: 0.5775\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 97us/sample - loss: 0.6426 - accuracy: 0.6620\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 100us/sample - loss: 0.6530 - accuracy: 0.6197\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.6497 - accuracy: 0.6197\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6454 - accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.6486 - accuracy: 0.6338\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6233 - accuracy: 0.6479\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6379 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.6053 - accuracy: 0.6479\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6296 - accuracy: 0.6479\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6197 - accuracy: 0.6479\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 94us/sample - loss: 0.6182 - accuracy: 0.6479\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6196 - accuracy: 0.6479\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 103us/sample - loss: 0.6205 - accuracy: 0.6479\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.6045 - accuracy: 0.6620\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 102us/sample - loss: 0.6238 - accuracy: 0.6479\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6208 - accuracy: 0.6620\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.6035 - accuracy: 0.6620\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6021 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6205 - accuracy: 0.6620\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.6162 - accuracy: 0.6620\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6107 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6221 - accuracy: 0.6620\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6015 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6216 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6102 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6186 - accuracy: 0.6620\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6015 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5953 - accuracy: 0.6620\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6040 - accuracy: 0.6620\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6060 - accuracy: 0.6620\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5879 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6050 - accuracy: 0.6620\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6085 - accuracy: 0.6620\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.6140 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5908 - accuracy: 0.6620\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5977 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5858 - accuracy: 0.6620\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5885 - accuracy: 0.6620\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6007 - accuracy: 0.6620\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6043 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5746 - accuracy: 0.6620\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5915 - accuracy: 0.6620\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5941 - accuracy: 0.6620\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5920 - accuracy: 0.6620\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5889 - accuracy: 0.6620\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6082 - accuracy: 0.6620\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5819 - accuracy: 0.6620\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5987 - accuracy: 0.6620\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5703 - accuracy: 0.6620\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5945 - accuracy: 0.6620\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5790 - accuracy: 0.6620\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5833 - accuracy: 0.6620\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5767 - accuracy: 0.6620\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5856 - accuracy: 0.6620\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5918 - accuracy: 0.6620\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6096 - accuracy: 0.6620\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.5919 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5671 - accuracy: 0.6620\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5836 - accuracy: 0.6620\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6141 - accuracy: 0.6620\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6075 - accuracy: 0.6620\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5672 - accuracy: 0.6620\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5789 - accuracy: 0.6620\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5781 - accuracy: 0.6620\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5707 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5764 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5881 - accuracy: 0.6620\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5908 - accuracy: 0.6620\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5649 - accuracy: 0.6620\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5755 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5965 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5884 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5831 - accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5725 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5659 - accuracy: 0.6620\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5908 - accuracy: 0.6620\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5681 - accuracy: 0.6620\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5817 - accuracy: 0.6620\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5910 - accuracy: 0.6620\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.1409 - accuracy: 0.6111\n",
      "--- Starting trial: run-3\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.6709 - accuracy: 0.5493\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.5708 - accuracy: 0.5352\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.5966 - accuracy: 0.5775\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.5594 - accuracy: 0.5775\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 94us/sample - loss: 1.4750 - accuracy: 0.5775\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.3506 - accuracy: 0.5775\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.4618 - accuracy: 0.5775\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.3911 - accuracy: 0.6197\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.4432 - accuracy: 0.5352\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 82us/sample - loss: 1.0675 - accuracy: 0.5915\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.1131 - accuracy: 0.5915\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.2526 - accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 1.2165 - accuracy: 0.6479\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.3282 - accuracy: 0.5915\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1833 - accuracy: 0.5775\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 1.2133 - accuracy: 0.5915\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2089 - accuracy: 0.5634\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.1930 - accuracy: 0.5634\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.2372 - accuracy: 0.5211\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0949 - accuracy: 0.5915\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 1.2081 - accuracy: 0.4930\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.2427 - accuracy: 0.5775\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 1.0920 - accuracy: 0.6056\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 1.0788 - accuracy: 0.6197\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9298 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8875 - accuracy: 0.6479\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.0865 - accuracy: 0.5493\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9711 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.0902 - accuracy: 0.5915\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.8835 - accuracy: 0.6338\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9004 - accuracy: 0.6338\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 96us/sample - loss: 0.9427 - accuracy: 0.6056\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9871 - accuracy: 0.6620\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9594 - accuracy: 0.6338\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 1.0125 - accuracy: 0.6056\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9558 - accuracy: 0.5915\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 96us/sample - loss: 1.0047 - accuracy: 0.5915\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.8771 - accuracy: 0.5775\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8267 - accuracy: 0.6338\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.9480 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9267 - accuracy: 0.6056\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.9125 - accuracy: 0.6056\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.8739 - accuracy: 0.6197\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8710 - accuracy: 0.6056\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 103us/sample - loss: 0.8483 - accuracy: 0.6338\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8643 - accuracy: 0.6197\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.8676 - accuracy: 0.6056\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8509 - accuracy: 0.6056\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8966 - accuracy: 0.5775\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.8007 - accuracy: 0.6479\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8199 - accuracy: 0.6338\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7143 - accuracy: 0.6197\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.9233 - accuracy: 0.6197\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.7512 - accuracy: 0.6338\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 97us/sample - loss: 0.6381 - accuracy: 0.6761\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7370 - accuracy: 0.6620\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8209 - accuracy: 0.5634\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8014 - accuracy: 0.6197\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7649 - accuracy: 0.5915\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 94us/sample - loss: 0.7236 - accuracy: 0.6338\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7066 - accuracy: 0.6761\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7585 - accuracy: 0.6197\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7025 - accuracy: 0.6479\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6699 - accuracy: 0.6620\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7840 - accuracy: 0.6338\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.7029 - accuracy: 0.5493\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6711 - accuracy: 0.6620\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7375 - accuracy: 0.6197\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6441 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.7091 - accuracy: 0.6056\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.7611 - accuracy: 0.5775\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.6794 - accuracy: 0.5915\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.7139 - accuracy: 0.6197\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7287 - accuracy: 0.6056\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.7632 - accuracy: 0.6197\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 99us/sample - loss: 0.6606 - accuracy: 0.6620\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6941 - accuracy: 0.6197\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6253 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6306 - accuracy: 0.6338\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6431 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.6493 - accuracy: 0.6338\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6885 - accuracy: 0.6338\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 110us/sample - loss: 0.7580 - accuracy: 0.6197\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 104us/sample - loss: 0.6451 - accuracy: 0.6338\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5952 - accuracy: 0.6479\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6129 - accuracy: 0.6901\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5711 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6384 - accuracy: 0.6338\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6553 - accuracy: 0.6901\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6118 - accuracy: 0.6901\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5834 - accuracy: 0.6901\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6211 - accuracy: 0.6479\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.6508 - accuracy: 0.6479\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.6513 - accuracy: 0.6338\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5785 - accuracy: 0.6761\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 101us/sample - loss: 0.6189 - accuracy: 0.6197\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5904 - accuracy: 0.6620\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5833 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6568 - accuracy: 0.6761\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5805 - accuracy: 0.6901\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.4016 - accuracy: 0.6667\n",
      "--- Starting trial: run-4\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.7703 - accuracy: 0.3380\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 2.7317 - accuracy: 0.3099\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.6699 - accuracy: 0.3803\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.2932 - accuracy: 0.2958\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 2.5224 - accuracy: 0.3380\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.2089 - accuracy: 0.3521\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.4288 - accuracy: 0.3099\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 2.6426 - accuracy: 0.2958\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.4266 - accuracy: 0.3239\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 2.3321 - accuracy: 0.3662\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.2270 - accuracy: 0.3099\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.1113 - accuracy: 0.3099\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 2.0653 - accuracy: 0.3803\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 2.1203 - accuracy: 0.3099\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.1107 - accuracy: 0.3521\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 2.0239 - accuracy: 0.3521\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.0061 - accuracy: 0.3099\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.8570 - accuracy: 0.3662\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.8169 - accuracy: 0.3662\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.8500 - accuracy: 0.3662\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.8649 - accuracy: 0.2817\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.8037 - accuracy: 0.3521\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.8186 - accuracy: 0.3239\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.7231 - accuracy: 0.3099\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.6430 - accuracy: 0.4085\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.6933 - accuracy: 0.3380\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.5721 - accuracy: 0.3662\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.5811 - accuracy: 0.3521\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.5756 - accuracy: 0.4085\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 1.5991 - accuracy: 0.3380\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.4348 - accuracy: 0.3521\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.4254 - accuracy: 0.3803\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.5100 - accuracy: 0.3662\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.2651 - accuracy: 0.3662\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.5533 - accuracy: 0.3380\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.3969 - accuracy: 0.3239\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 1.2649 - accuracy: 0.4366\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.2511 - accuracy: 0.3803\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.2556 - accuracy: 0.3803\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3427 - accuracy: 0.3662\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.3595 - accuracy: 0.3944\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.2058 - accuracy: 0.3803\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2960 - accuracy: 0.4085\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.3546 - accuracy: 0.4085\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 1.1930 - accuracy: 0.4789\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1690 - accuracy: 0.4225\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.2204 - accuracy: 0.3944\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1485 - accuracy: 0.4648\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1696 - accuracy: 0.4225\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 1.1725 - accuracy: 0.4366\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 1.1604 - accuracy: 0.4225\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.1482 - accuracy: 0.4085\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.0958 - accuracy: 0.5211\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1349 - accuracy: 0.3944\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.1080 - accuracy: 0.3662\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.1636 - accuracy: 0.3803\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0711 - accuracy: 0.4789\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.1480 - accuracy: 0.3944\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0560 - accuracy: 0.4507\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0271 - accuracy: 0.4085\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.9522 - accuracy: 0.4789\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.0863 - accuracy: 0.4366\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.0799 - accuracy: 0.4366\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9892 - accuracy: 0.4648\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0811 - accuracy: 0.4789\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9585 - accuracy: 0.4789\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.0072 - accuracy: 0.4507\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9518 - accuracy: 0.4930\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9353 - accuracy: 0.4789\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8509 - accuracy: 0.5070\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.9256 - accuracy: 0.5211\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.9102 - accuracy: 0.5211\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9474 - accuracy: 0.4789\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.8744 - accuracy: 0.5634\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.8592 - accuracy: 0.5915\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.8417 - accuracy: 0.5634\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8372 - accuracy: 0.5352\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.8722 - accuracy: 0.5493\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8981 - accuracy: 0.4930\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8479 - accuracy: 0.5352\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8335 - accuracy: 0.5352\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8126 - accuracy: 0.5775\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.8781 - accuracy: 0.5352\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.8511 - accuracy: 0.5493\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.8589 - accuracy: 0.5211\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8887 - accuracy: 0.5493\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8597 - accuracy: 0.5352\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.8053 - accuracy: 0.5775\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8009 - accuracy: 0.5070\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7951 - accuracy: 0.5352\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8033 - accuracy: 0.5775\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8377 - accuracy: 0.4930\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8182 - accuracy: 0.5211\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7967 - accuracy: 0.5070\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7920 - accuracy: 0.5493\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8280 - accuracy: 0.5070\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7987 - accuracy: 0.5211\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7567 - accuracy: 0.5634\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.8015 - accuracy: 0.5211\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7840 - accuracy: 0.5352\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8279 - accuracy: 0.4444\n",
      "--- Starting trial: run-5\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 0.8484 - accuracy: 0.4085\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8486 - accuracy: 0.4789\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7471 - accuracy: 0.5634\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7328 - accuracy: 0.5915\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7395 - accuracy: 0.5634\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7226 - accuracy: 0.5634\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6776 - accuracy: 0.6620\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.7244 - accuracy: 0.5493\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7259 - accuracy: 0.5775\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7041 - accuracy: 0.6056\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7146 - accuracy: 0.5775\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7054 - accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7162 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7399 - accuracy: 0.5352\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6742 - accuracy: 0.5634\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6579 - accuracy: 0.6056\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7082 - accuracy: 0.5775\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6892 - accuracy: 0.6056\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6965 - accuracy: 0.6056\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6653 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6458 - accuracy: 0.6338\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6797 - accuracy: 0.6479\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6536 - accuracy: 0.6761\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6794 - accuracy: 0.6620\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6466 - accuracy: 0.6197\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.6873 - accuracy: 0.5915\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6626 - accuracy: 0.6338\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6542 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6988 - accuracy: 0.5493\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6832 - accuracy: 0.6761\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6712 - accuracy: 0.5915\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6867 - accuracy: 0.6620\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6982 - accuracy: 0.5493\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6763 - accuracy: 0.6620\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6685 - accuracy: 0.7042\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7002 - accuracy: 0.6197\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7310 - accuracy: 0.5493\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.6497 - accuracy: 0.6479\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6441 - accuracy: 0.6761\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6686 - accuracy: 0.6901\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6599 - accuracy: 0.5915\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.6432 - accuracy: 0.6479\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6664 - accuracy: 0.6620\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6411 - accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6656 - accuracy: 0.6479\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6589 - accuracy: 0.6479\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6545 - accuracy: 0.6761\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6255 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6788 - accuracy: 0.6479\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6664 - accuracy: 0.6197\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6494 - accuracy: 0.6761\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 0.6448 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6546 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.50 - 0s 76us/sample - loss: 0.6543 - accuracy: 0.5634\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6403 - accuracy: 0.6901\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6461 - accuracy: 0.6761\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6576 - accuracy: 0.6761\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6240 - accuracy: 0.6761\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6530 - accuracy: 0.6620\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 99us/sample - loss: 0.6382 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6395 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6171 - accuracy: 0.6901\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6686 - accuracy: 0.6338\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6395 - accuracy: 0.6620\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6364 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6622 - accuracy: 0.6761\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6506 - accuracy: 0.6620\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6445 - accuracy: 0.6479\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6686 - accuracy: 0.5915\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6328 - accuracy: 0.6901\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6265 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6539 - accuracy: 0.6761\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6386 - accuracy: 0.6056\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6204 - accuracy: 0.6620\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6354 - accuracy: 0.6479\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6315 - accuracy: 0.6620\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6475 - accuracy: 0.6901\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6197 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6275 - accuracy: 0.6761\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6238 - accuracy: 0.6620\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6415 - accuracy: 0.6620\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6324 - accuracy: 0.7042\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6102 - accuracy: 0.6901\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6180 - accuracy: 0.6901\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6413 - accuracy: 0.6901\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6220 - accuracy: 0.6761\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5753 - accuracy: 0.6761\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6030 - accuracy: 0.6620\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6312 - accuracy: 0.6620\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6178 - accuracy: 0.6620\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6337 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6177 - accuracy: 0.7042\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6278 - accuracy: 0.7324\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6350 - accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5899 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6256 - accuracy: 0.6761\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5870 - accuracy: 0.6338\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6300 - accuracy: 0.7042\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6050 - accuracy: 0.7042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5931 - accuracy: 0.6761\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.1237 - accuracy: 0.5556\n",
      "--- Starting trial: run-6\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.8656 - accuracy: 0.5493\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.9171 - accuracy: 0.4789\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.8732 - accuracy: 0.4930\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 1.6706 - accuracy: 0.5634\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.7612 - accuracy: 0.4789\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.0214 - accuracy: 0.4930\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.2896 - accuracy: 0.5915\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.6553 - accuracy: 0.5493\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 1.4652 - accuracy: 0.5915\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.8878 - accuracy: 0.5211\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.6462 - accuracy: 0.6620\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5607 - accuracy: 0.5352\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.7054 - accuracy: 0.5915\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.5232 - accuracy: 0.5775\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.4333 - accuracy: 0.5352\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.6166 - accuracy: 0.5915\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.4572 - accuracy: 0.5211\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0209 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.6209 - accuracy: 0.5915\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 84us/sample - loss: 1.3185 - accuracy: 0.6056\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 1.4428 - accuracy: 0.5915\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.6285 - accuracy: 0.5915\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.5982 - accuracy: 0.5070\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 1.5466 - accuracy: 0.4930\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.5175 - accuracy: 0.5775\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2419 - accuracy: 0.6338\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.5022 - accuracy: 0.5775\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.6237 - accuracy: 0.5070\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.3004 - accuracy: 0.5634\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.1797 - accuracy: 0.6479\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2471 - accuracy: 0.6197\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.3188 - accuracy: 0.5493\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.3776 - accuracy: 0.5493\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0914 - accuracy: 0.5634\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1187 - accuracy: 0.6338\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.2000 - accuracy: 0.5634\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3842 - accuracy: 0.5775\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0821 - accuracy: 0.5775\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.3195 - accuracy: 0.5634\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.3444 - accuracy: 0.5775\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.0084 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.2938 - accuracy: 0.4930\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.0733 - accuracy: 0.5211\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.0502 - accuracy: 0.6197\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.2605 - accuracy: 0.5493\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 1.0424 - accuracy: 0.5634\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 97us/sample - loss: 0.9447 - accuracy: 0.6479\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7420 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.1458 - accuracy: 0.5070\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9469 - accuracy: 0.6479\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8312 - accuracy: 0.6901\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 1.0404 - accuracy: 0.6338\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9444 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.1555 - accuracy: 0.4930\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.1136 - accuracy: 0.6056\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7423 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.0415 - accuracy: 0.6338\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9349 - accuracy: 0.6338\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9300 - accuracy: 0.6761\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.8781 - accuracy: 0.5915\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8566 - accuracy: 0.6338\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8257 - accuracy: 0.6620\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9924 - accuracy: 0.5493\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9642 - accuracy: 0.6479\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9401 - accuracy: 0.5775\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0204 - accuracy: 0.6056\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8960 - accuracy: 0.6197\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6946 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9734 - accuracy: 0.5915\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7957 - accuracy: 0.6479\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9776 - accuracy: 0.6197\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8687 - accuracy: 0.5775\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7128 - accuracy: 0.6901\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8416 - accuracy: 0.6338\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8536 - accuracy: 0.5775\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9460 - accuracy: 0.5493\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.7690 - accuracy: 0.6197\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7907 - accuracy: 0.6197\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8208 - accuracy: 0.6479\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.9776 - accuracy: 0.6056\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6856 - accuracy: 0.6338\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.7119 - accuracy: 0.6620\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.8632 - accuracy: 0.5775\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8667 - accuracy: 0.6479\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.8247 - accuracy: 0.6620\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7701 - accuracy: 0.6761\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8127 - accuracy: 0.6479\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7738 - accuracy: 0.7465\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8550 - accuracy: 0.5915\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9022 - accuracy: 0.6197\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7567 - accuracy: 0.6479\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8075 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6902 - accuracy: 0.7324\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6942 - accuracy: 0.6901\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6837 - accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7813 - accuracy: 0.6479\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.7959 - accuracy: 0.6056\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7370 - accuracy: 0.5915\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6113 - accuracy: 0.6901\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7034 - accuracy: 0.6479\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.8305 - accuracy: 0.3889\n",
      "--- Starting trial: run-7\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 7ms/sample - loss: 1.1907 - accuracy: 0.5775\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1480 - accuracy: 0.6056\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.6198 - accuracy: 0.5634\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.4702 - accuracy: 0.5634\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.3538 - accuracy: 0.6197\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2483 - accuracy: 0.5634\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2551 - accuracy: 0.5915\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.4824 - accuracy: 0.6197\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.4227 - accuracy: 0.5915\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.2043 - accuracy: 0.6056\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2071 - accuracy: 0.6338\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2939 - accuracy: 0.6479\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.4567 - accuracy: 0.5634\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.2361 - accuracy: 0.5634\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.0405 - accuracy: 0.5915\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.2204 - accuracy: 0.5634\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.2250 - accuracy: 0.6056\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2454 - accuracy: 0.6338\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0826 - accuracy: 0.6620\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.2967 - accuracy: 0.5915\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8834 - accuracy: 0.6620\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 101us/sample - loss: 0.9738 - accuracy: 0.6197\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0503 - accuracy: 0.6056\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.1623 - accuracy: 0.5775\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.0803 - accuracy: 0.5352\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0924 - accuracy: 0.5775\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8760 - accuracy: 0.6761\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9607 - accuracy: 0.6197\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.9810 - accuracy: 0.6620\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.1109 - accuracy: 0.5915\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.9144 - accuracy: 0.6479\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0783 - accuracy: 0.5352\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7917 - accuracy: 0.6479\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0657 - accuracy: 0.6197\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8646 - accuracy: 0.6620\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.8199 - accuracy: 0.5775\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.9876 - accuracy: 0.6197\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9462 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.8230 - accuracy: 0.5915\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9564 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.8918 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8399 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.9812 - accuracy: 0.6056\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.8332 - accuracy: 0.7042\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.8376 - accuracy: 0.6901\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 97us/sample - loss: 0.9717 - accuracy: 0.5915\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 103us/sample - loss: 0.8633 - accuracy: 0.6761\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.9993 - accuracy: 0.6056\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7878 - accuracy: 0.6197\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9028 - accuracy: 0.6056\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.9710 - accuracy: 0.5634\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7617 - accuracy: 0.6056\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7941 - accuracy: 0.6479\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8649 - accuracy: 0.6056\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.8031 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 98us/sample - loss: 0.8178 - accuracy: 0.6197\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8539 - accuracy: 0.6479\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.8419 - accuracy: 0.6197\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 107us/sample - loss: 0.8374 - accuracy: 0.5634\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8922 - accuracy: 0.5915\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7766 - accuracy: 0.6338\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8215 - accuracy: 0.6197\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8164 - accuracy: 0.6338\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6961 - accuracy: 0.6479\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7029 - accuracy: 0.6620\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6701 - accuracy: 0.6620\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6598 - accuracy: 0.6338\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.7495 - accuracy: 0.6479\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.8156 - accuracy: 0.6197\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6624 - accuracy: 0.6620\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7952 - accuracy: 0.6620\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7671 - accuracy: 0.6197\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8275 - accuracy: 0.6620\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7434 - accuracy: 0.6338\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7039 - accuracy: 0.6338\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8414 - accuracy: 0.6338\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7775 - accuracy: 0.6479\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7374 - accuracy: 0.6338\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7551 - accuracy: 0.5915\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7731 - accuracy: 0.6197\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7250 - accuracy: 0.6338\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7397 - accuracy: 0.6338\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7544 - accuracy: 0.6197\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.7115 - accuracy: 0.6197\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7517 - accuracy: 0.6056\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6955 - accuracy: 0.5775\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7658 - accuracy: 0.6338\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7464 - accuracy: 0.6056\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7211 - accuracy: 0.6338\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7206 - accuracy: 0.5915\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7175 - accuracy: 0.6197\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6999 - accuracy: 0.6479\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7033 - accuracy: 0.5634\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6889 - accuracy: 0.5915\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7304 - accuracy: 0.6479\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6580 - accuracy: 0.6197\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6935 - accuracy: 0.5915\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6016 - accuracy: 0.6620\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6842 - accuracy: 0.5915\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.6410 - accuracy: 0.5915\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.3460 - accuracy: 0.6667\n",
      "--- Starting trial: run-8\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.0865 - accuracy: 0.4366\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 2.3966 - accuracy: 0.3944\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.3779 - accuracy: 0.5211\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.8502 - accuracy: 0.3662\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2922 - accuracy: 0.4789\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1463 - accuracy: 0.5352\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2959 - accuracy: 0.3521\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9602 - accuracy: 0.5211\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1727 - accuracy: 0.3944\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8612 - accuracy: 0.5211\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8650 - accuracy: 0.5634\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9844 - accuracy: 0.5211\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9282 - accuracy: 0.5775\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7292 - accuracy: 0.6056\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9283 - accuracy: 0.5352\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8244 - accuracy: 0.5634\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.9471 - accuracy: 0.5634\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8721 - accuracy: 0.5634\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8825 - accuracy: 0.5352\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8177 - accuracy: 0.5915\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7298 - accuracy: 0.5915\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.7425 - accuracy: 0.5915\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7273 - accuracy: 0.6338\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6913 - accuracy: 0.5634\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8022 - accuracy: 0.6197\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7163 - accuracy: 0.6479\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6141 - accuracy: 0.6056\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6718 - accuracy: 0.5493\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6355 - accuracy: 0.6620\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7479 - accuracy: 0.5493\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6675 - accuracy: 0.6056\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6738 - accuracy: 0.5493\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7107 - accuracy: 0.6338\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6622 - accuracy: 0.6901\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8011 - accuracy: 0.5634\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6287 - accuracy: 0.5775\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7421 - accuracy: 0.6338\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6826 - accuracy: 0.6761\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.6386 - accuracy: 0.6197\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 98us/sample - loss: 0.6716 - accuracy: 0.5775\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6792 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.6172 - accuracy: 0.5915\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6372 - accuracy: 0.6620\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6191 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6836 - accuracy: 0.6197\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6739 - accuracy: 0.6338\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7104 - accuracy: 0.6056\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5867 - accuracy: 0.6479\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6693 - accuracy: 0.6197\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6387 - accuracy: 0.6479\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.6312 - accuracy: 0.6338\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6217 - accuracy: 0.6620\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 85us/sample - loss: 0.6487 - accuracy: 0.5915\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 98us/sample - loss: 0.6614 - accuracy: 0.5775\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5998 - accuracy: 0.6901\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 103us/sample - loss: 0.6595 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6675 - accuracy: 0.6338\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 105us/sample - loss: 0.6420 - accuracy: 0.6056\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5964 - accuracy: 0.6620\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5766 - accuracy: 0.6620\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.6303 - accuracy: 0.6338\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6598 - accuracy: 0.6197\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6227 - accuracy: 0.6338\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.75 - 0s 75us/sample - loss: 0.5797 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6157 - accuracy: 0.6620\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 0.5877 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5977 - accuracy: 0.6901\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5413 - accuracy: 0.7042\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6004 - accuracy: 0.6761\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6449 - accuracy: 0.6338\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5809 - accuracy: 0.6620\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.6311 - accuracy: 0.6479\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5680 - accuracy: 0.7183\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5774 - accuracy: 0.6761\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6241 - accuracy: 0.6620\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5662 - accuracy: 0.6479\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6160 - accuracy: 0.6479\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5733 - accuracy: 0.6479\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6075 - accuracy: 0.6479\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6099 - accuracy: 0.6479\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5416 - accuracy: 0.7042\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6428 - accuracy: 0.6056\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.6404 - accuracy: 0.6197\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5651 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5734 - accuracy: 0.6901\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.5741 - accuracy: 0.6479\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5771 - accuracy: 0.6479\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6430 - accuracy: 0.6479\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6006 - accuracy: 0.6761\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6146 - accuracy: 0.6338\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6225 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6256 - accuracy: 0.6901\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5679 - accuracy: 0.6338\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5618 - accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5548 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6376 - accuracy: 0.6197\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6151 - accuracy: 0.6197\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6166 - accuracy: 0.6620\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.5707 - accuracy: 0.6761\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5633 - accuracy: 0.6620\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.6470 - accuracy: 0.5000\n",
      "--- Starting trial: run-9\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 2.6193 - accuracy: 0.3803\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.9983 - accuracy: 0.3944\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 2.7356 - accuracy: 0.4507\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.7758 - accuracy: 0.4789\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 2.8828 - accuracy: 0.4225\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 2.9369 - accuracy: 0.4366\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.7289 - accuracy: 0.4225\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 2.1468 - accuracy: 0.4648\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 2.1835 - accuracy: 0.3944\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.2322 - accuracy: 0.4507\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 2.3669 - accuracy: 0.4507\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 2.3128 - accuracy: 0.4930\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 96us/sample - loss: 2.2242 - accuracy: 0.4930\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 1.8319 - accuracy: 0.4366\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 2.0931 - accuracy: 0.4930\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 2.1335 - accuracy: 0.5070\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.6452 - accuracy: 0.4789\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 2.1082 - accuracy: 0.4648\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.6149 - accuracy: 0.4789\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.7765 - accuracy: 0.4648\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 2.3826 - accuracy: 0.4366\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.7394 - accuracy: 0.4789\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.5285 - accuracy: 0.5493\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.5455 - accuracy: 0.5634\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.6473 - accuracy: 0.4648\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.8203 - accuracy: 0.4507\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 101us/sample - loss: 1.7423 - accuracy: 0.3944\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.6054 - accuracy: 0.4648\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 1.6849 - accuracy: 0.4648\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 77us/sample - loss: 1.6308 - accuracy: 0.4789\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 1.5370 - accuracy: 0.3521\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.5251 - accuracy: 0.4789\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.3658 - accuracy: 0.4225\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.6063 - accuracy: 0.4789\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2798 - accuracy: 0.4648\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 1.4533 - accuracy: 0.4789\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.5182 - accuracy: 0.4648\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.4327 - accuracy: 0.4225\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.4789 - accuracy: 0.4507\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1309 - accuracy: 0.5070\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1584 - accuracy: 0.4648\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.1145 - accuracy: 0.4366\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.3926 - accuracy: 0.4507\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.3497 - accuracy: 0.4507\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 103us/sample - loss: 1.1582 - accuracy: 0.4507\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.3332 - accuracy: 0.5070\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.2332 - accuracy: 0.4789\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.0654 - accuracy: 0.5493\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3546 - accuracy: 0.4930\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.9508 - accuracy: 0.5211\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0250 - accuracy: 0.5634\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0528 - accuracy: 0.5211\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 1.0221 - accuracy: 0.4648\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.0093 - accuracy: 0.4648\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.9761 - accuracy: 0.4789\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 97us/sample - loss: 0.9981 - accuracy: 0.4507\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9579 - accuracy: 0.5070\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 94us/sample - loss: 1.0673 - accuracy: 0.4648\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.0583 - accuracy: 0.4930\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.9710 - accuracy: 0.5352\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.9403 - accuracy: 0.4789\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9015 - accuracy: 0.4789\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.8704 - accuracy: 0.5352\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.8415 - accuracy: 0.5775\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.9487 - accuracy: 0.4789\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 98us/sample - loss: 0.8409 - accuracy: 0.5352\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8766 - accuracy: 0.5352\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8545 - accuracy: 0.4930\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7632 - accuracy: 0.6056\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8362 - accuracy: 0.5352\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7552 - accuracy: 0.6056\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8588 - accuracy: 0.5634\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7424 - accuracy: 0.5915\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8366 - accuracy: 0.5775\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7409 - accuracy: 0.5775\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7401 - accuracy: 0.5915\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7688 - accuracy: 0.5775\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7419 - accuracy: 0.6338\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.7237 - accuracy: 0.6197\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7162 - accuracy: 0.5775\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7585 - accuracy: 0.5634\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7548 - accuracy: 0.5634\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7475 - accuracy: 0.5493\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6963 - accuracy: 0.6338\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.7311 - accuracy: 0.6479\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7099 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7256 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6522 - accuracy: 0.6338\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.6872 - accuracy: 0.6197\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7028 - accuracy: 0.6761\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.7688 - accuracy: 0.5493\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.7266 - accuracy: 0.6197\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6691 - accuracy: 0.6197\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6904 - accuracy: 0.6197\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6817 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6864 - accuracy: 0.6197\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6718 - accuracy: 0.6479\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6826 - accuracy: 0.6338\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6879 - accuracy: 0.6761\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6647 - accuracy: 0.6338\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.7113 - accuracy: 0.6667\n",
      "--- Starting trial: run-10\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.2022 - accuracy: 0.5775\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3636 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1006 - accuracy: 0.6056\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.1491 - accuracy: 0.6056\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9204 - accuracy: 0.6620\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.0688 - accuracy: 0.5915\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 75us/sample - loss: 1.0576 - accuracy: 0.6056\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0050 - accuracy: 0.6197\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1447 - accuracy: 0.6056\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9731 - accuracy: 0.6620\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0236 - accuracy: 0.6056\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8830 - accuracy: 0.6056\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1720 - accuracy: 0.6056\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.9772 - accuracy: 0.6197\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 1.1341 - accuracy: 0.5634\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9014 - accuracy: 0.6338\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.1202 - accuracy: 0.6056\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1349 - accuracy: 0.5915\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8808 - accuracy: 0.5775\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9376 - accuracy: 0.5775\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1481 - accuracy: 0.6056\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9060 - accuracy: 0.6479\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.0710 - accuracy: 0.4930\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2054 - accuracy: 0.5352\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9131 - accuracy: 0.6197\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.7870 - accuracy: 0.6338\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8430 - accuracy: 0.6620\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8073 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.9438 - accuracy: 0.5775\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8692 - accuracy: 0.6479\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8852 - accuracy: 0.6197\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0489 - accuracy: 0.5915\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9410 - accuracy: 0.6197\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8125 - accuracy: 0.6056\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8070 - accuracy: 0.6056\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6341 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8654 - accuracy: 0.6479\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.9990 - accuracy: 0.5070\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6850 - accuracy: 0.6761\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8316 - accuracy: 0.6479\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8297 - accuracy: 0.6197\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7825 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8825 - accuracy: 0.6197\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8946 - accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.8292 - accuracy: 0.6056\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6627 - accuracy: 0.6338\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8066 - accuracy: 0.5915\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8687 - accuracy: 0.5775\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8176 - accuracy: 0.6197\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8219 - accuracy: 0.6620\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8208 - accuracy: 0.6620\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6581 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7146 - accuracy: 0.6338\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.7420 - accuracy: 0.6338\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.7214 - accuracy: 0.6761\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.6930 - accuracy: 0.6761\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7354 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6889 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7503 - accuracy: 0.6197\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6978 - accuracy: 0.6197\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.7217 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7974 - accuracy: 0.6479\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8109 - accuracy: 0.6197\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8204 - accuracy: 0.5775\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7697 - accuracy: 0.6620\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6606 - accuracy: 0.7183\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6464 - accuracy: 0.6620\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6922 - accuracy: 0.6620\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7498 - accuracy: 0.6479\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7826 - accuracy: 0.6197\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7171 - accuracy: 0.6901\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6613 - accuracy: 0.6901\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6698 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7530 - accuracy: 0.6197\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7413 - accuracy: 0.6479\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6835 - accuracy: 0.6056\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6815 - accuracy: 0.6620\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6892 - accuracy: 0.6479\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5934 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7301 - accuracy: 0.6620\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6254 - accuracy: 0.6620\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8105 - accuracy: 0.6197\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5568 - accuracy: 0.7042\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6308 - accuracy: 0.6479\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6965 - accuracy: 0.6761\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6980 - accuracy: 0.7042\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6382 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.7355 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.6277 - accuracy: 0.6620\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.7126 - accuracy: 0.6620\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6061 - accuracy: 0.6761\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5817 - accuracy: 0.6901\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6065 - accuracy: 0.7042\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7214 - accuracy: 0.6479\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.6718 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7006 - accuracy: 0.6620\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.7052 - accuracy: 0.6197\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6332 - accuracy: 0.6620\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6161 - accuracy: 0.6479\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6920 - accuracy: 0.6761\n",
      "18/18 [==============================] - 0s 5ms/sample - loss: 1.4242 - accuracy: 0.5000\n",
      "--- Starting trial: run-11\n",
      "{'num_units 1': 4, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.2684 - accuracy: 0.5775\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 2.1929 - accuracy: 0.6056\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.8429 - accuracy: 0.6056\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.4625 - accuracy: 0.6056\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2875 - accuracy: 0.6479\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.9888 - accuracy: 0.6197\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0623 - accuracy: 0.6479\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0145 - accuracy: 0.6338\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9877 - accuracy: 0.6479\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7849 - accuracy: 0.6761\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1700 - accuracy: 0.6197\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0790 - accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8900 - accuracy: 0.5493\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7624 - accuracy: 0.6056\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6879 - accuracy: 0.6197\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6896 - accuracy: 0.6901\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7668 - accuracy: 0.6761\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6818 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8891 - accuracy: 0.5915\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7115 - accuracy: 0.6338\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8819 - accuracy: 0.6338\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7972 - accuracy: 0.5493\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5757 - accuracy: 0.7465\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6877 - accuracy: 0.5493\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6013 - accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6248 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6613 - accuracy: 0.5915\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6499 - accuracy: 0.5775\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6467 - accuracy: 0.5775\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6791 - accuracy: 0.6056\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6037 - accuracy: 0.6761\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6749 - accuracy: 0.6479\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7552 - accuracy: 0.5211\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5677 - accuracy: 0.5915\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6423 - accuracy: 0.6620\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6456 - accuracy: 0.6056\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6016 - accuracy: 0.5493\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6564 - accuracy: 0.5634\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6076 - accuracy: 0.5915\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6673 - accuracy: 0.5775\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6422 - accuracy: 0.5775\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5621 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5943 - accuracy: 0.5775\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5487 - accuracy: 0.6901\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6599 - accuracy: 0.5775\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5979 - accuracy: 0.6056\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 100us/sample - loss: 0.6073 - accuracy: 0.6197\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6099 - accuracy: 0.5775\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5505 - accuracy: 0.6620\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.5846 - accuracy: 0.6901\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5749 - accuracy: 0.6338\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5624 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7031 - accuracy: 0.5775\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5710 - accuracy: 0.6338\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6409 - accuracy: 0.6197\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 104us/sample - loss: 0.6295 - accuracy: 0.6056\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6581 - accuracy: 0.6338\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6162 - accuracy: 0.6056\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6772 - accuracy: 0.5915\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6399 - accuracy: 0.6197\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5652 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 97us/sample - loss: 0.5357 - accuracy: 0.6338\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6320 - accuracy: 0.5211\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.6386 - accuracy: 0.5775\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.5794 - accuracy: 0.5915\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6103 - accuracy: 0.5493\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6194 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6855 - accuracy: 0.6620\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5790 - accuracy: 0.7042\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5677 - accuracy: 0.6479\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5953 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.5674 - accuracy: 0.6901\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.6158 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6072 - accuracy: 0.6338\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5464 - accuracy: 0.6056\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5663 - accuracy: 0.5634\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5723 - accuracy: 0.5915\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6049 - accuracy: 0.6197\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5726 - accuracy: 0.6761\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6373 - accuracy: 0.5915\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6151 - accuracy: 0.6761\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5948 - accuracy: 0.6620\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5532 - accuracy: 0.6761\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6386 - accuracy: 0.6338\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 101us/sample - loss: 0.6197 - accuracy: 0.6479\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.5897 - accuracy: 0.6479\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6177 - accuracy: 0.6761\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.68 - 0s 81us/sample - loss: 0.5614 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5462 - accuracy: 0.7042\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.6457 - accuracy: 0.6479\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6049 - accuracy: 0.6901\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6020 - accuracy: 0.6901\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 94us/sample - loss: 0.6057 - accuracy: 0.6761\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.5903 - accuracy: 0.6479\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5989 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6031 - accuracy: 0.6761\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5417 - accuracy: 0.6901\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5372 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5236 - accuracy: 0.7042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5412 - accuracy: 0.7042\n",
      "18/18 [==============================] - 0s 5ms/sample - loss: 1.0797 - accuracy: 0.5556\n",
      "--- Starting trial: run-12\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 2.2417 - accuracy: 0.4789\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.9282 - accuracy: 0.5493\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.9356 - accuracy: 0.5211\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.6085 - accuracy: 0.5211\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.4289 - accuracy: 0.5352\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.8641 - accuracy: 0.5211\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.6755 - accuracy: 0.5352\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.5639 - accuracy: 0.5493\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.4867 - accuracy: 0.5493\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.6088 - accuracy: 0.6197\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4520 - accuracy: 0.5775\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2042 - accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2855 - accuracy: 0.5915\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.4635 - accuracy: 0.5493\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0371 - accuracy: 0.6056\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2626 - accuracy: 0.5915\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2618 - accuracy: 0.5352\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1783 - accuracy: 0.5775\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1316 - accuracy: 0.6056\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0748 - accuracy: 0.5634\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9179 - accuracy: 0.6197\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9773 - accuracy: 0.6056\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0142 - accuracy: 0.5775\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.0595 - accuracy: 0.5915\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9561 - accuracy: 0.5634\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9210 - accuracy: 0.5915\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9192 - accuracy: 0.5915\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8848 - accuracy: 0.5915\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8189 - accuracy: 0.6056\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9418 - accuracy: 0.5915\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8628 - accuracy: 0.5634\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7865 - accuracy: 0.6338\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7884 - accuracy: 0.6338\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7598 - accuracy: 0.5915\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7201 - accuracy: 0.6479\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6840 - accuracy: 0.6479\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6976 - accuracy: 0.6479\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6908 - accuracy: 0.6338\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7260 - accuracy: 0.6620\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7156 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6594 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7316 - accuracy: 0.6761\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6578 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7420 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6505 - accuracy: 0.6761\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6302 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6588 - accuracy: 0.6479\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6083 - accuracy: 0.7183\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6291 - accuracy: 0.6761\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6341 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6338 - accuracy: 0.6761\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6637 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6125 - accuracy: 0.6901\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6344 - accuracy: 0.6761\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6412 - accuracy: 0.6761\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5827 - accuracy: 0.6761\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6481 - accuracy: 0.6761\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6400 - accuracy: 0.6620\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5866 - accuracy: 0.6620\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6250 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6145 - accuracy: 0.6338\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6148 - accuracy: 0.6761\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6042 - accuracy: 0.7042\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5858 - accuracy: 0.6901\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5823 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6591 - accuracy: 0.6338\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7006 - accuracy: 0.6479\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5882 - accuracy: 0.6761\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5505 - accuracy: 0.6901\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6395 - accuracy: 0.6620\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5663 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5683 - accuracy: 0.6761\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6405 - accuracy: 0.6620\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5803 - accuracy: 0.6620\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5519 - accuracy: 0.6901\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5834 - accuracy: 0.6761\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5744 - accuracy: 0.6761\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5884 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6231 - accuracy: 0.6197\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5791 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6010 - accuracy: 0.6901\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5594 - accuracy: 0.6761\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5816 - accuracy: 0.6901\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5703 - accuracy: 0.6901\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5582 - accuracy: 0.6901\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5857 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5924 - accuracy: 0.6761\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5557 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5576 - accuracy: 0.6761\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5625 - accuracy: 0.6620\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5660 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6008 - accuracy: 0.6338\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5903 - accuracy: 0.6479\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.68 - 0s 73us/sample - loss: 0.5858 - accuracy: 0.6197\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5761 - accuracy: 0.6761\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5800 - accuracy: 0.6761\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5834 - accuracy: 0.6479\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5375 - accuracy: 0.6761\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5404 - accuracy: 0.6479\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5929 - accuracy: 0.6479\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.3332 - accuracy: 0.4444\n",
      "--- Starting trial: run-13\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.5244 - accuracy: 0.6338\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.9445 - accuracy: 0.6197\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.8248 - accuracy: 0.5915\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.8353 - accuracy: 0.6197\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5596 - accuracy: 0.6338\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.7459 - accuracy: 0.6338\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.6023 - accuracy: 0.6197\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.5744 - accuracy: 0.6620\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.6226 - accuracy: 0.6479\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.6477 - accuracy: 0.6056\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.5169 - accuracy: 0.6338\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5312 - accuracy: 0.5915\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5034 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4985 - accuracy: 0.5915\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3239 - accuracy: 0.6197\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.2928 - accuracy: 0.6479\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2765 - accuracy: 0.6338\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3485 - accuracy: 0.6338\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0212 - accuracy: 0.6479\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2441 - accuracy: 0.5915\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.1740 - accuracy: 0.5915\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.2204 - accuracy: 0.6338\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9145 - accuracy: 0.6338\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.1120 - accuracy: 0.6479\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.1612 - accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1462 - accuracy: 0.6197\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.1431 - accuracy: 0.6056\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1034 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0930 - accuracy: 0.5915\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0254 - accuracy: 0.6338\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.0449 - accuracy: 0.6197\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.0174 - accuracy: 0.6479\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0084 - accuracy: 0.6197\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9121 - accuracy: 0.6338\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9620 - accuracy: 0.6056\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9116 - accuracy: 0.6056\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9426 - accuracy: 0.5915\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.9236 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8924 - accuracy: 0.6197\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8899 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8302 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8292 - accuracy: 0.6338\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7596 - accuracy: 0.6338\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8316 - accuracy: 0.6338\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8245 - accuracy: 0.6338\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7862 - accuracy: 0.6338\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8686 - accuracy: 0.6197\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7453 - accuracy: 0.6761\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7775 - accuracy: 0.6338\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7753 - accuracy: 0.6338\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7863 - accuracy: 0.6056\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7968 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6844 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6870 - accuracy: 0.7042\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7157 - accuracy: 0.6197\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6809 - accuracy: 0.6901\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6820 - accuracy: 0.7042\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6915 - accuracy: 0.7042\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7098 - accuracy: 0.6761\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7158 - accuracy: 0.6620\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6890 - accuracy: 0.6901\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7232 - accuracy: 0.6761\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6936 - accuracy: 0.6901\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6763 - accuracy: 0.6901\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6670 - accuracy: 0.6901\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6564 - accuracy: 0.7183\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6216 - accuracy: 0.6901\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6432 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6296 - accuracy: 0.7042\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6238 - accuracy: 0.7183\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6506 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6238 - accuracy: 0.7042\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5607 - accuracy: 0.7324\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6366 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5798 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6135 - accuracy: 0.7042\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6168 - accuracy: 0.6901\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5590 - accuracy: 0.6761\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5929 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5670 - accuracy: 0.6901\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5697 - accuracy: 0.6620\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5799 - accuracy: 0.7042\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5739 - accuracy: 0.7042\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5723 - accuracy: 0.7324\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5783 - accuracy: 0.6761\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5719 - accuracy: 0.7465\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5762 - accuracy: 0.6901\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5778 - accuracy: 0.7042\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5408 - accuracy: 0.6901\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5982 - accuracy: 0.7042\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5557 - accuracy: 0.7183\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6040 - accuracy: 0.6901\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5934 - accuracy: 0.6761\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5424 - accuracy: 0.7183\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5242 - accuracy: 0.7183\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5495 - accuracy: 0.7042\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6174 - accuracy: 0.6479\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5679 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5280 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5818 - accuracy: 0.6901\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.5467 - accuracy: 0.5000\n",
      "--- Starting trial: run-14\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.1297 - accuracy: 0.5211\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8992 - accuracy: 0.5634\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7979 - accuracy: 0.6197\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.8030 - accuracy: 0.5634\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7268 - accuracy: 0.5915\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7034 - accuracy: 0.6479\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7097 - accuracy: 0.6056\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6247 - accuracy: 0.6197\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6637 - accuracy: 0.6197\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6441 - accuracy: 0.6056\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6395 - accuracy: 0.6197\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6633 - accuracy: 0.6338\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6081 - accuracy: 0.6901\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6609 - accuracy: 0.5915\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6462 - accuracy: 0.6056\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6269 - accuracy: 0.6338\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6289 - accuracy: 0.6620\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6370 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6214 - accuracy: 0.6901\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6332 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6094 - accuracy: 0.7042\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5876 - accuracy: 0.7183\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6372 - accuracy: 0.6761\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5833 - accuracy: 0.6901\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6396 - accuracy: 0.6901\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6017 - accuracy: 0.6901\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6168 - accuracy: 0.6901\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6075 - accuracy: 0.7183\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5920 - accuracy: 0.7183\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5947 - accuracy: 0.6901\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5829 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5778 - accuracy: 0.7324\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5548 - accuracy: 0.6901\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5889 - accuracy: 0.7042\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5993 - accuracy: 0.7042\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5820 - accuracy: 0.7042\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5757 - accuracy: 0.7042\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5975 - accuracy: 0.6761\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5747 - accuracy: 0.7324\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5880 - accuracy: 0.7324\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6006 - accuracy: 0.7183\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5644 - accuracy: 0.7183\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5685 - accuracy: 0.7324\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5777 - accuracy: 0.7183\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5995 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5664 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5476 - accuracy: 0.7606\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5713 - accuracy: 0.7183\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5661 - accuracy: 0.7324\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5757 - accuracy: 0.6901\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5605 - accuracy: 0.7465\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5818 - accuracy: 0.7183\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5750 - accuracy: 0.6901\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5767 - accuracy: 0.6901\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5515 - accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5773 - accuracy: 0.7042\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5531 - accuracy: 0.7465\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5428 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5744 - accuracy: 0.7183\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5661 - accuracy: 0.7324\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5518 - accuracy: 0.7324\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5601 - accuracy: 0.7042\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5651 - accuracy: 0.7042\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5816 - accuracy: 0.6620\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5815 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5896 - accuracy: 0.6620\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5540 - accuracy: 0.7183\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5411 - accuracy: 0.7465\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5447 - accuracy: 0.7324\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5443 - accuracy: 0.7465\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5758 - accuracy: 0.6901\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5655 - accuracy: 0.7183\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5485 - accuracy: 0.7324\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5669 - accuracy: 0.7324\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5681 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5553 - accuracy: 0.7324\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5446 - accuracy: 0.7465\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5775 - accuracy: 0.7042\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5326 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5374 - accuracy: 0.7183\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5328 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5425 - accuracy: 0.7183\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5257 - accuracy: 0.7324\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5540 - accuracy: 0.7183\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5559 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5650 - accuracy: 0.7324\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5690 - accuracy: 0.7183\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5594 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5289 - accuracy: 0.7183\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 56us/sample - loss: 0.5418 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5196 - accuracy: 0.6901\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5243 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5700 - accuracy: 0.6761\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5418 - accuracy: 0.7746\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5475 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5541 - accuracy: 0.7183\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5517 - accuracy: 0.7324\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5234 - accuracy: 0.7465\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5383 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5083 - accuracy: 0.7324\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.2156 - accuracy: 0.5000\n",
      "--- Starting trial: run-15\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 1s 8ms/sample - loss: 1.0043 - accuracy: 0.5775\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.9704 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9289 - accuracy: 0.5775\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9502 - accuracy: 0.5211\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9645 - accuracy: 0.5352\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8835 - accuracy: 0.5493\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8673 - accuracy: 0.5915\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8396 - accuracy: 0.5915\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8603 - accuracy: 0.5634\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8000 - accuracy: 0.5915\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6831 - accuracy: 0.6197\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8576 - accuracy: 0.5634\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6786 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7390 - accuracy: 0.6197\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8463 - accuracy: 0.5775\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6640 - accuracy: 0.6056\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7275 - accuracy: 0.6056\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7341 - accuracy: 0.6197\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7650 - accuracy: 0.5915\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6480 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7522 - accuracy: 0.5915\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7203 - accuracy: 0.6197\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7191 - accuracy: 0.6056\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7263 - accuracy: 0.6197\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6320 - accuracy: 0.6761\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6997 - accuracy: 0.5775\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6694 - accuracy: 0.5915\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6730 - accuracy: 0.6197\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6964 - accuracy: 0.6197\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6168 - accuracy: 0.6761\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6128 - accuracy: 0.6620\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5796 - accuracy: 0.7042\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6312 - accuracy: 0.6479\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6535 - accuracy: 0.6620\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6086 - accuracy: 0.7042\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6240 - accuracy: 0.6479\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6636 - accuracy: 0.6197\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6250 - accuracy: 0.6620\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6288 - accuracy: 0.6479\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6534 - accuracy: 0.6620\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6205 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5996 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6102 - accuracy: 0.6338\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6459 - accuracy: 0.6197\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6013 - accuracy: 0.6761\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6444 - accuracy: 0.5634\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6226 - accuracy: 0.6338\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5581 - accuracy: 0.6901\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5455 - accuracy: 0.7183\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6015 - accuracy: 0.6479\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5808 - accuracy: 0.6620\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6025 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5672 - accuracy: 0.6479\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5934 - accuracy: 0.6761\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5513 - accuracy: 0.6761\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5411 - accuracy: 0.7183\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5574 - accuracy: 0.6901\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5766 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6028 - accuracy: 0.6620\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5260 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5312 - accuracy: 0.7324\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5695 - accuracy: 0.7042\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5557 - accuracy: 0.6901\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5316 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5336 - accuracy: 0.7324\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5355 - accuracy: 0.7183\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5588 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5696 - accuracy: 0.6479\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5616 - accuracy: 0.6620\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5387 - accuracy: 0.7183\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4965 - accuracy: 0.7465\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5517 - accuracy: 0.6338\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.65 - 0s 72us/sample - loss: 0.5368 - accuracy: 0.7324\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5441 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5323 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5273 - accuracy: 0.6901\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5497 - accuracy: 0.6761\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5352 - accuracy: 0.7042\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5743 - accuracy: 0.6197\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5344 - accuracy: 0.6901\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5179 - accuracy: 0.6901\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5781 - accuracy: 0.6338\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5201 - accuracy: 0.6901\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5096 - accuracy: 0.6901\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5224 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5201 - accuracy: 0.6901\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5082 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4998 - accuracy: 0.7183\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5740 - accuracy: 0.6479\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5216 - accuracy: 0.7183\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5184 - accuracy: 0.7042\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5175 - accuracy: 0.7042\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4932 - accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4793 - accuracy: 0.7887\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5112 - accuracy: 0.7183\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4641 - accuracy: 0.8028\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5060 - accuracy: 0.7042\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5011 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.4877 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5117 - accuracy: 0.7183\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8775 - accuracy: 0.6111\n",
      "--- Starting trial: run-16\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 0.8637 - accuracy: 0.6056\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9056 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.7989 - accuracy: 0.6197\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8048 - accuracy: 0.6197\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.8172 - accuracy: 0.6056\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.7092 - accuracy: 0.5775\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6594 - accuracy: 0.6197\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7467 - accuracy: 0.5915\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6483 - accuracy: 0.6197\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7397 - accuracy: 0.6901\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6911 - accuracy: 0.6901\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6522 - accuracy: 0.7183\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6877 - accuracy: 0.7042\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6718 - accuracy: 0.6479\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6392 - accuracy: 0.6479\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6458 - accuracy: 0.6761\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.6492 - accuracy: 0.7042\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6806 - accuracy: 0.6620\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6633 - accuracy: 0.6761\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6292 - accuracy: 0.6761\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6565 - accuracy: 0.6901\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6483 - accuracy: 0.6901\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6177 - accuracy: 0.7606\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6027 - accuracy: 0.6901\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6331 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5832 - accuracy: 0.7183\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6197 - accuracy: 0.6479\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6064 - accuracy: 0.7042\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.5893 - accuracy: 0.6620\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6152 - accuracy: 0.7042\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5758 - accuracy: 0.6056\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5928 - accuracy: 0.7042\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5943 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5836 - accuracy: 0.6056\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5999 - accuracy: 0.6620\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5897 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5569 - accuracy: 0.7042\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5739 - accuracy: 0.7324\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6158 - accuracy: 0.6901\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5262 - accuracy: 0.7324\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5641 - accuracy: 0.6901\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5795 - accuracy: 0.6761\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5452 - accuracy: 0.7183\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5233 - accuracy: 0.7465\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5172 - accuracy: 0.7465\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5712 - accuracy: 0.7465\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5376 - accuracy: 0.7465\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5432 - accuracy: 0.7324\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5833 - accuracy: 0.7042\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4931 - accuracy: 0.7606\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5488 - accuracy: 0.7324\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5701 - accuracy: 0.7465\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5875 - accuracy: 0.7324\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5358 - accuracy: 0.7465\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5311 - accuracy: 0.7465\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5189 - accuracy: 0.7746\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5061 - accuracy: 0.7746\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.4983 - accuracy: 0.7746\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5358 - accuracy: 0.7606\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5339 - accuracy: 0.7324\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5125 - accuracy: 0.7324\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5171 - accuracy: 0.7606\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4989 - accuracy: 0.7746\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5005 - accuracy: 0.7887\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4830 - accuracy: 0.7887\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5385 - accuracy: 0.7183\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5247 - accuracy: 0.7606\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5379 - accuracy: 0.8028\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4956 - accuracy: 0.7887\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5036 - accuracy: 0.8028\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4902 - accuracy: 0.8028\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4832 - accuracy: 0.8169\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5814 - accuracy: 0.7324\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4807 - accuracy: 0.7887\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4795 - accuracy: 0.7887\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5547 - accuracy: 0.7465\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4662 - accuracy: 0.8169\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4979 - accuracy: 0.7746\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4803 - accuracy: 0.7746\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5023 - accuracy: 0.7887\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4941 - accuracy: 0.7606\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4726 - accuracy: 0.7887\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.4922 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4515 - accuracy: 0.8169\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.4451 - accuracy: 0.8451\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4989 - accuracy: 0.7887\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4711 - accuracy: 0.7887\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.4488 - accuracy: 0.7746\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4722 - accuracy: 0.7606\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4657 - accuracy: 0.7887\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5217 - accuracy: 0.7887\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4499 - accuracy: 0.8451\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4838 - accuracy: 0.7746\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5196 - accuracy: 0.7606\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5094 - accuracy: 0.7465\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4707 - accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4609 - accuracy: 0.8310\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4680 - accuracy: 0.8310\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4835 - accuracy: 0.8028\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4399 - accuracy: 0.8310\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.9638 - accuracy: 0.4444\n",
      "--- Starting trial: run-17\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 0.8573 - accuracy: 0.5775\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7672 - accuracy: 0.5634\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7106 - accuracy: 0.6197\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6872 - accuracy: 0.5915\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6621 - accuracy: 0.6338\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6400 - accuracy: 0.6338\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6547 - accuracy: 0.6620\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6965 - accuracy: 0.6338\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5994 - accuracy: 0.6901\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6907 - accuracy: 0.6479\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6502 - accuracy: 0.6338\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6720 - accuracy: 0.6620\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6440 - accuracy: 0.6620\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6413 - accuracy: 0.6620\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6428 - accuracy: 0.6620\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6637 - accuracy: 0.6620\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6206 - accuracy: 0.6620\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6212 - accuracy: 0.6620\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6606 - accuracy: 0.6620\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6527 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6328 - accuracy: 0.6620\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6236 - accuracy: 0.6620\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6338 - accuracy: 0.6620\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6392 - accuracy: 0.6620\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6345 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6108 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6307 - accuracy: 0.6620\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6114 - accuracy: 0.6620\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6292 - accuracy: 0.6620\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6579 - accuracy: 0.6620\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6465 - accuracy: 0.6620\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6258 - accuracy: 0.6620\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6164 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6234 - accuracy: 0.6620\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6031 - accuracy: 0.6761\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6476 - accuracy: 0.6620\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6367 - accuracy: 0.6620\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6122 - accuracy: 0.6620\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6093 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6063 - accuracy: 0.6620\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6236 - accuracy: 0.6620\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6047 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5914 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5931 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5801 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6208 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5924 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6120 - accuracy: 0.6479\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6407 - accuracy: 0.6761\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6369 - accuracy: 0.6620\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6056 - accuracy: 0.7042\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6268 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6053 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6056 - accuracy: 0.6761\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6134 - accuracy: 0.6761\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6070 - accuracy: 0.6761\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6008 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6047 - accuracy: 0.6761\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5825 - accuracy: 0.6620\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5974 - accuracy: 0.6761\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5907 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6019 - accuracy: 0.6620\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5947 - accuracy: 0.6901\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5956 - accuracy: 0.6901\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5857 - accuracy: 0.6901\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6050 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6204 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6131 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5964 - accuracy: 0.6901\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5849 - accuracy: 0.6901\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6102 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5794 - accuracy: 0.6901\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5793 - accuracy: 0.6901\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5824 - accuracy: 0.7183\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5909 - accuracy: 0.6901\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6220 - accuracy: 0.7042\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6178 - accuracy: 0.6620\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6042 - accuracy: 0.6761\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5784 - accuracy: 0.7465\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5896 - accuracy: 0.7465\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5744 - accuracy: 0.6901\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6126 - accuracy: 0.6620\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5799 - accuracy: 0.6901\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.5857 - accuracy: 0.6901\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5909 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5634 - accuracy: 0.7183\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5996 - accuracy: 0.6901\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5904 - accuracy: 0.6901\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6048 - accuracy: 0.7042\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5991 - accuracy: 0.7042\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5934 - accuracy: 0.6901\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6078 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6197 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5909 - accuracy: 0.7042\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5875 - accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5859 - accuracy: 0.6901\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6385 - accuracy: 0.6620\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5713 - accuracy: 0.7042\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5884 - accuracy: 0.7042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5794 - accuracy: 0.7042\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8017 - accuracy: 0.5556\n",
      "--- Starting trial: run-18\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 3.8340 - accuracy: 0.3803\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.4909 - accuracy: 0.4085\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.9286 - accuracy: 0.3662\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.7579 - accuracy: 0.4930\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.9391 - accuracy: 0.4789\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.9921 - accuracy: 0.4366\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 2.7771 - accuracy: 0.4648\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.6054 - accuracy: 0.3380\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.1938 - accuracy: 0.4085\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.2698 - accuracy: 0.3662\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 2.7882 - accuracy: 0.4225\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.3259 - accuracy: 0.4930\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.3524 - accuracy: 0.5634\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.9039 - accuracy: 0.4366\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.5163 - accuracy: 0.5211\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.6745 - accuracy: 0.4789\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.7793 - accuracy: 0.5493\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.6915 - accuracy: 0.4930\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.9903 - accuracy: 0.5211\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.5251 - accuracy: 0.4930\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.1411 - accuracy: 0.4085\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 2.2072 - accuracy: 0.4507\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.7389 - accuracy: 0.4789\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.8300 - accuracy: 0.5211\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.7892 - accuracy: 0.4930\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.5177 - accuracy: 0.5211\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.9160 - accuracy: 0.4789\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.8538 - accuracy: 0.4507\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.5509 - accuracy: 0.4648\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.6908 - accuracy: 0.5211\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.7849 - accuracy: 0.4225\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0527 - accuracy: 0.5211\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1624 - accuracy: 0.4648\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.6723 - accuracy: 0.4648\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.4272 - accuracy: 0.5070\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.3466 - accuracy: 0.5070\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.4166 - accuracy: 0.5211\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9385 - accuracy: 0.5775\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.4040 - accuracy: 0.5352\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1765 - accuracy: 0.4648\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0934 - accuracy: 0.4507\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0369 - accuracy: 0.4930\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.2837 - accuracy: 0.5211\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1426 - accuracy: 0.5211\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8842 - accuracy: 0.5070\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0875 - accuracy: 0.4930\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9605 - accuracy: 0.5211\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9229 - accuracy: 0.5352\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1795 - accuracy: 0.5070\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0348 - accuracy: 0.5211\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8511 - accuracy: 0.5070\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0692 - accuracy: 0.5352\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9858 - accuracy: 0.4507\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8505 - accuracy: 0.5211\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9341 - accuracy: 0.5352\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0858 - accuracy: 0.4507\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7918 - accuracy: 0.5352\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7433 - accuracy: 0.5915\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9506 - accuracy: 0.5915\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8600 - accuracy: 0.6338\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7303 - accuracy: 0.6338\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.71 - 0s 66us/sample - loss: 0.8899 - accuracy: 0.5634\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7065 - accuracy: 0.6056\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8247 - accuracy: 0.5775\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6748 - accuracy: 0.6620\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7586 - accuracy: 0.6338\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7917 - accuracy: 0.6197\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8428 - accuracy: 0.5352\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6776 - accuracy: 0.6479\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6699 - accuracy: 0.6338\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7934 - accuracy: 0.5775\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6644 - accuracy: 0.6620\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7582 - accuracy: 0.5775\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6905 - accuracy: 0.6479\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7380 - accuracy: 0.5493\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6817 - accuracy: 0.5915\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7063 - accuracy: 0.6056\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6502 - accuracy: 0.5915\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6924 - accuracy: 0.6479\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7744 - accuracy: 0.6197\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6326 - accuracy: 0.6620\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6712 - accuracy: 0.6197\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6452 - accuracy: 0.6197\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6422 - accuracy: 0.6197\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6786 - accuracy: 0.6197\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6696 - accuracy: 0.5915\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6069 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6102 - accuracy: 0.6620\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6331 - accuracy: 0.7042\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7026 - accuracy: 0.6197\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6843 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6817 - accuracy: 0.5634\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5913 - accuracy: 0.6479\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5920 - accuracy: 0.6761\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6106 - accuracy: 0.6338\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6168 - accuracy: 0.6338\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6902 - accuracy: 0.6056\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6135 - accuracy: 0.6479\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 94us/sample - loss: 0.5791 - accuracy: 0.7042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6563 - accuracy: 0.5915\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.9480 - accuracy: 0.6111\n",
      "--- Starting trial: run-19\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.3978 - accuracy: 0.4085\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.7570 - accuracy: 0.5070\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.9795 - accuracy: 0.4789\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.2257 - accuracy: 0.4085\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.0553 - accuracy: 0.4507\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2714 - accuracy: 0.5775\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5983 - accuracy: 0.4789\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.9748 - accuracy: 0.4930\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.6202 - accuracy: 0.4930\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.8112 - accuracy: 0.4930\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5543 - accuracy: 0.4507\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.3179 - accuracy: 0.4930\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.6621 - accuracy: 0.4507\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5912 - accuracy: 0.5211\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8878 - accuracy: 0.6338\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.2781 - accuracy: 0.5211\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3745 - accuracy: 0.5211\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.3677 - accuracy: 0.5775\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2636 - accuracy: 0.4507\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1388 - accuracy: 0.6056\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2261 - accuracy: 0.5493\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.9470 - accuracy: 0.5634\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1705 - accuracy: 0.5070\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1045 - accuracy: 0.5070\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1583 - accuracy: 0.5352\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9677 - accuracy: 0.6338\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0882 - accuracy: 0.5634\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0603 - accuracy: 0.5775\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9009 - accuracy: 0.5915\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9825 - accuracy: 0.5634\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0995 - accuracy: 0.5352\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 105us/sample - loss: 0.8526 - accuracy: 0.5775\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6418 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7336 - accuracy: 0.6338\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7707 - accuracy: 0.6197\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9200 - accuracy: 0.5915\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8177 - accuracy: 0.6338\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.1207 - accuracy: 0.5352\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6809 - accuracy: 0.6901\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9137 - accuracy: 0.6338\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7369 - accuracy: 0.6479\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6512 - accuracy: 0.6761\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6759 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7405 - accuracy: 0.6761\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8277 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8622 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6927 - accuracy: 0.7042\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7729 - accuracy: 0.6338\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6409 - accuracy: 0.7042\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6437 - accuracy: 0.6901\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8016 - accuracy: 0.6197\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0356 - accuracy: 0.6197\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7801 - accuracy: 0.6338\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8747 - accuracy: 0.6197\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7165 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6960 - accuracy: 0.7746\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7338 - accuracy: 0.6479\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6322 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7462 - accuracy: 0.6338\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5523 - accuracy: 0.7183\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9735 - accuracy: 0.5915\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8029 - accuracy: 0.5915\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5973 - accuracy: 0.6479\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6963 - accuracy: 0.6479\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0186 - accuracy: 0.6056\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7803 - accuracy: 0.6479\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6434 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6790 - accuracy: 0.6761\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7588 - accuracy: 0.5915\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8335 - accuracy: 0.5915\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6880 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9046 - accuracy: 0.6338\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7279 - accuracy: 0.5915\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7355 - accuracy: 0.6479\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.7347 - accuracy: 0.6620\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7762 - accuracy: 0.6056\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7958 - accuracy: 0.6338\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7640 - accuracy: 0.5493\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6335 - accuracy: 0.6901\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6815 - accuracy: 0.6479\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7713 - accuracy: 0.6479\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6770 - accuracy: 0.7183\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.6551 - accuracy: 0.6479\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6003 - accuracy: 0.7042\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6698 - accuracy: 0.6338\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6414 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6874 - accuracy: 0.7042\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6992 - accuracy: 0.6901\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6974 - accuracy: 0.6761\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6313 - accuracy: 0.7042\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6671 - accuracy: 0.6197\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6862 - accuracy: 0.7183\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6511 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5950 - accuracy: 0.6479\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7381 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.5163 - accuracy: 0.7606\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6970 - accuracy: 0.6620\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7495 - accuracy: 0.6761\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6493 - accuracy: 0.6197\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6532 - accuracy: 0.6620\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.0002 - accuracy: 0.5556\n",
      "--- Starting trial: run-20\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.8716 - accuracy: 0.4225\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.2776 - accuracy: 0.5211\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0448 - accuracy: 0.5634\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.8889 - accuracy: 0.4648\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8446 - accuracy: 0.4789\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7077 - accuracy: 0.5211\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.6990 - accuracy: 0.5634\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7258 - accuracy: 0.5493\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.7257 - accuracy: 0.5211\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6882 - accuracy: 0.6197\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6622 - accuracy: 0.6338\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7049 - accuracy: 0.5634\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7578 - accuracy: 0.6338\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7482 - accuracy: 0.6901\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6817 - accuracy: 0.7042\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6818 - accuracy: 0.6620\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7305 - accuracy: 0.6620\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6727 - accuracy: 0.6197\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6563 - accuracy: 0.6761\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6917 - accuracy: 0.6479\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6869 - accuracy: 0.6620\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6855 - accuracy: 0.6197\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6410 - accuracy: 0.6761\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6624 - accuracy: 0.6620\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7135 - accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6380 - accuracy: 0.6479\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6956 - accuracy: 0.6338\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6864 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7005 - accuracy: 0.6761\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6649 - accuracy: 0.6479\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6929 - accuracy: 0.6620\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6360 - accuracy: 0.6479\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6565 - accuracy: 0.6620\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6872 - accuracy: 0.6620\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6877 - accuracy: 0.6338\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6545 - accuracy: 0.6761\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6674 - accuracy: 0.6620\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6882 - accuracy: 0.6479\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6782 - accuracy: 0.6761\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6785 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6791 - accuracy: 0.6620\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6618 - accuracy: 0.6479\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6785 - accuracy: 0.6197\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6579 - accuracy: 0.6338\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6457 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6330 - accuracy: 0.6761\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6618 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6657 - accuracy: 0.6479\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6555 - accuracy: 0.6479\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6528 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6258 - accuracy: 0.6761\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6644 - accuracy: 0.6338\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6519 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6448 - accuracy: 0.6761\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6514 - accuracy: 0.7042\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6282 - accuracy: 0.7183\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6434 - accuracy: 0.7042\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6036 - accuracy: 0.6901\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6272 - accuracy: 0.6901\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6404 - accuracy: 0.6761\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6286 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.6638 - accuracy: 0.6901\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6514 - accuracy: 0.6479\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6505 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6453 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6351 - accuracy: 0.6620\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6486 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6499 - accuracy: 0.6761\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6529 - accuracy: 0.6761\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6415 - accuracy: 0.6761\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6453 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6357 - accuracy: 0.7042\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6260 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6491 - accuracy: 0.6620\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6522 - accuracy: 0.6761\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6677 - accuracy: 0.6620\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6590 - accuracy: 0.6479\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6265 - accuracy: 0.6901\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6561 - accuracy: 0.6761\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6523 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6576 - accuracy: 0.6479\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6245 - accuracy: 0.6620\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6393 - accuracy: 0.6620\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6366 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6324 - accuracy: 0.6901\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6447 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6205 - accuracy: 0.6761\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6318 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6603 - accuracy: 0.6620\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6080 - accuracy: 0.6901\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6488 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6255 - accuracy: 0.6761\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6107 - accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6391 - accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6241 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6311 - accuracy: 0.6620\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6319 - accuracy: 0.6901\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6331 - accuracy: 0.6620\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.6406 - accuracy: 0.6761\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6406 - accuracy: 0.6620\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.6786 - accuracy: 0.5556\n",
      "--- Starting trial: run-21\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 0.8347 - accuracy: 0.6761\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0822 - accuracy: 0.5352\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1303 - accuracy: 0.5634\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.0882 - accuracy: 0.6338\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0319 - accuracy: 0.5915\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 0.7123 - accuracy: 0.6197\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.1329 - accuracy: 0.5634\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.0472 - accuracy: 0.6338\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8510 - accuracy: 0.5915\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9239 - accuracy: 0.5915\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0026 - accuracy: 0.5493\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7639 - accuracy: 0.6620\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9887 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7715 - accuracy: 0.5775\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9243 - accuracy: 0.6338\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8215 - accuracy: 0.6761\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9327 - accuracy: 0.5775\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8406 - accuracy: 0.5493\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.8182 - accuracy: 0.6197\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7236 - accuracy: 0.6197\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8889 - accuracy: 0.6761\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8372 - accuracy: 0.7042\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8812 - accuracy: 0.6197\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6843 - accuracy: 0.6338\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6824 - accuracy: 0.6761\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8485 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8558 - accuracy: 0.6197\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7445 - accuracy: 0.6901\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6923 - accuracy: 0.7324\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7045 - accuracy: 0.6338\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7381 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6907 - accuracy: 0.6338\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7010 - accuracy: 0.6620\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7799 - accuracy: 0.7183\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6942 - accuracy: 0.6338\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6696 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6299 - accuracy: 0.6479\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7797 - accuracy: 0.6338\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7268 - accuracy: 0.6479\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7516 - accuracy: 0.6338\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6288 - accuracy: 0.6197\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7025 - accuracy: 0.6197\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6653 - accuracy: 0.6338\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.6643 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6520 - accuracy: 0.6338\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7504 - accuracy: 0.5352\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7061 - accuracy: 0.7042\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6743 - accuracy: 0.6761\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7146 - accuracy: 0.6197\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6454 - accuracy: 0.6620\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6437 - accuracy: 0.6620\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5896 - accuracy: 0.6761\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6576 - accuracy: 0.6056\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6830 - accuracy: 0.6479\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6483 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6670 - accuracy: 0.6761\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6615 - accuracy: 0.6761\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6557 - accuracy: 0.6056\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6951 - accuracy: 0.5915\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6506 - accuracy: 0.5915\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5979 - accuracy: 0.7042\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6467 - accuracy: 0.5775\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5795 - accuracy: 0.6761\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5929 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5978 - accuracy: 0.6620\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6462 - accuracy: 0.6056\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6415 - accuracy: 0.6338\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6140 - accuracy: 0.6761\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6235 - accuracy: 0.6620\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6266 - accuracy: 0.6761\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6016 - accuracy: 0.6197\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6192 - accuracy: 0.6197\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5641 - accuracy: 0.6901\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6037 - accuracy: 0.6620\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5942 - accuracy: 0.6901\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6088 - accuracy: 0.6620\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6402 - accuracy: 0.5775\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5564 - accuracy: 0.7042\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6347 - accuracy: 0.6620\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5998 - accuracy: 0.6620\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5732 - accuracy: 0.6761\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6281 - accuracy: 0.6479\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5946 - accuracy: 0.6620\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5824 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5438 - accuracy: 0.7183\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5938 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5088 - accuracy: 0.7465\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5866 - accuracy: 0.7042\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5610 - accuracy: 0.6761\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5561 - accuracy: 0.7183\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6327 - accuracy: 0.5915\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5598 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5477 - accuracy: 0.7606\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6333 - accuracy: 0.6056\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5799 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5652 - accuracy: 0.6338\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5219 - accuracy: 0.7042\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5625 - accuracy: 0.6620\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5593 - accuracy: 0.6901\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5730 - accuracy: 0.7042\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.0564 - accuracy: 0.5556\n",
      "--- Starting trial: run-22\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 4.0661 - accuracy: 0.4507\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 4.1020 - accuracy: 0.4507\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 4.1026 - accuracy: 0.4648\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 3.4272 - accuracy: 0.5634\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.2145 - accuracy: 0.4789\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 3.2937 - accuracy: 0.4507\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.5854 - accuracy: 0.5211\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 3.6084 - accuracy: 0.4789\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 4.1803 - accuracy: 0.4789\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 3.5765 - accuracy: 0.4366\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 2.9457 - accuracy: 0.5070\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 3.1388 - accuracy: 0.4789\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 3.5085 - accuracy: 0.4648\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.3316 - accuracy: 0.4648\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.9202 - accuracy: 0.5070\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.4248 - accuracy: 0.5211\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.4088 - accuracy: 0.5352\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.8066 - accuracy: 0.4930\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.8561 - accuracy: 0.4930\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.1596 - accuracy: 0.5211\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.7611 - accuracy: 0.4930\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.6429 - accuracy: 0.5352\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.6734 - accuracy: 0.5352\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.1271 - accuracy: 0.4648\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.2752 - accuracy: 0.5775\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.6140 - accuracy: 0.5775\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 2.1711 - accuracy: 0.4930\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.4478 - accuracy: 0.5352\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.2683 - accuracy: 0.4648\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 2.1123 - accuracy: 0.5211\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.3861 - accuracy: 0.5070\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.0090 - accuracy: 0.5352\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.9105 - accuracy: 0.5352\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.1255 - accuracy: 0.5211\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.7221 - accuracy: 0.5634\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.6654 - accuracy: 0.5070\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5674 - accuracy: 0.6338\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.8613 - accuracy: 0.5493\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 2.2198 - accuracy: 0.5211\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9695 - accuracy: 0.6901\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.8607 - accuracy: 0.5352\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.0566 - accuracy: 0.5352\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.5490 - accuracy: 0.5493\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.1760 - accuracy: 0.5352\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5152 - accuracy: 0.5915\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.8290 - accuracy: 0.5634\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 63us/sample - loss: 1.6488 - accuracy: 0.5634\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.7578 - accuracy: 0.5634\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.5075 - accuracy: 0.5070\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.5562 - accuracy: 0.5493\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.7129 - accuracy: 0.5493\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.8779 - accuracy: 0.5493\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.7874 - accuracy: 0.5352\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2669 - accuracy: 0.6338\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.4619 - accuracy: 0.5493\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.4968 - accuracy: 0.5775\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.6517 - accuracy: 0.5352\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.5515 - accuracy: 0.5775\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.4380 - accuracy: 0.6338\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.6291 - accuracy: 0.5775\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.2900 - accuracy: 0.5493\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3856 - accuracy: 0.5775\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3439 - accuracy: 0.5634\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.2123 - accuracy: 0.5775\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.4262 - accuracy: 0.5070\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1604 - accuracy: 0.5634\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6320 - accuracy: 0.5070\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2715 - accuracy: 0.5775\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2082 - accuracy: 0.6056\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2638 - accuracy: 0.6338\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.3472 - accuracy: 0.5493\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2455 - accuracy: 0.5775\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1413 - accuracy: 0.5775\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0849 - accuracy: 0.6197\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.2487 - accuracy: 0.5775\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.4362 - accuracy: 0.5493\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.2594 - accuracy: 0.5493\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.0875 - accuracy: 0.5493\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.2022 - accuracy: 0.5352\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.3504 - accuracy: 0.5775\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1477 - accuracy: 0.5634\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.8992 - accuracy: 0.6197\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.9744 - accuracy: 0.62 - 0s 64us/sample - loss: 1.0921 - accuracy: 0.6056\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0570 - accuracy: 0.5915\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0665 - accuracy: 0.5775\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1116 - accuracy: 0.5775\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1267 - accuracy: 0.5915\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0064 - accuracy: 0.5775\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.0207 - accuracy: 0.6056\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.0310 - accuracy: 0.5915\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.1021 - accuracy: 0.6056\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9299 - accuracy: 0.5915\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.0314 - accuracy: 0.6056\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 1.0011 - accuracy: 0.5775\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1887 - accuracy: 0.5493\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1533 - accuracy: 0.5775\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0660 - accuracy: 0.5493\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8658 - accuracy: 0.6338\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.1018 - accuracy: 0.6197\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9147 - accuracy: 0.5634\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 2.8170 - accuracy: 0.4444\n",
      "--- Starting trial: run-23\n",
      "{'num_units 1': 4, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.2258 - accuracy: 0.3662\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.8124 - accuracy: 0.3944\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 1.7432 - accuracy: 0.3380\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5652 - accuracy: 0.4085\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.3166 - accuracy: 0.4225\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0454 - accuracy: 0.3944\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9533 - accuracy: 0.3239\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8908 - accuracy: 0.3380\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7757 - accuracy: 0.4930\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7870 - accuracy: 0.5070\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7024 - accuracy: 0.6056\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7689 - accuracy: 0.4930\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7331 - accuracy: 0.5493\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7224 - accuracy: 0.5775\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7195 - accuracy: 0.5070\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6504 - accuracy: 0.6056\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6841 - accuracy: 0.6479\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6693 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6331 - accuracy: 0.7042\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6779 - accuracy: 0.6338\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6196 - accuracy: 0.7465\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6307 - accuracy: 0.6479\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6883 - accuracy: 0.5915\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6406 - accuracy: 0.7042\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6500 - accuracy: 0.6761\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6458 - accuracy: 0.6479\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6315 - accuracy: 0.6479\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6198 - accuracy: 0.6620\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6204 - accuracy: 0.6479\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6049 - accuracy: 0.7042\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6168 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5938 - accuracy: 0.7042\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6155 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6714 - accuracy: 0.7042\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6163 - accuracy: 0.6338\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6346 - accuracy: 0.6620\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6213 - accuracy: 0.6901\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6573 - accuracy: 0.6620\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6534 - accuracy: 0.6761\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5962 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6760 - accuracy: 0.6479\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6255 - accuracy: 0.6761\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6276 - accuracy: 0.6901\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6091 - accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6326 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.6131 - accuracy: 0.6761\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6410 - accuracy: 0.6620\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6198 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5987 - accuracy: 0.6761\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6354 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6397 - accuracy: 0.6620\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6210 - accuracy: 0.6761\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6209 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6034 - accuracy: 0.6761\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6380 - accuracy: 0.6901\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6089 - accuracy: 0.6620\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6257 - accuracy: 0.6761\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6060 - accuracy: 0.6761\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5953 - accuracy: 0.7042\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5814 - accuracy: 0.6761\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5934 - accuracy: 0.6761\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6328 - accuracy: 0.6620\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6248 - accuracy: 0.6620\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6139 - accuracy: 0.6761\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6041 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6269 - accuracy: 0.6761\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6217 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5875 - accuracy: 0.6620\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5844 - accuracy: 0.6620\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6257 - accuracy: 0.6620\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6038 - accuracy: 0.6620\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6409 - accuracy: 0.6620\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6128 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5833 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5526 - accuracy: 0.6901\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.6222 - accuracy: 0.6620\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 56us/sample - loss: 0.6309 - accuracy: 0.6761\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.5830 - accuracy: 0.6901\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.6216 - accuracy: 0.6620\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 0.5930 - accuracy: 0.6901\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5908 - accuracy: 0.6761\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6190 - accuracy: 0.6901\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6016 - accuracy: 0.7042\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6138 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5863 - accuracy: 0.6761\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6076 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5757 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6102 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6154 - accuracy: 0.6620\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6420 - accuracy: 0.6761\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6032 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6172 - accuracy: 0.6761\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6103 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5927 - accuracy: 0.6761\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6164 - accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5694 - accuracy: 0.7042\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5625 - accuracy: 0.6479\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5679 - accuracy: 0.6901\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5903 - accuracy: 0.6761\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.6039 - accuracy: 0.6761\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8328 - accuracy: 0.6111\n",
      "--- Starting trial: run-24\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 8ms/sample - loss: 2.1864 - accuracy: 0.3944\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.9860 - accuracy: 0.3803\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6529 - accuracy: 0.4789\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.8353 - accuracy: 0.4366\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.7514 - accuracy: 0.5070\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.6568 - accuracy: 0.4789\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.5003 - accuracy: 0.5070\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.5884 - accuracy: 0.4789\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.4994 - accuracy: 0.5211\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.3914 - accuracy: 0.5211\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.4240 - accuracy: 0.5070\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.3598 - accuracy: 0.4930\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.3705 - accuracy: 0.5070\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.2411 - accuracy: 0.5352\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.4681 - accuracy: 0.5070\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1814 - accuracy: 0.5634\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.3281 - accuracy: 0.5211\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2679 - accuracy: 0.5352\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1983 - accuracy: 0.5352\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9827 - accuracy: 0.5775\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1263 - accuracy: 0.5634\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0742 - accuracy: 0.5634\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0890 - accuracy: 0.5775\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0191 - accuracy: 0.5775\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1389 - accuracy: 0.5070\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.1411 - accuracy: 0.5211\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9394 - accuracy: 0.6197\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9165 - accuracy: 0.5915\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0215 - accuracy: 0.5493\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9618 - accuracy: 0.6197\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9996 - accuracy: 0.5634\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9763 - accuracy: 0.5634\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9809 - accuracy: 0.5352\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9557 - accuracy: 0.5211\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8490 - accuracy: 0.6056\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8265 - accuracy: 0.6056\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8893 - accuracy: 0.6479\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8657 - accuracy: 0.5493\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8501 - accuracy: 0.5915\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8451 - accuracy: 0.6197\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7684 - accuracy: 0.6479\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7695 - accuracy: 0.6479\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7772 - accuracy: 0.6056\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7142 - accuracy: 0.6901\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8144 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8030 - accuracy: 0.5915\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7179 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6903 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7765 - accuracy: 0.6056\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7502 - accuracy: 0.6620\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6775 - accuracy: 0.7042\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6489 - accuracy: 0.6901\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7219 - accuracy: 0.6056\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7210 - accuracy: 0.6761\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7374 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6210 - accuracy: 0.7042\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6863 - accuracy: 0.7042\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5878 - accuracy: 0.7606\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6320 - accuracy: 0.7042\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6336 - accuracy: 0.7042\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6719 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6891 - accuracy: 0.7042\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6161 - accuracy: 0.7042\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6652 - accuracy: 0.6901\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6496 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5977 - accuracy: 0.7465\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5693 - accuracy: 0.7324\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6468 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6606 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6119 - accuracy: 0.7183\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7011 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6055 - accuracy: 0.6761\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6064 - accuracy: 0.7324\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6372 - accuracy: 0.7042\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6363 - accuracy: 0.6761\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5498 - accuracy: 0.8028\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5782 - accuracy: 0.7606\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5746 - accuracy: 0.7465\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5239 - accuracy: 0.7746\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5363 - accuracy: 0.7465\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5902 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5520 - accuracy: 0.7887\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5508 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5523 - accuracy: 0.7606\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5525 - accuracy: 0.7606\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4934 - accuracy: 0.8028\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6142 - accuracy: 0.7324\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5649 - accuracy: 0.7042\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5389 - accuracy: 0.7606\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6753 - accuracy: 0.6761\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5822 - accuracy: 0.7324\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5109 - accuracy: 0.7887\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5366 - accuracy: 0.7465\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5458 - accuracy: 0.7746\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5430 - accuracy: 0.7746\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5237 - accuracy: 0.7606\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5765 - accuracy: 0.7606\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5053 - accuracy: 0.8028\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4636 - accuracy: 0.8169\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5141 - accuracy: 0.7606\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.0589 - accuracy: 0.4444\n",
      "--- Starting trial: run-25\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 3.3835 - accuracy: 0.3380\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 3.1581 - accuracy: 0.3380\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 2.8880 - accuracy: 0.3380\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.9704 - accuracy: 0.3521\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 3.0172 - accuracy: 0.3239\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 3.0674 - accuracy: 0.3239\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.4414 - accuracy: 0.3662\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 2.6735 - accuracy: 0.3662\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 2.5117 - accuracy: 0.3662\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.4257 - accuracy: 0.3803\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.5229 - accuracy: 0.3521\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 2.3593 - accuracy: 0.3662\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.5291 - accuracy: 0.3521\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.6556 - accuracy: 0.3380\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.2840 - accuracy: 0.3521\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.9884 - accuracy: 0.3662\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.0593 - accuracy: 0.3521\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.9750 - accuracy: 0.3521\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.0910 - accuracy: 0.3521\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.0643 - accuracy: 0.3662\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.8834 - accuracy: 0.3803\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.9647 - accuracy: 0.3803\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.7776 - accuracy: 0.3662\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.7750 - accuracy: 0.4085\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.6442 - accuracy: 0.3803\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.7201 - accuracy: 0.3944\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.5677 - accuracy: 0.4366\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.5345 - accuracy: 0.4507\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6959 - accuracy: 0.4648\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6657 - accuracy: 0.4648\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5398 - accuracy: 0.4085\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1886 - accuracy: 0.4648\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3400 - accuracy: 0.4507\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.4185 - accuracy: 0.4648\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.6540 - accuracy: 0.4225\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.3186 - accuracy: 0.4648\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1594 - accuracy: 0.5070\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2366 - accuracy: 0.4930\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.1953 - accuracy: 0.5352\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1559 - accuracy: 0.4930\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1222 - accuracy: 0.5352\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0851 - accuracy: 0.4930\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0868 - accuracy: 0.4648\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9832 - accuracy: 0.5211\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0598 - accuracy: 0.4507\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0629 - accuracy: 0.5070\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0201 - accuracy: 0.5070\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.3316 - accuracy: 0.5211\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0640 - accuracy: 0.5070\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9934 - accuracy: 0.5352\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9125 - accuracy: 0.5352\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0264 - accuracy: 0.5070\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9709 - accuracy: 0.4930\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9919 - accuracy: 0.5493\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9816 - accuracy: 0.5915\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8558 - accuracy: 0.5775\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9681 - accuracy: 0.5493\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9285 - accuracy: 0.5634\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9354 - accuracy: 0.5775\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8690 - accuracy: 0.5915\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9082 - accuracy: 0.4507\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 104us/sample - loss: 0.9092 - accuracy: 0.5634\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.9958 - accuracy: 0.5352\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8616 - accuracy: 0.5352\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8494 - accuracy: 0.5352\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9474 - accuracy: 0.5634\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.9109 - accuracy: 0.5634\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8829 - accuracy: 0.5211\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8456 - accuracy: 0.6056\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7841 - accuracy: 0.6056\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7783 - accuracy: 0.5915\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8589 - accuracy: 0.5915\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9170 - accuracy: 0.5915\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0113 - accuracy: 0.5211\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8199 - accuracy: 0.6197\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7619 - accuracy: 0.6197\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8260 - accuracy: 0.5915\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8101 - accuracy: 0.5352\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7392 - accuracy: 0.6479\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.7740 - accuracy: 0.6479\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7750 - accuracy: 0.6056\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9769 - accuracy: 0.6338\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7408 - accuracy: 0.6338\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7601 - accuracy: 0.6479\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7226 - accuracy: 0.6901\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7216 - accuracy: 0.6479\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7505 - accuracy: 0.6479\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.8049 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7087 - accuracy: 0.6901\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8598 - accuracy: 0.6056\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7895 - accuracy: 0.5775\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7053 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7333 - accuracy: 0.6197\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7321 - accuracy: 0.6479\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7627 - accuracy: 0.6056\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8671 - accuracy: 0.5493\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6847 - accuracy: 0.6620\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6721 - accuracy: 0.6761\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6761 - accuracy: 0.6761\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7778 - accuracy: 0.7324\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.3126 - accuracy: 0.5000\n",
      "--- Starting trial: run-26\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 5.6029 - accuracy: 0.3944\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 3.2897 - accuracy: 0.4366\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.3058 - accuracy: 0.4648\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 1.8311 - accuracy: 0.4507\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.6180 - accuracy: 0.4789\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.3583 - accuracy: 0.4789\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.1888 - accuracy: 0.4789\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.0863 - accuracy: 0.4789\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9782 - accuracy: 0.4930\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.9309 - accuracy: 0.4507\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8696 - accuracy: 0.5493\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8271 - accuracy: 0.6056\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8728 - accuracy: 0.5070\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7708 - accuracy: 0.5915\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7817 - accuracy: 0.5915\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8376 - accuracy: 0.5775\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7827 - accuracy: 0.5634\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7999 - accuracy: 0.5493\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7300 - accuracy: 0.5915\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7223 - accuracy: 0.5775\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7591 - accuracy: 0.6056\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7147 - accuracy: 0.6620\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7446 - accuracy: 0.5915\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7180 - accuracy: 0.6197\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7208 - accuracy: 0.5915\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7140 - accuracy: 0.6338\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7269 - accuracy: 0.5775\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7072 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6803 - accuracy: 0.6479\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6860 - accuracy: 0.6056\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6848 - accuracy: 0.6479\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6873 - accuracy: 0.6197\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6972 - accuracy: 0.5775\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7025 - accuracy: 0.5775\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6852 - accuracy: 0.6056\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6634 - accuracy: 0.6620\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6744 - accuracy: 0.5915\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6686 - accuracy: 0.6338\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6691 - accuracy: 0.6197\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6742 - accuracy: 0.6197\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6844 - accuracy: 0.6197\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6694 - accuracy: 0.6056\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6826 - accuracy: 0.5634\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6683 - accuracy: 0.6197\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6567 - accuracy: 0.6761\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6612 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6678 - accuracy: 0.6479\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6681 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6599 - accuracy: 0.6479\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6793 - accuracy: 0.6197\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6771 - accuracy: 0.6338\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6541 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6489 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6678 - accuracy: 0.6901\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6609 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6614 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6587 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6536 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6567 - accuracy: 0.6479\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6540 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6564 - accuracy: 0.6479\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6594 - accuracy: 0.6479\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.6447 - accuracy: 0.6901\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6434 - accuracy: 0.6761\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6437 - accuracy: 0.6901\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6665 - accuracy: 0.6620\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6602 - accuracy: 0.6479\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6526 - accuracy: 0.6620\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6488 - accuracy: 0.6901\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6490 - accuracy: 0.6620\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.6377 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6476 - accuracy: 0.6197\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6547 - accuracy: 0.6479\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6434 - accuracy: 0.6761\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6459 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6355 - accuracy: 0.7324\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6454 - accuracy: 0.7042\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6390 - accuracy: 0.6761\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6367 - accuracy: 0.7042\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6346 - accuracy: 0.7183\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6323 - accuracy: 0.7042\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6228 - accuracy: 0.7465\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6360 - accuracy: 0.6620\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6359 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6429 - accuracy: 0.6761\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6448 - accuracy: 0.6479\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6409 - accuracy: 0.6620\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6356 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6383 - accuracy: 0.6901\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6209 - accuracy: 0.7324\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6328 - accuracy: 0.7183\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6319 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6312 - accuracy: 0.7465\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6106 - accuracy: 0.7606\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6303 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6286 - accuracy: 0.7324\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6191 - accuracy: 0.7324\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6276 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6265 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6289 - accuracy: 0.7183\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8367 - accuracy: 0.4444\n",
      "--- Starting trial: run-27\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.5881 - accuracy: 0.4930\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.4833 - accuracy: 0.4930\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.4988 - accuracy: 0.5070\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.3114 - accuracy: 0.5211\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3208 - accuracy: 0.5211\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.3567 - accuracy: 0.4930\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2714 - accuracy: 0.5634\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2968 - accuracy: 0.5493\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2315 - accuracy: 0.5352\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0981 - accuracy: 0.5352\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2460 - accuracy: 0.5211\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1092 - accuracy: 0.5634\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0652 - accuracy: 0.5352\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0411 - accuracy: 0.5493\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2606 - accuracy: 0.5211\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1075 - accuracy: 0.5352\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0267 - accuracy: 0.5352\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 103us/sample - loss: 1.0505 - accuracy: 0.5211\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8751 - accuracy: 0.5352\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9000 - accuracy: 0.4930\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9413 - accuracy: 0.5493\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.9478 - accuracy: 0.5634\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9048 - accuracy: 0.4648\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9589 - accuracy: 0.4930\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8382 - accuracy: 0.4930\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.9323 - accuracy: 0.4789\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.8289 - accuracy: 0.5070\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7726 - accuracy: 0.5775\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8811 - accuracy: 0.5070\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8447 - accuracy: 0.5352\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.8257 - accuracy: 0.4930\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9032 - accuracy: 0.4930\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8911 - accuracy: 0.4789\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7868 - accuracy: 0.5634\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8565 - accuracy: 0.4930\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7828 - accuracy: 0.5211\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7921 - accuracy: 0.6056\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.7615 - accuracy: 0.6761\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8276 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7507 - accuracy: 0.6479\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6758 - accuracy: 0.6901\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7428 - accuracy: 0.6197\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7844 - accuracy: 0.6479\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7533 - accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8140 - accuracy: 0.5775\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7492 - accuracy: 0.6338\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7434 - accuracy: 0.6479\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6784 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6319 - accuracy: 0.6620\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7729 - accuracy: 0.6197\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7005 - accuracy: 0.6761\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6676 - accuracy: 0.6761\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6087 - accuracy: 0.6479\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6554 - accuracy: 0.6620\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6048 - accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6383 - accuracy: 0.7042\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6150 - accuracy: 0.6901\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6253 - accuracy: 0.6761\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6631 - accuracy: 0.6479\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6920 - accuracy: 0.5775\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5405 - accuracy: 0.7183\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5309 - accuracy: 0.7042\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5975 - accuracy: 0.7324\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5581 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5267 - accuracy: 0.7042\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5855 - accuracy: 0.7324\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5945 - accuracy: 0.6901\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5658 - accuracy: 0.7042\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5266 - accuracy: 0.6761\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5780 - accuracy: 0.6620\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5433 - accuracy: 0.7183\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5738 - accuracy: 0.7324\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5852 - accuracy: 0.6479\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.4510 - accuracy: 0.7324\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.4929 - accuracy: 0.7324\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5685 - accuracy: 0.7042\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5178 - accuracy: 0.7183\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5285 - accuracy: 0.6761\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6814 - accuracy: 0.6761\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5524 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5192 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5381 - accuracy: 0.7465\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5519 - accuracy: 0.7042\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5399 - accuracy: 0.7746\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5683 - accuracy: 0.7324\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4937 - accuracy: 0.7465\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5385 - accuracy: 0.7183\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5472 - accuracy: 0.7465\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4389 - accuracy: 0.7746\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4464 - accuracy: 0.7746\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5061 - accuracy: 0.7606\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5776 - accuracy: 0.7606\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5365 - accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5208 - accuracy: 0.7183\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5741 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4940 - accuracy: 0.7887\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4737 - accuracy: 0.7887\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4227 - accuracy: 0.8028\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5673 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4694 - accuracy: 0.7465\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.0503 - accuracy: 0.5000\n",
      "--- Starting trial: run-28\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.2551 - accuracy: 0.4225\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.1285 - accuracy: 0.5070\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.1516 - accuracy: 0.5070\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.1003 - accuracy: 0.5211\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9871 - accuracy: 0.5211\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.0616 - accuracy: 0.5211\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.1075 - accuracy: 0.5070\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9148 - accuracy: 0.5775\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9814 - accuracy: 0.4789\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9738 - accuracy: 0.5070\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8939 - accuracy: 0.5634\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8057 - accuracy: 0.6197\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8039 - accuracy: 0.5915\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8193 - accuracy: 0.6197\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8006 - accuracy: 0.5775\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8825 - accuracy: 0.5634\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8309 - accuracy: 0.6056\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7348 - accuracy: 0.6338\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7040 - accuracy: 0.6338\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7474 - accuracy: 0.6197\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8008 - accuracy: 0.6197\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7256 - accuracy: 0.6056\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7605 - accuracy: 0.6056\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8080 - accuracy: 0.6620\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6522 - accuracy: 0.6901\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6748 - accuracy: 0.6338\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7568 - accuracy: 0.6620\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6268 - accuracy: 0.7183\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6714 - accuracy: 0.6901\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6240 - accuracy: 0.7042\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6471 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6768 - accuracy: 0.6901\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6332 - accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6201 - accuracy: 0.6761\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7370 - accuracy: 0.6338\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6150 - accuracy: 0.6761\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6339 - accuracy: 0.6901\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6447 - accuracy: 0.6620\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7275 - accuracy: 0.6338\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5900 - accuracy: 0.7042\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5696 - accuracy: 0.7465\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6795 - accuracy: 0.6901\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6204 - accuracy: 0.7042\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6473 - accuracy: 0.6761\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6801 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6303 - accuracy: 0.6901\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6824 - accuracy: 0.7324\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6417 - accuracy: 0.6901\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6015 - accuracy: 0.6761\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6050 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5863 - accuracy: 0.7042\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6239 - accuracy: 0.7042\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6154 - accuracy: 0.7183\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.5559 - accuracy: 0.7465\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5556 - accuracy: 0.7042\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5438 - accuracy: 0.7465\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5994 - accuracy: 0.6901\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6116 - accuracy: 0.6901\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6065 - accuracy: 0.7183\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6478 - accuracy: 0.6620\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6074 - accuracy: 0.7324\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5200 - accuracy: 0.7887\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5715 - accuracy: 0.7183\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5706 - accuracy: 0.6901\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5617 - accuracy: 0.7465\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5341 - accuracy: 0.7324\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5588 - accuracy: 0.7465\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4979 - accuracy: 0.7887\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5528 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5354 - accuracy: 0.7606\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5965 - accuracy: 0.7183\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5600 - accuracy: 0.7324\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5543 - accuracy: 0.7606\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5648 - accuracy: 0.7183\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5081 - accuracy: 0.7465\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5565 - accuracy: 0.7465\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5822 - accuracy: 0.7042\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5899 - accuracy: 0.7183\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5761 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4866 - accuracy: 0.7887\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5404 - accuracy: 0.7465\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5415 - accuracy: 0.7324\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4958 - accuracy: 0.7746\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4703 - accuracy: 0.8028\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4822 - accuracy: 0.8310\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6295 - accuracy: 0.7887\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5095 - accuracy: 0.7887\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5101 - accuracy: 0.8028\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4650 - accuracy: 0.8310\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.4679 - accuracy: 0.8028\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.4886 - accuracy: 0.8169\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6093 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5094 - accuracy: 0.8169\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5685 - accuracy: 0.7746\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5315 - accuracy: 0.7606\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4930 - accuracy: 0.7887\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4949 - accuracy: 0.8028\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4853 - accuracy: 0.7887\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4827 - accuracy: 0.7887\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5054 - accuracy: 0.7746\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8075 - accuracy: 0.6111\n",
      "--- Starting trial: run-29\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 0.8825 - accuracy: 0.5634\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8297 - accuracy: 0.5352\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8348 - accuracy: 0.5634\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7305 - accuracy: 0.6338\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6783 - accuracy: 0.6479\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7303 - accuracy: 0.6338\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7568 - accuracy: 0.6197\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7306 - accuracy: 0.6056\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6725 - accuracy: 0.6479\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7908 - accuracy: 0.6338\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6710 - accuracy: 0.6479\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6867 - accuracy: 0.6479\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.7425 - accuracy: 0.6479\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6756 - accuracy: 0.6761\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7416 - accuracy: 0.6479\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6813 - accuracy: 0.5775\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6179 - accuracy: 0.6901\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6338 - accuracy: 0.6197\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6066 - accuracy: 0.6620\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6303 - accuracy: 0.6056\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7463 - accuracy: 0.6479\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7459 - accuracy: 0.6479\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6862 - accuracy: 0.6056\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6195 - accuracy: 0.6479\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5727 - accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6190 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6443 - accuracy: 0.6620\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6696 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6108 - accuracy: 0.6197\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5965 - accuracy: 0.6479\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5975 - accuracy: 0.6479\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5923 - accuracy: 0.6761\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5456 - accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6268 - accuracy: 0.6761\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6672 - accuracy: 0.7042\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5863 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6124 - accuracy: 0.6761\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5385 - accuracy: 0.6901\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5945 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5537 - accuracy: 0.7183\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5911 - accuracy: 0.6620\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6626 - accuracy: 0.6479\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5670 - accuracy: 0.6479\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5645 - accuracy: 0.6761\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6086 - accuracy: 0.6761\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5528 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5598 - accuracy: 0.6761\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5749 - accuracy: 0.6338\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5423 - accuracy: 0.7324\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5497 - accuracy: 0.6479\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5847 - accuracy: 0.6901\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5590 - accuracy: 0.6197\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6197 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6040 - accuracy: 0.6901\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5401 - accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5629 - accuracy: 0.7042\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5119 - accuracy: 0.7042\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5633 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6116 - accuracy: 0.7324\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6104 - accuracy: 0.7042\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5523 - accuracy: 0.6761\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5260 - accuracy: 0.7465\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5530 - accuracy: 0.6761\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5823 - accuracy: 0.7183\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5382 - accuracy: 0.7183\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5784 - accuracy: 0.7324\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5610 - accuracy: 0.7183\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5643 - accuracy: 0.7183\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5070 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5284 - accuracy: 0.6901\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5322 - accuracy: 0.7183\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5719 - accuracy: 0.6620\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6206 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5860 - accuracy: 0.7042\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5405 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5694 - accuracy: 0.6901\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6320 - accuracy: 0.7183\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5123 - accuracy: 0.7183\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5287 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4993 - accuracy: 0.7746\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4937 - accuracy: 0.7183\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5774 - accuracy: 0.7183\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5432 - accuracy: 0.6761\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5259 - accuracy: 0.7183\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6093 - accuracy: 0.6901\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5155 - accuracy: 0.7183\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5138 - accuracy: 0.6901\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5274 - accuracy: 0.6620\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5593 - accuracy: 0.6901\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5302 - accuracy: 0.6761\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5617 - accuracy: 0.7042\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5237 - accuracy: 0.7042\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5653 - accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5443 - accuracy: 0.6761\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.4905 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5659 - accuracy: 0.7324\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5395 - accuracy: 0.6479\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5293 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.5458 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5088 - accuracy: 0.6901\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.9291 - accuracy: 0.5556\n",
      "--- Starting trial: run-30\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 0.9860 - accuracy: 0.4648\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8682 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7200 - accuracy: 0.6338\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 54us/sample - loss: 0.8435 - accuracy: 0.5775\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.8522 - accuracy: 0.5634\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7902 - accuracy: 0.6338\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.7583 - accuracy: 0.6056\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7472 - accuracy: 0.6338\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 56us/sample - loss: 0.7258 - accuracy: 0.6620\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7576 - accuracy: 0.5775\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6900 - accuracy: 0.6197\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6521 - accuracy: 0.6620\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6856 - accuracy: 0.6620\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7009 - accuracy: 0.6620\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7091 - accuracy: 0.6056\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6630 - accuracy: 0.6620\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6868 - accuracy: 0.6056\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7507 - accuracy: 0.6620\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7216 - accuracy: 0.6056\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6316 - accuracy: 0.6761\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6387 - accuracy: 0.6479\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7966 - accuracy: 0.5915\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7271 - accuracy: 0.6197\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6845 - accuracy: 0.6338\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7467 - accuracy: 0.6197\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6304 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6927 - accuracy: 0.6338\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7521 - accuracy: 0.6197\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6479 - accuracy: 0.6197\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5774 - accuracy: 0.6761\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7118 - accuracy: 0.6197\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6183 - accuracy: 0.6338\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6263 - accuracy: 0.6620\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.7125 - accuracy: 0.6338\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6995 - accuracy: 0.6197\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6537 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6813 - accuracy: 0.6197\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6691 - accuracy: 0.7183\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7323 - accuracy: 0.6197\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5686 - accuracy: 0.6901\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5770 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6615 - accuracy: 0.6197\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6794 - accuracy: 0.6338\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.6451 - accuracy: 0.6338\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6049 - accuracy: 0.6901\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6854 - accuracy: 0.6197\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6471 - accuracy: 0.7042\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6186 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5470 - accuracy: 0.6479\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5794 - accuracy: 0.7183\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6160 - accuracy: 0.6197\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5922 - accuracy: 0.7183\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5967 - accuracy: 0.7042\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5583 - accuracy: 0.6901\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5628 - accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5921 - accuracy: 0.6901\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5275 - accuracy: 0.6761\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5821 - accuracy: 0.6761\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5935 - accuracy: 0.6901\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6248 - accuracy: 0.6761\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5944 - accuracy: 0.6761\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6470 - accuracy: 0.7042\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5216 - accuracy: 0.7183\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5052 - accuracy: 0.7465\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6079 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5601 - accuracy: 0.6761\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5694 - accuracy: 0.6620\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5854 - accuracy: 0.6761\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5519 - accuracy: 0.6901\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5629 - accuracy: 0.6620\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6129 - accuracy: 0.6338\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5914 - accuracy: 0.6901\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5417 - accuracy: 0.7042\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5261 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5888 - accuracy: 0.6479\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4977 - accuracy: 0.7183\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6359 - accuracy: 0.6901\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5856 - accuracy: 0.6338\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5123 - accuracy: 0.7324\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5717 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5339 - accuracy: 0.7042\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5240 - accuracy: 0.6901\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6725 - accuracy: 0.6338\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5774 - accuracy: 0.6479\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5196 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5892 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5629 - accuracy: 0.7324\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5508 - accuracy: 0.6620\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5194 - accuracy: 0.6901\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5378 - accuracy: 0.7183\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5442 - accuracy: 0.7042\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5176 - accuracy: 0.7183\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5202 - accuracy: 0.6479\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5352 - accuracy: 0.7183\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4788 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5761 - accuracy: 0.6620\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5446 - accuracy: 0.6620\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5584 - accuracy: 0.6479\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5296 - accuracy: 0.6901\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5362 - accuracy: 0.6620\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8195 - accuracy: 0.6111\n",
      "--- Starting trial: run-31\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.0512 - accuracy: 0.5352\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.8434 - accuracy: 0.6479\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.4850 - accuracy: 0.4930\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.2993 - accuracy: 0.5070\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.6616 - accuracy: 0.6056\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 2.3257 - accuracy: 0.5634\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.7312 - accuracy: 0.6197\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.9381 - accuracy: 0.6197\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.8181 - accuracy: 0.6479\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 2.0099 - accuracy: 0.5915\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3338 - accuracy: 0.6479\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.7985 - accuracy: 0.6197\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.5955 - accuracy: 0.6479\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.1181 - accuracy: 0.5493\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.0385 - accuracy: 0.5915\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.6342 - accuracy: 0.5775\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.8041 - accuracy: 0.5634\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.8646 - accuracy: 0.6197\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.3757 - accuracy: 0.5352\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.0719 - accuracy: 0.5634\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4795 - accuracy: 0.5915\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.6156 - accuracy: 0.5775\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3487 - accuracy: 0.5775\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.1894 - accuracy: 0.6197\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.8104 - accuracy: 0.5211\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.3854 - accuracy: 0.5775\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.8406 - accuracy: 0.5634\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.4236 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.2262 - accuracy: 0.6338\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.6177 - accuracy: 0.5915\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3387 - accuracy: 0.5775\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3891 - accuracy: 0.6338\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0856 - accuracy: 0.5634\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.3197 - accuracy: 0.6338\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0880 - accuracy: 0.5775\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.3091 - accuracy: 0.6479\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2895 - accuracy: 0.5493\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.3431 - accuracy: 0.5775\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0707 - accuracy: 0.5915\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.1540 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.2183 - accuracy: 0.5634\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.3284 - accuracy: 0.5915\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.4008 - accuracy: 0.5493\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0759 - accuracy: 0.6056\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 1.5898 - accuracy: 0.4930\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.3092 - accuracy: 0.6056\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.0571 - accuracy: 0.5070\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.4147 - accuracy: 0.4507\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.1519 - accuracy: 0.5634\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3194 - accuracy: 0.5352\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.0898 - accuracy: 0.5634\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4126 - accuracy: 0.5775\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2256 - accuracy: 0.6197\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0769 - accuracy: 0.5211\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9171 - accuracy: 0.6338\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9913 - accuracy: 0.5493\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.0884 - accuracy: 0.5634\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.4025 - accuracy: 0.4507\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0938 - accuracy: 0.5352\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0129 - accuracy: 0.5352\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9562 - accuracy: 0.5915\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9105 - accuracy: 0.5775\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0430 - accuracy: 0.4789\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8493 - accuracy: 0.6479\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0071 - accuracy: 0.5634\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0020 - accuracy: 0.5915\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9232 - accuracy: 0.5915\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0654 - accuracy: 0.5634\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9110 - accuracy: 0.6056\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7536 - accuracy: 0.6338\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7067 - accuracy: 0.6197\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7408 - accuracy: 0.6479\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7555 - accuracy: 0.5915\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0043 - accuracy: 0.5634\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8688 - accuracy: 0.5775\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.9264 - accuracy: 0.5493\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7097 - accuracy: 0.5493\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8052 - accuracy: 0.6479\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9065 - accuracy: 0.6338\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7557 - accuracy: 0.7042\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7388 - accuracy: 0.6056\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8425 - accuracy: 0.6197\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8344 - accuracy: 0.6479\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8295 - accuracy: 0.6056\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8498 - accuracy: 0.6056\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6994 - accuracy: 0.6761\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8301 - accuracy: 0.5493\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8146 - accuracy: 0.5915\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8628 - accuracy: 0.5211\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8627 - accuracy: 0.5634\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9976 - accuracy: 0.5915\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8315 - accuracy: 0.5493\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6297 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8567 - accuracy: 0.6901\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9601 - accuracy: 0.5634\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0466 - accuracy: 0.6056\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9297 - accuracy: 0.6901\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6430 - accuracy: 0.6901\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8131 - accuracy: 0.5775\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8288 - accuracy: 0.6197\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.4634 - accuracy: 0.5556\n",
      "--- Starting trial: run-32\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 5.0082 - accuracy: 0.3803\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 3.4801 - accuracy: 0.3944\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.2022 - accuracy: 0.3944\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 1.9632 - accuracy: 0.5070\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 1.3906 - accuracy: 0.5634\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 1.4980 - accuracy: 0.4507\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 1.2384 - accuracy: 0.4648\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.0156 - accuracy: 0.6056\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.0590 - accuracy: 0.5211\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.0647 - accuracy: 0.5493\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7706 - accuracy: 0.6338\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8489 - accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.8141 - accuracy: 0.4930\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7790 - accuracy: 0.6338\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8805 - accuracy: 0.5352\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8054 - accuracy: 0.6338\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7877 - accuracy: 0.6197\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9583 - accuracy: 0.5775\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7189 - accuracy: 0.6620\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8439 - accuracy: 0.5915\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7390 - accuracy: 0.6197\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8686 - accuracy: 0.6620\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7636 - accuracy: 0.6056\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6938 - accuracy: 0.7042\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.7289 - accuracy: 0.6056\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7226 - accuracy: 0.6761\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8160 - accuracy: 0.6901\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7479 - accuracy: 0.6056\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6603 - accuracy: 0.6901\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7691 - accuracy: 0.6197\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7029 - accuracy: 0.6479\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6886 - accuracy: 0.6761\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6505 - accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7015 - accuracy: 0.6197\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7490 - accuracy: 0.6901\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6951 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7032 - accuracy: 0.6761\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6033 - accuracy: 0.6620\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7133 - accuracy: 0.6479\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6289 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6725 - accuracy: 0.7183\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7835 - accuracy: 0.6056\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5877 - accuracy: 0.7183\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6826 - accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7095 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6212 - accuracy: 0.7324\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6861 - accuracy: 0.6479\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6597 - accuracy: 0.6761\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6663 - accuracy: 0.6620\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6522 - accuracy: 0.7042\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6308 - accuracy: 0.7183\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6670 - accuracy: 0.6901\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6635 - accuracy: 0.6479\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5758 - accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6243 - accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6653 - accuracy: 0.6620\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6686 - accuracy: 0.7465\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6250 - accuracy: 0.7042\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7094 - accuracy: 0.6479\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5904 - accuracy: 0.7606\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6193 - accuracy: 0.7183\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6109 - accuracy: 0.7606\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6264 - accuracy: 0.6761\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6421 - accuracy: 0.6901\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6084 - accuracy: 0.7606\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6201 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6527 - accuracy: 0.6901\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6000 - accuracy: 0.7606\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5888 - accuracy: 0.7324\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6224 - accuracy: 0.7183\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5712 - accuracy: 0.7324\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5988 - accuracy: 0.7042\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6437 - accuracy: 0.7183\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6676 - accuracy: 0.6761\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5823 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6342 - accuracy: 0.7324\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5831 - accuracy: 0.6901\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6816 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5584 - accuracy: 0.7465\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6861 - accuracy: 0.6620\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6060 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6654 - accuracy: 0.6901\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5921 - accuracy: 0.7746\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6371 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.6060 - accuracy: 0.7183\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6533 - accuracy: 0.7324\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5988 - accuracy: 0.7183\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5943 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5883 - accuracy: 0.7606\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5624 - accuracy: 0.7746\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6411 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5838 - accuracy: 0.7606\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5392 - accuracy: 0.7746\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6500 - accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5919 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5966 - accuracy: 0.7183\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5715 - accuracy: 0.7324\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5747 - accuracy: 0.7606\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5874 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5792 - accuracy: 0.7465\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8083 - accuracy: 0.5556\n",
      "--- Starting trial: run-33\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.7972 - accuracy: 0.4930\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.6370 - accuracy: 0.5493\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.8282 - accuracy: 0.5070\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.1871 - accuracy: 0.5775\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2528 - accuracy: 0.5634\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.3519 - accuracy: 0.5070\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2841 - accuracy: 0.5775\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2496 - accuracy: 0.4789\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.5343 - accuracy: 0.5634\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4651 - accuracy: 0.4789\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.5511 - accuracy: 0.5352\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.3505 - accuracy: 0.5493\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3888 - accuracy: 0.5775\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1344 - accuracy: 0.5211\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0220 - accuracy: 0.6338\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.5227 - accuracy: 0.5352\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2170 - accuracy: 0.6056\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2516 - accuracy: 0.5775\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1998 - accuracy: 0.5493\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2892 - accuracy: 0.5493\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1404 - accuracy: 0.5352\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.2506 - accuracy: 0.5493\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3255 - accuracy: 0.5211\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.2614 - accuracy: 0.5211\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1141 - accuracy: 0.5915\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1379 - accuracy: 0.5915\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2106 - accuracy: 0.5070\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2171 - accuracy: 0.5211\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8003 - accuracy: 0.5915\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1953 - accuracy: 0.6056\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8363 - accuracy: 0.5915\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8872 - accuracy: 0.6620\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0559 - accuracy: 0.5915\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0632 - accuracy: 0.5915\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9798 - accuracy: 0.5915\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0465 - accuracy: 0.5634\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9075 - accuracy: 0.5634\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8877 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7204 - accuracy: 0.5775\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9157 - accuracy: 0.5634\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9202 - accuracy: 0.5775\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0117 - accuracy: 0.5915\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.9402 - accuracy: 0.6479\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8852 - accuracy: 0.6056\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7180 - accuracy: 0.6620\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9279 - accuracy: 0.5775\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7013 - accuracy: 0.6479\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7731 - accuracy: 0.6479\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6919 - accuracy: 0.6620\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7034 - accuracy: 0.6338\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8328 - accuracy: 0.6197\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7796 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7080 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8931 - accuracy: 0.6197\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7770 - accuracy: 0.6056\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5732 - accuracy: 0.7042\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8288 - accuracy: 0.6197\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7133 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7579 - accuracy: 0.6479\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6724 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6946 - accuracy: 0.6479\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6547 - accuracy: 0.6901\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8353 - accuracy: 0.6056\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6305 - accuracy: 0.6761\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7842 - accuracy: 0.6901\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6734 - accuracy: 0.6338\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8498 - accuracy: 0.6056\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6224 - accuracy: 0.6620\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7008 - accuracy: 0.6338\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5847 - accuracy: 0.6761\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6245 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5762 - accuracy: 0.7183\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6322 - accuracy: 0.6338\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6956 - accuracy: 0.6479\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7621 - accuracy: 0.6056\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5824 - accuracy: 0.6901\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6661 - accuracy: 0.6620\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6971 - accuracy: 0.7183\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7251 - accuracy: 0.6901\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6926 - accuracy: 0.6479\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6233 - accuracy: 0.7042\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6474 - accuracy: 0.6479\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6000 - accuracy: 0.7183\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6830 - accuracy: 0.6479\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6491 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7163 - accuracy: 0.6901\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5954 - accuracy: 0.7042\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5207 - accuracy: 0.7465\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6657 - accuracy: 0.6479\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6112 - accuracy: 0.6901\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5785 - accuracy: 0.6761\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5855 - accuracy: 0.7465\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7065 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6657 - accuracy: 0.6761\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7173 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7141 - accuracy: 0.6338\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6517 - accuracy: 0.6901\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6081 - accuracy: 0.6761\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6130 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6269 - accuracy: 0.6056\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.3126 - accuracy: 0.5000\n",
      "--- Starting trial: run-34\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 1s 8ms/sample - loss: 3.0705 - accuracy: 0.6479\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 2.6430 - accuracy: 0.6761\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 3.3666 - accuracy: 0.6620\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.9587 - accuracy: 0.7042\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 2.9600 - accuracy: 0.6620\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.9426 - accuracy: 0.7042\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.8795 - accuracy: 0.6620\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 69us/sample - loss: 2.1810 - accuracy: 0.7042\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 3.4361 - accuracy: 0.6479\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.3467 - accuracy: 0.6761\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.7968 - accuracy: 0.6620\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.1996 - accuracy: 0.6761\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.2292 - accuracy: 0.6761\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 2.8233 - accuracy: 0.6761\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.3682 - accuracy: 0.6479\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.7335 - accuracy: 0.6620\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.3083 - accuracy: 0.6761\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.0091 - accuracy: 0.6056\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.9497 - accuracy: 0.6620\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.0799 - accuracy: 0.6479\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5198 - accuracy: 0.6761\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.6289 - accuracy: 0.7042\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5627 - accuracy: 0.6901\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.9574 - accuracy: 0.6761\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.9323 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.0159 - accuracy: 0.6479\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.0681 - accuracy: 0.6620\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5354 - accuracy: 0.6620\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.7292 - accuracy: 0.6338\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6407 - accuracy: 0.6901\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4070 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3775 - accuracy: 0.6479\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1637 - accuracy: 0.6620\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2318 - accuracy: 0.7183\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.8826 - accuracy: 0.7183\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.4420 - accuracy: 0.6197\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3163 - accuracy: 0.7183\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2593 - accuracy: 0.6761\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.6344 - accuracy: 0.6901\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1893 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1428 - accuracy: 0.7042\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1523 - accuracy: 0.7183\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1527 - accuracy: 0.6901\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2325 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1558 - accuracy: 0.6761\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1287 - accuracy: 0.6479\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.1915 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.1191 - accuracy: 0.78 - 0s 64us/sample - loss: 1.2900 - accuracy: 0.6901\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8343 - accuracy: 0.7324\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2219 - accuracy: 0.6479\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.4087 - accuracy: 0.6479\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0033 - accuracy: 0.7465\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0226 - accuracy: 0.7324\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8216 - accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2492 - accuracy: 0.6901\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.4049 - accuracy: 0.6761\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0146 - accuracy: 0.7042\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7852 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8810 - accuracy: 0.7183\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7973 - accuracy: 0.7042\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8024 - accuracy: 0.6901\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0161 - accuracy: 0.6901\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0463 - accuracy: 0.7183\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9061 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8753 - accuracy: 0.6479\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8466 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7887 - accuracy: 0.6197\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9589 - accuracy: 0.7042\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9067 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9007 - accuracy: 0.7465\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7765 - accuracy: 0.7324\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8767 - accuracy: 0.7042\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9124 - accuracy: 0.7042\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7206 - accuracy: 0.6761\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9598 - accuracy: 0.6901\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8980 - accuracy: 0.6761\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5552 - accuracy: 0.7465\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6380 - accuracy: 0.7042\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7595 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8197 - accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7785 - accuracy: 0.6761\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7184 - accuracy: 0.7042\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7212 - accuracy: 0.7324\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6158 - accuracy: 0.7042\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8043 - accuracy: 0.6479\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7733 - accuracy: 0.6901\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6914 - accuracy: 0.7465\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6973 - accuracy: 0.6901\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7411 - accuracy: 0.7183\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7361 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7089 - accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6942 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6337 - accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6312 - accuracy: 0.7042\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7975 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7017 - accuracy: 0.7887\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5992 - accuracy: 0.7465\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8099 - accuracy: 0.6479\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6688 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7025 - accuracy: 0.7465\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 2.4885 - accuracy: 0.5000\n",
      "--- Starting trial: run-35\n",
      "{'num_units 1': 8, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 4.8401 - accuracy: 0.3099\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 4.0949 - accuracy: 0.3803\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 2.4723 - accuracy: 0.4366\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 1.8175 - accuracy: 0.4225\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.6083 - accuracy: 0.4225\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1309 - accuracy: 0.5352\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2484 - accuracy: 0.4225\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1240 - accuracy: 0.4930\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0000 - accuracy: 0.4789\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9042 - accuracy: 0.4366\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8231 - accuracy: 0.4366\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.8006 - accuracy: 0.4507\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8076 - accuracy: 0.4648\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8393 - accuracy: 0.4930\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8028 - accuracy: 0.5070\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7510 - accuracy: 0.5634\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7427 - accuracy: 0.5070\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7374 - accuracy: 0.5915\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7668 - accuracy: 0.5070\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7017 - accuracy: 0.6338\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8436 - accuracy: 0.5211\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7402 - accuracy: 0.5352\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7074 - accuracy: 0.5915\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6853 - accuracy: 0.6761\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6657 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7149 - accuracy: 0.5915\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6745 - accuracy: 0.7183\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7124 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6831 - accuracy: 0.6620\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6682 - accuracy: 0.6901\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7116 - accuracy: 0.6479\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6487 - accuracy: 0.6761\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6729 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6814 - accuracy: 0.6901\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6673 - accuracy: 0.7042\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6940 - accuracy: 0.6338\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6894 - accuracy: 0.6479\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6801 - accuracy: 0.6197\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6756 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7050 - accuracy: 0.6338\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6704 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7195 - accuracy: 0.6197\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6868 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6727 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6583 - accuracy: 0.6761\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6841 - accuracy: 0.6761\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6892 - accuracy: 0.6338\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6843 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7005 - accuracy: 0.6479\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6805 - accuracy: 0.7042\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6385 - accuracy: 0.7042\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7152 - accuracy: 0.6901\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6654 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6646 - accuracy: 0.7324\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6641 - accuracy: 0.6901\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6499 - accuracy: 0.7042\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6563 - accuracy: 0.7183\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6677 - accuracy: 0.7042\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6635 - accuracy: 0.7042\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6684 - accuracy: 0.6761\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6606 - accuracy: 0.7042\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6773 - accuracy: 0.6901\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6657 - accuracy: 0.6761\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6394 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6657 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6540 - accuracy: 0.7183\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6709 - accuracy: 0.6620\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6455 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6589 - accuracy: 0.6761\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7106 - accuracy: 0.5775\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6582 - accuracy: 0.6901\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6583 - accuracy: 0.6761\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6603 - accuracy: 0.6901\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6437 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6430 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6786 - accuracy: 0.6197\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6477 - accuracy: 0.7042\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6635 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6512 - accuracy: 0.6901\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6508 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6817 - accuracy: 0.6056\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6711 - accuracy: 0.6197\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6685 - accuracy: 0.6620\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6359 - accuracy: 0.7324\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6468 - accuracy: 0.6761\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6465 - accuracy: 0.6901\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6670 - accuracy: 0.6056\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6499 - accuracy: 0.6620\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6425 - accuracy: 0.7042\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6531 - accuracy: 0.6901\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6711 - accuracy: 0.6056\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6364 - accuracy: 0.7042\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6568 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6495 - accuracy: 0.6901\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6284 - accuracy: 0.7183\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6540 - accuracy: 0.6761\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6708 - accuracy: 0.6620\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6363 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6411 - accuracy: 0.7042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6509 - accuracy: 0.6620\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.6702 - accuracy: 0.6667\n",
      "--- Starting trial: run-36\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.4357 - accuracy: 0.6479\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2716 - accuracy: 0.6620\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.3762 - accuracy: 0.6338\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.2165 - accuracy: 0.6197\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.2213 - accuracy: 0.6338\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.2034 - accuracy: 0.6479\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.1572 - accuracy: 0.6479\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1452 - accuracy: 0.5915\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0504 - accuracy: 0.6338\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0062 - accuracy: 0.6479\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0108 - accuracy: 0.6338\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9643 - accuracy: 0.6197\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9659 - accuracy: 0.6338\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9756 - accuracy: 0.6479\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9139 - accuracy: 0.6338\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9132 - accuracy: 0.6479\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8519 - accuracy: 0.6338\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8728 - accuracy: 0.6620\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7997 - accuracy: 0.6338\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8398 - accuracy: 0.6338\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7490 - accuracy: 0.6197\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7076 - accuracy: 0.6338\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7686 - accuracy: 0.7042\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6766 - accuracy: 0.6620\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6808 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7110 - accuracy: 0.6479\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6922 - accuracy: 0.7042\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7207 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6949 - accuracy: 0.6620\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6732 - accuracy: 0.6901\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6715 - accuracy: 0.6338\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6150 - accuracy: 0.6620\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6608 - accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6290 - accuracy: 0.6479\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6561 - accuracy: 0.6901\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5805 - accuracy: 0.7324\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6131 - accuracy: 0.6901\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6233 - accuracy: 0.7183\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5565 - accuracy: 0.7183\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6361 - accuracy: 0.6901\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5661 - accuracy: 0.6901\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6013 - accuracy: 0.7042\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5687 - accuracy: 0.7465\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5913 - accuracy: 0.6901\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5410 - accuracy: 0.7042\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6231 - accuracy: 0.6479\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5482 - accuracy: 0.7183\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5629 - accuracy: 0.7183\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5579 - accuracy: 0.6901\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5361 - accuracy: 0.7606\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5454 - accuracy: 0.7042\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5655 - accuracy: 0.7042\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5402 - accuracy: 0.7042\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5480 - accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6057 - accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5233 - accuracy: 0.7465\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4819 - accuracy: 0.7746\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5067 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.78 - 0s 71us/sample - loss: 0.5002 - accuracy: 0.7606\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5665 - accuracy: 0.7324\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5119 - accuracy: 0.7606\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5697 - accuracy: 0.7183\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5065 - accuracy: 0.7606\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5327 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5021 - accuracy: 0.7324\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5153 - accuracy: 0.7606\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5449 - accuracy: 0.7465\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4701 - accuracy: 0.7887\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5212 - accuracy: 0.7746\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4476 - accuracy: 0.8169\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5346 - accuracy: 0.7465\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5322 - accuracy: 0.7465\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5015 - accuracy: 0.8028\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5091 - accuracy: 0.7887\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5012 - accuracy: 0.8169\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4660 - accuracy: 0.8028\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.4709 - accuracy: 0.7887\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4643 - accuracy: 0.8169\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5356 - accuracy: 0.7606\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4617 - accuracy: 0.8169\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4900 - accuracy: 0.7887\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4615 - accuracy: 0.8028\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4343 - accuracy: 0.8451\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4879 - accuracy: 0.7465\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4928 - accuracy: 0.7324\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4640 - accuracy: 0.8028\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4435 - accuracy: 0.8169\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4518 - accuracy: 0.7887\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4263 - accuracy: 0.7887\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4688 - accuracy: 0.7887\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4529 - accuracy: 0.8028\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4273 - accuracy: 0.8028\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4453 - accuracy: 0.8028\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4379 - accuracy: 0.8592\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4868 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4127 - accuracy: 0.8310\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4470 - accuracy: 0.8028\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4009 - accuracy: 0.8169\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4352 - accuracy: 0.8310\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4124 - accuracy: 0.8310\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.2042 - accuracy: 0.5556\n",
      "--- Starting trial: run-37\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.9454 - accuracy: 0.6620\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.8606 - accuracy: 0.6620\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.6871 - accuracy: 0.6620\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.8450 - accuracy: 0.6620\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.7763 - accuracy: 0.6620\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6002 - accuracy: 0.6620\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.6502 - accuracy: 0.6620\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.6534 - accuracy: 0.6479\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.4834 - accuracy: 0.6761\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5654 - accuracy: 0.6761\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.4671 - accuracy: 0.6479\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5307 - accuracy: 0.6901\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3025 - accuracy: 0.6761\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3939 - accuracy: 0.6761\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3742 - accuracy: 0.6761\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3807 - accuracy: 0.6761\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1746 - accuracy: 0.7042\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2363 - accuracy: 0.6901\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.3060 - accuracy: 0.6761\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2850 - accuracy: 0.6901\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2577 - accuracy: 0.6761\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1929 - accuracy: 0.6761\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1987 - accuracy: 0.6761\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1031 - accuracy: 0.6761\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0878 - accuracy: 0.6761\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1824 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0738 - accuracy: 0.6620\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1205 - accuracy: 0.6761\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0352 - accuracy: 0.6761\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9976 - accuracy: 0.6901\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0407 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9613 - accuracy: 0.6620\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0058 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9180 - accuracy: 0.6620\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8812 - accuracy: 0.6620\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9291 - accuracy: 0.6620\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9459 - accuracy: 0.6620\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9251 - accuracy: 0.6338\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8215 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9166 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8862 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8901 - accuracy: 0.6901\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8452 - accuracy: 0.6901\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.8232 - accuracy: 0.6901\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7688 - accuracy: 0.6901\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8271 - accuracy: 0.6761\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7472 - accuracy: 0.6620\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7805 - accuracy: 0.6901\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7851 - accuracy: 0.6620\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7554 - accuracy: 0.6901\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7106 - accuracy: 0.7042\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7857 - accuracy: 0.6901\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7752 - accuracy: 0.6620\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7393 - accuracy: 0.6901\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6993 - accuracy: 0.7042\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6585 - accuracy: 0.6901\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6597 - accuracy: 0.7042\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6544 - accuracy: 0.6761\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6888 - accuracy: 0.6901\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6216 - accuracy: 0.7183\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7052 - accuracy: 0.7042\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6657 - accuracy: 0.6761\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6531 - accuracy: 0.6620\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7021 - accuracy: 0.6761\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6372 - accuracy: 0.7042\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6443 - accuracy: 0.7042\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6396 - accuracy: 0.7042\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6552 - accuracy: 0.6761\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6261 - accuracy: 0.7042\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6704 - accuracy: 0.6761\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6385 - accuracy: 0.7324\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6570 - accuracy: 0.7183\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6458 - accuracy: 0.7183\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6069 - accuracy: 0.7183\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6140 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5823 - accuracy: 0.6901\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6103 - accuracy: 0.7042\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5811 - accuracy: 0.7042\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5803 - accuracy: 0.7042\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5877 - accuracy: 0.6901\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6130 - accuracy: 0.6620\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6113 - accuracy: 0.6901\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5766 - accuracy: 0.7324\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5703 - accuracy: 0.7042\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5354 - accuracy: 0.7183\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5664 - accuracy: 0.6761\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5656 - accuracy: 0.7183\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5424 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4956 - accuracy: 0.7183\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5708 - accuracy: 0.7324\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5114 - accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5217 - accuracy: 0.7746\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5405 - accuracy: 0.7465\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5413 - accuracy: 0.7465\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5090 - accuracy: 0.7465\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4860 - accuracy: 0.7324\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5254 - accuracy: 0.7042\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4875 - accuracy: 0.7606\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5311 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4848 - accuracy: 0.7746\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8783 - accuracy: 0.5556\n",
      "--- Starting trial: run-38\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.0137 - accuracy: 0.4225\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9153 - accuracy: 0.4366\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8193 - accuracy: 0.5352\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 56us/sample - loss: 0.8165 - accuracy: 0.5352\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8168 - accuracy: 0.4789\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7427 - accuracy: 0.5775\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6553 - accuracy: 0.6056\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7334 - accuracy: 0.5634\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6717 - accuracy: 0.6056\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6742 - accuracy: 0.6479\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8053 - accuracy: 0.5070\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6624 - accuracy: 0.6197\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7175 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6977 - accuracy: 0.6338\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6848 - accuracy: 0.6479\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7072 - accuracy: 0.6338\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6668 - accuracy: 0.6197\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6346 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5930 - accuracy: 0.6761\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6453 - accuracy: 0.6479\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5952 - accuracy: 0.7042\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6299 - accuracy: 0.6761\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6583 - accuracy: 0.6479\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5729 - accuracy: 0.7183\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6520 - accuracy: 0.6479\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5970 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5600 - accuracy: 0.7042\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6748 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6053 - accuracy: 0.6761\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6340 - accuracy: 0.7606\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5676 - accuracy: 0.6761\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6171 - accuracy: 0.6901\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6174 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5795 - accuracy: 0.7042\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6211 - accuracy: 0.6620\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5737 - accuracy: 0.6761\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5651 - accuracy: 0.7324\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6902 - accuracy: 0.6901\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5854 - accuracy: 0.7042\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5656 - accuracy: 0.7324\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5504 - accuracy: 0.7606\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5442 - accuracy: 0.7042\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5972 - accuracy: 0.7042\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5661 - accuracy: 0.7183\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5995 - accuracy: 0.7042\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5951 - accuracy: 0.7465\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5111 - accuracy: 0.7606\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5148 - accuracy: 0.7465\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5455 - accuracy: 0.7183\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5073 - accuracy: 0.7465\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5307 - accuracy: 0.7183\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5003 - accuracy: 0.7887\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5656 - accuracy: 0.7465\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4752 - accuracy: 0.7746\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5655 - accuracy: 0.7606\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5417 - accuracy: 0.7324\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5448 - accuracy: 0.7183\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5007 - accuracy: 0.7183\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5506 - accuracy: 0.7324\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4840 - accuracy: 0.7324\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4887 - accuracy: 0.7324\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5050 - accuracy: 0.7324\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5326 - accuracy: 0.7465\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5185 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5579 - accuracy: 0.7183\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5634 - accuracy: 0.7183\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4460 - accuracy: 0.7887\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5443 - accuracy: 0.7324\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4517 - accuracy: 0.7746\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4857 - accuracy: 0.7324\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4794 - accuracy: 0.7606\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4848 - accuracy: 0.7465\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5361 - accuracy: 0.7183\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5363 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5180 - accuracy: 0.7324\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4968 - accuracy: 0.7465\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4451 - accuracy: 0.8028\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4600 - accuracy: 0.7746\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5145 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4766 - accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5435 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4345 - accuracy: 0.7887\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4552 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4389 - accuracy: 0.8169\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4573 - accuracy: 0.7746\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4737 - accuracy: 0.7606\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4404 - accuracy: 0.7887\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.4565 - accuracy: 0.7746\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5053 - accuracy: 0.7606\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4830 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4807 - accuracy: 0.7324\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4972 - accuracy: 0.7465\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5493 - accuracy: 0.7042\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4600 - accuracy: 0.7465\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4277 - accuracy: 0.8028\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4334 - accuracy: 0.7606\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4308 - accuracy: 0.7465\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4350 - accuracy: 0.7465\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4453 - accuracy: 0.7887\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4838 - accuracy: 0.7746\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.2200 - accuracy: 0.5000\n",
      "--- Starting trial: run-39\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.6534 - accuracy: 0.6620\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3600 - accuracy: 0.6761\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.4876 - accuracy: 0.6056\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.3380 - accuracy: 0.6479\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.2577 - accuracy: 0.6338\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 1.2634 - accuracy: 0.6338\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3296 - accuracy: 0.6338\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2682 - accuracy: 0.5915\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.2547 - accuracy: 0.6056\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1189 - accuracy: 0.6338\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1297 - accuracy: 0.6338\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9488 - accuracy: 0.6197\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1149 - accuracy: 0.6338\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.0719 - accuracy: 0.6197\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1074 - accuracy: 0.5775\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8554 - accuracy: 0.6197\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9028 - accuracy: 0.6056\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9670 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7567 - accuracy: 0.6901\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7374 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9488 - accuracy: 0.6056\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8173 - accuracy: 0.6761\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8724 - accuracy: 0.6338\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8385 - accuracy: 0.6338\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7650 - accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7316 - accuracy: 0.6056\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8587 - accuracy: 0.6620\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7093 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7860 - accuracy: 0.6479\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9074 - accuracy: 0.5915\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7436 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7611 - accuracy: 0.6761\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7909 - accuracy: 0.6901\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6749 - accuracy: 0.6761\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7243 - accuracy: 0.6620\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6110 - accuracy: 0.7042\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7062 - accuracy: 0.6761\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6601 - accuracy: 0.6620\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5991 - accuracy: 0.7606\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7193 - accuracy: 0.6620\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5293 - accuracy: 0.7606\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6429 - accuracy: 0.6901\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6214 - accuracy: 0.7183\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6337 - accuracy: 0.7324\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6580 - accuracy: 0.6338\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5468 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6616 - accuracy: 0.7183\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5822 - accuracy: 0.7183\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5267 - accuracy: 0.7465\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6008 - accuracy: 0.6901\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5871 - accuracy: 0.7465\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5026 - accuracy: 0.7465\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5515 - accuracy: 0.7324\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6475 - accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5281 - accuracy: 0.7324\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5396 - accuracy: 0.7746\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5621 - accuracy: 0.7042\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5404 - accuracy: 0.7324\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5527 - accuracy: 0.7324\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5619 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5527 - accuracy: 0.7042\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5025 - accuracy: 0.6761\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4965 - accuracy: 0.7465\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5153 - accuracy: 0.7183\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5398 - accuracy: 0.7465\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4652 - accuracy: 0.7324\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5524 - accuracy: 0.7042\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5618 - accuracy: 0.7183\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5300 - accuracy: 0.6901\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5646 - accuracy: 0.7465\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4511 - accuracy: 0.7324\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4919 - accuracy: 0.7324\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4815 - accuracy: 0.7324\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4864 - accuracy: 0.7042\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.78 - 0s 67us/sample - loss: 0.4573 - accuracy: 0.7887\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.4937 - accuracy: 0.7324\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5268 - accuracy: 0.7324\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.4854 - accuracy: 0.7324\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.4806 - accuracy: 0.7606\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4403 - accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5299 - accuracy: 0.7183\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4710 - accuracy: 0.7183\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4645 - accuracy: 0.7746\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4836 - accuracy: 0.7324\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5203 - accuracy: 0.7324\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5079 - accuracy: 0.7042\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4218 - accuracy: 0.7746\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5002 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5134 - accuracy: 0.7324\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4268 - accuracy: 0.7746\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4724 - accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4754 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4604 - accuracy: 0.7465\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4938 - accuracy: 0.7324\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5000 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4347 - accuracy: 0.7324\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4304 - accuracy: 0.7606\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.3954 - accuracy: 0.7887\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4337 - accuracy: 0.7606\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4519 - accuracy: 0.7606\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.1151 - accuracy: 0.6111\n",
      "--- Starting trial: run-40\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.7042 - accuracy: 0.4085\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.5047 - accuracy: 0.4930\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.3386 - accuracy: 0.4789\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.3836 - accuracy: 0.5352\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2298 - accuracy: 0.4930\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.3699 - accuracy: 0.4930\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1587 - accuracy: 0.4930\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9659 - accuracy: 0.5915\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1987 - accuracy: 0.5070\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2593 - accuracy: 0.5775\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9740 - accuracy: 0.5775\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9120 - accuracy: 0.5211\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9684 - accuracy: 0.6056\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9318 - accuracy: 0.5634\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9701 - accuracy: 0.5775\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9974 - accuracy: 0.4789\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8466 - accuracy: 0.5915\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8332 - accuracy: 0.5352\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9671 - accuracy: 0.5634\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9288 - accuracy: 0.5493\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8565 - accuracy: 0.5915\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.9233 - accuracy: 0.5493\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7435 - accuracy: 0.6620\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8785 - accuracy: 0.6197\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7635 - accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7218 - accuracy: 0.6901\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7758 - accuracy: 0.5915\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7222 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7288 - accuracy: 0.6338\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7968 - accuracy: 0.6620\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7621 - accuracy: 0.6338\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7687 - accuracy: 0.6620\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7415 - accuracy: 0.6479\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6763 - accuracy: 0.6761\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7067 - accuracy: 0.6761\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7282 - accuracy: 0.6761\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8513 - accuracy: 0.6338\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7003 - accuracy: 0.6479\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7149 - accuracy: 0.6338\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6522 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7241 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7205 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6969 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6226 - accuracy: 0.7042\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6189 - accuracy: 0.6901\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6449 - accuracy: 0.6761\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6333 - accuracy: 0.6761\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7617 - accuracy: 0.6479\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6332 - accuracy: 0.7183\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7078 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6809 - accuracy: 0.6761\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6399 - accuracy: 0.6901\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5950 - accuracy: 0.7465\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5596 - accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6863 - accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.75 - 0s 68us/sample - loss: 0.6574 - accuracy: 0.6901\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6115 - accuracy: 0.6901\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6227 - accuracy: 0.7183\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5221 - accuracy: 0.7746\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5869 - accuracy: 0.7042\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6771 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5425 - accuracy: 0.7606\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5974 - accuracy: 0.7183\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6005 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6208 - accuracy: 0.7465\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5382 - accuracy: 0.7324\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6737 - accuracy: 0.7183\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5815 - accuracy: 0.7183\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4849 - accuracy: 0.7606\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5389 - accuracy: 0.7465\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5503 - accuracy: 0.7042\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.75 - 0s 68us/sample - loss: 0.5611 - accuracy: 0.6761\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5533 - accuracy: 0.7183\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5522 - accuracy: 0.7042\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5478 - accuracy: 0.7324\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5367 - accuracy: 0.7324\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6729 - accuracy: 0.7183\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5444 - accuracy: 0.6761\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6493 - accuracy: 0.6620\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5285 - accuracy: 0.7183\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5029 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5273 - accuracy: 0.6901\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5056 - accuracy: 0.7324\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5142 - accuracy: 0.7183\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5470 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5949 - accuracy: 0.7465\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5784 - accuracy: 0.7606\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5539 - accuracy: 0.7183\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6040 - accuracy: 0.7183\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4846 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5266 - accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5569 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5168 - accuracy: 0.7606\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5441 - accuracy: 0.7465\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6048 - accuracy: 0.7465\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4862 - accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6141 - accuracy: 0.7042\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5978 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5259 - accuracy: 0.7746\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4911 - accuracy: 0.7183\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.1495 - accuracy: 0.5556\n",
      "--- Starting trial: run-41\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.4101 - accuracy: 0.4930\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9931 - accuracy: 0.5493\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.8888 - accuracy: 0.6056\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 58us/sample - loss: 0.8719 - accuracy: 0.6338\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8052 - accuracy: 0.6761\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7932 - accuracy: 0.6479\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6664 - accuracy: 0.7183\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6946 - accuracy: 0.7183\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7441 - accuracy: 0.6761\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8525 - accuracy: 0.6620\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7593 - accuracy: 0.6901\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7189 - accuracy: 0.6620\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6072 - accuracy: 0.7324\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6133 - accuracy: 0.7465\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5635 - accuracy: 0.8028\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6216 - accuracy: 0.7465\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5785 - accuracy: 0.7324\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5976 - accuracy: 0.7324\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5966 - accuracy: 0.7606\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5437 - accuracy: 0.7465\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5095 - accuracy: 0.7324\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5511 - accuracy: 0.7606\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5761 - accuracy: 0.7606\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5384 - accuracy: 0.7465\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5612 - accuracy: 0.7465\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5235 - accuracy: 0.7606\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5464 - accuracy: 0.7606\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5652 - accuracy: 0.7324\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5220 - accuracy: 0.7887\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5489 - accuracy: 0.7465\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5451 - accuracy: 0.7746\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4856 - accuracy: 0.7887\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5267 - accuracy: 0.7746\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.5292 - accuracy: 0.7042\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 0.4956 - accuracy: 0.7887\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 0.5520 - accuracy: 0.7324\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 53us/sample - loss: 0.6036 - accuracy: 0.7324\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 0.4985 - accuracy: 0.7887\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 0.5638 - accuracy: 0.7465\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 0.4909 - accuracy: 0.8028\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5453 - accuracy: 0.7324\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5343 - accuracy: 0.7324\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5459 - accuracy: 0.7606\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5105 - accuracy: 0.7606\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5341 - accuracy: 0.7887\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6137 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4554 - accuracy: 0.7746\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5484 - accuracy: 0.6761\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5473 - accuracy: 0.7606\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5428 - accuracy: 0.7183\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5436 - accuracy: 0.7465\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4997 - accuracy: 0.7465\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.5047 - accuracy: 0.7606\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4997 - accuracy: 0.8028\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4992 - accuracy: 0.7465\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4960 - accuracy: 0.7606\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4687 - accuracy: 0.7324\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5154 - accuracy: 0.7324\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5023 - accuracy: 0.7746\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5013 - accuracy: 0.8028\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4764 - accuracy: 0.7746\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4509 - accuracy: 0.7465\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4599 - accuracy: 0.8310\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5108 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5678 - accuracy: 0.7042\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.4718 - accuracy: 0.7606\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4413 - accuracy: 0.8169\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4630 - accuracy: 0.7746\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5136 - accuracy: 0.7324\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4364 - accuracy: 0.7465\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4813 - accuracy: 0.8028\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4982 - accuracy: 0.7887\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4318 - accuracy: 0.8310\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5028 - accuracy: 0.7606\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4520 - accuracy: 0.8028\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4617 - accuracy: 0.7746\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4676 - accuracy: 0.8169\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4794 - accuracy: 0.7887\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4358 - accuracy: 0.8169\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4851 - accuracy: 0.7887\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4495 - accuracy: 0.7746\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.4510 - accuracy: 0.7606\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4764 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5426 - accuracy: 0.7324\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5110 - accuracy: 0.7324\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4402 - accuracy: 0.8028\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5248 - accuracy: 0.7324\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4590 - accuracy: 0.7746\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4573 - accuracy: 0.7887\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.4571 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.4903 - accuracy: 0.7606\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4535 - accuracy: 0.7887\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.5565 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.4331 - accuracy: 0.7746\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4814 - accuracy: 0.7183\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.4379 - accuracy: 0.7887\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.4340 - accuracy: 0.7746\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4872 - accuracy: 0.7746\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4875 - accuracy: 0.8028\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4968 - accuracy: 0.8028\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.1728 - accuracy: 0.5556\n",
      "--- Starting trial: run-42\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 2.9924 - accuracy: 0.4366\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.9321 - accuracy: 0.4225\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.5326 - accuracy: 0.4930\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.6032 - accuracy: 0.5915\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.6257 - accuracy: 0.5352\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.6629 - accuracy: 0.5493\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 2.2893 - accuracy: 0.5775\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 2.6812 - accuracy: 0.4648\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.5743 - accuracy: 0.4930\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.2782 - accuracy: 0.5211\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.9753 - accuracy: 0.5493\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 2.0674 - accuracy: 0.5211\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.8435 - accuracy: 0.5352\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.8841 - accuracy: 0.5352\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.7751 - accuracy: 0.5915\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.8687 - accuracy: 0.5070\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.9659 - accuracy: 0.5352\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.8037 - accuracy: 0.5634\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6495 - accuracy: 0.5634\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.8182 - accuracy: 0.5070\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.4580 - accuracy: 0.4789\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2585 - accuracy: 0.5775\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 2.0264 - accuracy: 0.4507\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2844 - accuracy: 0.4930\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.6656 - accuracy: 0.5493\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.2131 - accuracy: 0.5915\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.7471 - accuracy: 0.4225\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1822 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.6363 - accuracy: 0.5775\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3000 - accuracy: 0.5634\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1191 - accuracy: 0.6197\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1487 - accuracy: 0.5775\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2593 - accuracy: 0.5211\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.3095 - accuracy: 0.5775\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0813 - accuracy: 0.5493\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.2505 - accuracy: 0.5070\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.4463 - accuracy: 0.5211\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4396 - accuracy: 0.5493\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0776 - accuracy: 0.6056\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1048 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9730 - accuracy: 0.5915\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2383 - accuracy: 0.6056\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9196 - accuracy: 0.6056\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0494 - accuracy: 0.6056\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.1913 - accuracy: 0.5070\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9958 - accuracy: 0.5493\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9763 - accuracy: 0.5070\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0707 - accuracy: 0.5634\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0187 - accuracy: 0.6479\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9564 - accuracy: 0.6338\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9183 - accuracy: 0.6056\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8210 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9225 - accuracy: 0.6620\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7040 - accuracy: 0.6620\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6399 - accuracy: 0.7042\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8829 - accuracy: 0.5493\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7188 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8673 - accuracy: 0.6197\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7104 - accuracy: 0.7324\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7150 - accuracy: 0.6056\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8728 - accuracy: 0.6479\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8003 - accuracy: 0.5634\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8281 - accuracy: 0.6620\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6138 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7527 - accuracy: 0.6479\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8153 - accuracy: 0.6056\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.8006 - accuracy: 0.6338\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6869 - accuracy: 0.6197\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8266 - accuracy: 0.6056\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7040 - accuracy: 0.6338\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6461 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6267 - accuracy: 0.7042\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7386 - accuracy: 0.6056\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6904 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5923 - accuracy: 0.7324\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7374 - accuracy: 0.6479\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6615 - accuracy: 0.6620\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6434 - accuracy: 0.6761\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6456 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7056 - accuracy: 0.6479\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5831 - accuracy: 0.7042\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6121 - accuracy: 0.6761\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6569 - accuracy: 0.6901\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6929 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6301 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5564 - accuracy: 0.6901\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5598 - accuracy: 0.7324\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5847 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5503 - accuracy: 0.7324\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6248 - accuracy: 0.7183\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6100 - accuracy: 0.7324\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6205 - accuracy: 0.6479\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6239 - accuracy: 0.6901\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5385 - accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5511 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6004 - accuracy: 0.6620\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5486 - accuracy: 0.7465\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5289 - accuracy: 0.7465\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.78 - 0s 66us/sample - loss: 0.5785 - accuracy: 0.7465\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5448 - accuracy: 0.7183\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.7454 - accuracy: 0.4444\n",
      "--- Starting trial: run-43\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.8450 - accuracy: 0.4225\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.7207 - accuracy: 0.4930\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.8715 - accuracy: 0.4930\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.7277 - accuracy: 0.5352\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.8700 - accuracy: 0.4507\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.7050 - accuracy: 0.4789\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.3957 - accuracy: 0.4930\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.9957 - accuracy: 0.4930\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.4543 - accuracy: 0.5634\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.7372 - accuracy: 0.5070\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6434 - accuracy: 0.4225\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5923 - accuracy: 0.5211\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.5194 - accuracy: 0.4648\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1463 - accuracy: 0.5775\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.3038 - accuracy: 0.5634\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.3149 - accuracy: 0.6056\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2263 - accuracy: 0.5493\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2995 - accuracy: 0.4789\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1755 - accuracy: 0.5493\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.2486 - accuracy: 0.5634\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1104 - accuracy: 0.6197\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0125 - accuracy: 0.6197\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.2686 - accuracy: 0.5493\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.1033 - accuracy: 0.5915\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1764 - accuracy: 0.5352\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9030 - accuracy: 0.6620\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1017 - accuracy: 0.6197\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1991 - accuracy: 0.5634\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9439 - accuracy: 0.5775\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.0234 - accuracy: 0.6056\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9226 - accuracy: 0.6197\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9597 - accuracy: 0.5775\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0949 - accuracy: 0.5211\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0164 - accuracy: 0.5915\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7900 - accuracy: 0.6056\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0031 - accuracy: 0.5775\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0009 - accuracy: 0.5775\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0445 - accuracy: 0.5211\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8123 - accuracy: 0.6338\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8805 - accuracy: 0.5634\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9470 - accuracy: 0.5915\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0252 - accuracy: 0.5915\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7690 - accuracy: 0.6620\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.8506 - accuracy: 0.5915\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7647 - accuracy: 0.5775\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8385 - accuracy: 0.5915\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.9001 - accuracy: 0.5634\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.9775 - accuracy: 0.5493\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7295 - accuracy: 0.6761\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7748 - accuracy: 0.6056\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.7397 - accuracy: 0.6197\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8039 - accuracy: 0.6338\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7036 - accuracy: 0.7042\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7123 - accuracy: 0.6338\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7791 - accuracy: 0.6479\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6975 - accuracy: 0.6479\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8879 - accuracy: 0.5775\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7861 - accuracy: 0.6338\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7876 - accuracy: 0.6761\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7654 - accuracy: 0.6620\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7774 - accuracy: 0.6479\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7563 - accuracy: 0.6338\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8101 - accuracy: 0.6479\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7729 - accuracy: 0.6338\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8684 - accuracy: 0.5915\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7403 - accuracy: 0.6056\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8742 - accuracy: 0.5775\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6598 - accuracy: 0.7042\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6679 - accuracy: 0.6761\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8236 - accuracy: 0.6056\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7133 - accuracy: 0.6197\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8248 - accuracy: 0.5915\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7172 - accuracy: 0.6338\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7136 - accuracy: 0.6479\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7700 - accuracy: 0.6056\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6734 - accuracy: 0.6338\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7156 - accuracy: 0.6761\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6546 - accuracy: 0.7324\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6270 - accuracy: 0.6479\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6582 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6628 - accuracy: 0.6338\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5472 - accuracy: 0.7042\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6711 - accuracy: 0.6479\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8229 - accuracy: 0.5915\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7180 - accuracy: 0.5915\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6011 - accuracy: 0.6901\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6854 - accuracy: 0.6056\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5629 - accuracy: 0.7465\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5994 - accuracy: 0.6761\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6147 - accuracy: 0.6901\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6721 - accuracy: 0.6761\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6838 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6972 - accuracy: 0.6056\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5909 - accuracy: 0.6761\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6514 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6399 - accuracy: 0.6901\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6491 - accuracy: 0.6479\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6573 - accuracy: 0.6338\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5470 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5638 - accuracy: 0.7324\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8801 - accuracy: 0.5556\n",
      "--- Starting trial: run-44\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.4340 - accuracy: 0.5493\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 1.1955 - accuracy: 0.5211\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.1974 - accuracy: 0.6197\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7837 - accuracy: 0.5775\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0943 - accuracy: 0.5915\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.0290 - accuracy: 0.5915\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0268 - accuracy: 0.5775\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 94us/sample - loss: 0.9348 - accuracy: 0.5493\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.9467 - accuracy: 0.5915\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.8759 - accuracy: 0.5634\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.8077 - accuracy: 0.5775\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7430 - accuracy: 0.6056\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8003 - accuracy: 0.6197\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7419 - accuracy: 0.5493\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6539 - accuracy: 0.6901\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6483 - accuracy: 0.6056\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6004 - accuracy: 0.6338\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6676 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7442 - accuracy: 0.5915\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6662 - accuracy: 0.6479\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.7123 - accuracy: 0.6197\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6904 - accuracy: 0.6479\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6477 - accuracy: 0.6197\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.6622 - accuracy: 0.5775\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6369 - accuracy: 0.6901\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.6438 - accuracy: 0.6056\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6747 - accuracy: 0.5634\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6732 - accuracy: 0.6761\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6213 - accuracy: 0.6056\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.7230 - accuracy: 0.5775\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6290 - accuracy: 0.6056\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6118 - accuracy: 0.5775\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6346 - accuracy: 0.5211\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5995 - accuracy: 0.6479\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 102us/sample - loss: 0.6439 - accuracy: 0.6479\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6427 - accuracy: 0.5493\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6218 - accuracy: 0.6338\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6113 - accuracy: 0.6338\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6434 - accuracy: 0.5775\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 97us/sample - loss: 0.5886 - accuracy: 0.6620\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5497 - accuracy: 0.7183\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5474 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 0.6127 - accuracy: 0.6056\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5995 - accuracy: 0.6197\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5922 - accuracy: 0.6338\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.5633 - accuracy: 0.6197\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5674 - accuracy: 0.6761\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5425 - accuracy: 0.6761\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5668 - accuracy: 0.6056\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5951 - accuracy: 0.6479\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5738 - accuracy: 0.6901\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5764 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5895 - accuracy: 0.6479\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5761 - accuracy: 0.6197\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6405 - accuracy: 0.6197\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6152 - accuracy: 0.6197\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5446 - accuracy: 0.7042\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5656 - accuracy: 0.6761\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6136 - accuracy: 0.6479\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6204 - accuracy: 0.6056\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5705 - accuracy: 0.5915\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.6253 - accuracy: 0.6620\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6128 - accuracy: 0.6479\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5802 - accuracy: 0.6761\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5218 - accuracy: 0.7465\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6414 - accuracy: 0.6620\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5151 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5927 - accuracy: 0.6056\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6268 - accuracy: 0.6197\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5723 - accuracy: 0.5915\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5309 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5508 - accuracy: 0.6338\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5506 - accuracy: 0.6338\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6033 - accuracy: 0.5915\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5712 - accuracy: 0.6479\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5582 - accuracy: 0.6901\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5168 - accuracy: 0.6479\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5733 - accuracy: 0.6479\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5856 - accuracy: 0.6761\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5472 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5448 - accuracy: 0.6761\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5314 - accuracy: 0.6197\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.4726 - accuracy: 0.7465\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.5621 - accuracy: 0.6338\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5366 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5688 - accuracy: 0.6197\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5535 - accuracy: 0.6479\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5244 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5700 - accuracy: 0.5775\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5112 - accuracy: 0.6620\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5215 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5159 - accuracy: 0.7042\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5439 - accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5047 - accuracy: 0.7465\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5130 - accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5437 - accuracy: 0.7042\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5336 - accuracy: 0.6338\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5581 - accuracy: 0.7324\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5028 - accuracy: 0.7746\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5254 - accuracy: 0.7042\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8570 - accuracy: 0.5556\n",
      "--- Starting trial: run-45\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.7333 - accuracy: 0.6761\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5346 - accuracy: 0.6479\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.6712 - accuracy: 0.6761\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2287 - accuracy: 0.6620\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.4036 - accuracy: 0.6620\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.3390 - accuracy: 0.6901\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.2074 - accuracy: 0.6620\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2755 - accuracy: 0.7042\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0985 - accuracy: 0.6479\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.3358 - accuracy: 0.6620\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0589 - accuracy: 0.6620\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9808 - accuracy: 0.6761\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8869 - accuracy: 0.6620\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2026 - accuracy: 0.6761\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0428 - accuracy: 0.6620\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1799 - accuracy: 0.6197\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9026 - accuracy: 0.6761\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8815 - accuracy: 0.6620\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.0498 - accuracy: 0.6901\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1089 - accuracy: 0.6479\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0551 - accuracy: 0.6761\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0648 - accuracy: 0.6901\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9281 - accuracy: 0.6901\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9188 - accuracy: 0.6338\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9363 - accuracy: 0.6901\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.0534 - accuracy: 0.6901\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8798 - accuracy: 0.7183\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7534 - accuracy: 0.7042\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7636 - accuracy: 0.7324\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8927 - accuracy: 0.6197\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6148 - accuracy: 0.7465\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8008 - accuracy: 0.6479\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7571 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7303 - accuracy: 0.7183\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6718 - accuracy: 0.6901\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7505 - accuracy: 0.6479\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7020 - accuracy: 0.7324\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7134 - accuracy: 0.7042\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8714 - accuracy: 0.6197\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8454 - accuracy: 0.5915\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6614 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6655 - accuracy: 0.6761\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7186 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6544 - accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6623 - accuracy: 0.6479\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6084 - accuracy: 0.6338\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6800 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8600 - accuracy: 0.6479\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6217 - accuracy: 0.7183\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7032 - accuracy: 0.5915\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7446 - accuracy: 0.6338\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6304 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7182 - accuracy: 0.6338\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5605 - accuracy: 0.7042\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5865 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6347 - accuracy: 0.6761\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7112 - accuracy: 0.6056\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4587 - accuracy: 0.7746\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6854 - accuracy: 0.6338\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6127 - accuracy: 0.7324\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.6418 - accuracy: 0.6479\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5595 - accuracy: 0.7465\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6543 - accuracy: 0.6479\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.5267 - accuracy: 0.7606\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7102 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6083 - accuracy: 0.6620\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5929 - accuracy: 0.7324\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5361 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6291 - accuracy: 0.6479\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6147 - accuracy: 0.7324\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5971 - accuracy: 0.6056\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.7350 - accuracy: 0.6338\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6400 - accuracy: 0.6901\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6093 - accuracy: 0.6761\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6876 - accuracy: 0.6761\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6043 - accuracy: 0.6901\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5335 - accuracy: 0.7746\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.5553 - accuracy: 0.7465\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5437 - accuracy: 0.6901\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5924 - accuracy: 0.7042\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5264 - accuracy: 0.6620\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.4577 - accuracy: 0.7887\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.5360 - accuracy: 0.7465\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6806 - accuracy: 0.6620\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5298 - accuracy: 0.6761\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.5574 - accuracy: 0.7324\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5213 - accuracy: 0.7606\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.5612 - accuracy: 0.6901\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4901 - accuracy: 0.7746\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.4794 - accuracy: 0.7746\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.4910 - accuracy: 0.7324\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.4773 - accuracy: 0.7465\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.4904 - accuracy: 0.7606\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.4731 - accuracy: 0.7887\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5099 - accuracy: 0.7465\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5546 - accuracy: 0.6761\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5303 - accuracy: 0.6901\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.4677 - accuracy: 0.7887\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4967 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.5276 - accuracy: 0.7887\n",
      "18/18 [==============================] - 0s 5ms/sample - loss: 0.8257 - accuracy: 0.6111\n",
      "--- Starting trial: run-46\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 3.3479 - accuracy: 0.5352\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.5704 - accuracy: 0.5634\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.9419 - accuracy: 0.5352\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.7027 - accuracy: 0.4648\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 3.1407 - accuracy: 0.4507\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.5328 - accuracy: 0.4930\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 2.6426 - accuracy: 0.5070\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 2.3312 - accuracy: 0.5352\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 2.6110 - accuracy: 0.4648\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.2936 - accuracy: 0.4930\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 2.1176 - accuracy: 0.5493\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.4660 - accuracy: 0.4366\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.3587 - accuracy: 0.5493\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.9196 - accuracy: 0.5634\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.6819 - accuracy: 0.6056\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.9670 - accuracy: 0.5493\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.2018 - accuracy: 0.4930\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.6940 - accuracy: 0.5493\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.8795 - accuracy: 0.5070\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5532 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.6647 - accuracy: 0.5915\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.4430 - accuracy: 0.6056\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.6343 - accuracy: 0.6056\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.6564 - accuracy: 0.5493\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.4594 - accuracy: 0.5352\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.5261 - accuracy: 0.5775\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2883 - accuracy: 0.6479\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.7819 - accuracy: 0.5634\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.4285 - accuracy: 0.5634\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5192 - accuracy: 0.5634\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.5079 - accuracy: 0.5634\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3343 - accuracy: 0.5775\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2381 - accuracy: 0.5493\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.5817 - accuracy: 0.5634\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0731 - accuracy: 0.6338\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2031 - accuracy: 0.5493\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.2715 - accuracy: 0.4930\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1674 - accuracy: 0.5493\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.2717 - accuracy: 0.5352\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9796 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1547 - accuracy: 0.6197\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1589 - accuracy: 0.6479\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9788 - accuracy: 0.5634\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8601 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1082 - accuracy: 0.6197\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0212 - accuracy: 0.6197\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1413 - accuracy: 0.6056\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1718 - accuracy: 0.6056\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.8710 - accuracy: 0.6197\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8259 - accuracy: 0.5915\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9266 - accuracy: 0.6197\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8319 - accuracy: 0.6056\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8228 - accuracy: 0.7042\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8797 - accuracy: 0.6338\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1392 - accuracy: 0.5211\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9251 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9105 - accuracy: 0.6056\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8252 - accuracy: 0.6197\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8709 - accuracy: 0.6197\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8074 - accuracy: 0.6197\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9127 - accuracy: 0.5634\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8021 - accuracy: 0.6056\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6926 - accuracy: 0.6620\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7602 - accuracy: 0.6479\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7086 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7462 - accuracy: 0.6197\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7550 - accuracy: 0.6338\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6569 - accuracy: 0.7042\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7192 - accuracy: 0.6479\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7501 - accuracy: 0.6479\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6759 - accuracy: 0.6338\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7015 - accuracy: 0.7042\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6454 - accuracy: 0.6901\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6714 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5536 - accuracy: 0.7183\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6958 - accuracy: 0.6197\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6296 - accuracy: 0.6901\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6083 - accuracy: 0.7183\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7817 - accuracy: 0.6620\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6519 - accuracy: 0.7183\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5687 - accuracy: 0.7465\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5873 - accuracy: 0.6901\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.5508 - accuracy: 0.7042\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6253 - accuracy: 0.6620\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6063 - accuracy: 0.6620\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6767 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6795 - accuracy: 0.7183\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6143 - accuracy: 0.6620\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5908 - accuracy: 0.6761\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5103 - accuracy: 0.7183\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5978 - accuracy: 0.6901\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5135 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7006 - accuracy: 0.6620\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5748 - accuracy: 0.7042\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6000 - accuracy: 0.6620\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5680 - accuracy: 0.7465\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7211 - accuracy: 0.6761\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5419 - accuracy: 0.7606\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6538 - accuracy: 0.6197\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4971 - accuracy: 0.7746\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.3730 - accuracy: 0.6111\n",
      "--- Starting trial: run-47\n",
      "{'num_units 1': 8, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.3243 - accuracy: 0.5634\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.1555 - accuracy: 0.5352\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8874 - accuracy: 0.6197\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1425 - accuracy: 0.5493\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8811 - accuracy: 0.5775\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8569 - accuracy: 0.5775\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7644 - accuracy: 0.6197\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7594 - accuracy: 0.6056\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0044 - accuracy: 0.5775\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8037 - accuracy: 0.5915\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8852 - accuracy: 0.5775\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7617 - accuracy: 0.6479\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7153 - accuracy: 0.6479\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7779 - accuracy: 0.6620\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6264 - accuracy: 0.6197\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7238 - accuracy: 0.6479\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6607 - accuracy: 0.6338\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7025 - accuracy: 0.6901\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7012 - accuracy: 0.6338\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8155 - accuracy: 0.5915\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7121 - accuracy: 0.6338\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6199 - accuracy: 0.6479\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5835 - accuracy: 0.6620\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6845 - accuracy: 0.6056\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5981 - accuracy: 0.6761\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6659 - accuracy: 0.6901\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6931 - accuracy: 0.5493\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6964 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5933 - accuracy: 0.6901\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6527 - accuracy: 0.6056\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5576 - accuracy: 0.7183\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5708 - accuracy: 0.7324\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6132 - accuracy: 0.6479\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5729 - accuracy: 0.6479\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5241 - accuracy: 0.7042\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6112 - accuracy: 0.6479\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5821 - accuracy: 0.6620\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6470 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5803 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5878 - accuracy: 0.6901\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5908 - accuracy: 0.6479\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5433 - accuracy: 0.7183\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6034 - accuracy: 0.6338\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5859 - accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5490 - accuracy: 0.6901\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5829 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5506 - accuracy: 0.6761\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5331 - accuracy: 0.7042\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5869 - accuracy: 0.6620\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5855 - accuracy: 0.5915\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5566 - accuracy: 0.6338\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5977 - accuracy: 0.6901\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5575 - accuracy: 0.6338\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6144 - accuracy: 0.6338\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5923 - accuracy: 0.5775\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5367 - accuracy: 0.7746\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5548 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5687 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5245 - accuracy: 0.6761\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5982 - accuracy: 0.6338\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5723 - accuracy: 0.6901\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5738 - accuracy: 0.6761\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5590 - accuracy: 0.6620\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5704 - accuracy: 0.6338\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5694 - accuracy: 0.6620\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5771 - accuracy: 0.6197\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5500 - accuracy: 0.7042\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5599 - accuracy: 0.6338\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5942 - accuracy: 0.6901\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5976 - accuracy: 0.6197\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5908 - accuracy: 0.6338\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5952 - accuracy: 0.6338\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5556 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.5533 - accuracy: 0.6620\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5281 - accuracy: 0.7324\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5389 - accuracy: 0.6479\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5306 - accuracy: 0.6761\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5229 - accuracy: 0.6901\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5514 - accuracy: 0.6761\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5321 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5695 - accuracy: 0.6338\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5757 - accuracy: 0.6620\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5467 - accuracy: 0.6479\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5177 - accuracy: 0.7183\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5320 - accuracy: 0.6620\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5448 - accuracy: 0.6479\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5845 - accuracy: 0.6901\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5043 - accuracy: 0.7183\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.71 - 0s 62us/sample - loss: 0.5055 - accuracy: 0.7606\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5030 - accuracy: 0.7042\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5326 - accuracy: 0.7324\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5306 - accuracy: 0.6901\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5227 - accuracy: 0.7606\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5578 - accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5214 - accuracy: 0.7183\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5030 - accuracy: 0.7183\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5539 - accuracy: 0.6901\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5238 - accuracy: 0.7042\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5586 - accuracy: 0.6761\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.5503 - accuracy: 0.6901\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8064 - accuracy: 0.5556\n",
      "--- Starting trial: run-48\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 5ms/sample - loss: 5.5336 - accuracy: 0.3662\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 4.7787 - accuracy: 0.3662\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 4.3306 - accuracy: 0.4085\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 3.9614 - accuracy: 0.4085\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 4.2296 - accuracy: 0.3803\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 4.0697 - accuracy: 0.3662\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 3.7969 - accuracy: 0.3521\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 3.8976 - accuracy: 0.3803\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 3.3463 - accuracy: 0.4225\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.8798 - accuracy: 0.4366\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 3.4160 - accuracy: 0.3662\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 3.1453 - accuracy: 0.4225\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.8149 - accuracy: 0.4225\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.6408 - accuracy: 0.4507\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 2.5465 - accuracy: 0.4085\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 2.4271 - accuracy: 0.3803\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 2.3155 - accuracy: 0.4085\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.2822 - accuracy: 0.4507\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.0499 - accuracy: 0.4507\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.9453 - accuracy: 0.4085\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.2063 - accuracy: 0.4085\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.8012 - accuracy: 0.4225\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.6379 - accuracy: 0.5211\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.7309 - accuracy: 0.4507\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.6785 - accuracy: 0.4507\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.5201 - accuracy: 0.4930\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.4129 - accuracy: 0.4930\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6446 - accuracy: 0.4507\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.6380 - accuracy: 0.4789\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2664 - accuracy: 0.5352\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2171 - accuracy: 0.5070\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.4527 - accuracy: 0.5211\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0381 - accuracy: 0.5352\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1831 - accuracy: 0.5915\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.2232 - accuracy: 0.5352\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.2216 - accuracy: 0.4930\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.0923 - accuracy: 0.5211\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 1.0324 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9501 - accuracy: 0.5915\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.1907 - accuracy: 0.5634\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0720 - accuracy: 0.5634\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9502 - accuracy: 0.5352\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9948 - accuracy: 0.5352\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0885 - accuracy: 0.5634\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9677 - accuracy: 0.5915\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9055 - accuracy: 0.5775\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9268 - accuracy: 0.6197\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9552 - accuracy: 0.5634\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7256 - accuracy: 0.6620\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8288 - accuracy: 0.6197\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8239 - accuracy: 0.5775\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7914 - accuracy: 0.6338\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7917 - accuracy: 0.6620\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7162 - accuracy: 0.6620\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8391 - accuracy: 0.6056\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6859 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7075 - accuracy: 0.6479\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8666 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8493 - accuracy: 0.6479\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7292 - accuracy: 0.6761\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6676 - accuracy: 0.7324\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6592 - accuracy: 0.6479\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6586 - accuracy: 0.6761\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6488 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7217 - accuracy: 0.7324\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6631 - accuracy: 0.6761\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7866 - accuracy: 0.6901\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6796 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6211 - accuracy: 0.8028\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6233 - accuracy: 0.7746\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7782 - accuracy: 0.7183\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7132 - accuracy: 0.7746\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6601 - accuracy: 0.7324\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7011 - accuracy: 0.7887\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6298 - accuracy: 0.7887\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6095 - accuracy: 0.7746\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5956 - accuracy: 0.7887\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7758 - accuracy: 0.6901\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7117 - accuracy: 0.7606\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7367 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6503 - accuracy: 0.7887\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6673 - accuracy: 0.7746\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6706 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6660 - accuracy: 0.7465\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6078 - accuracy: 0.7887\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6078 - accuracy: 0.7887\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5988 - accuracy: 0.8028\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6082 - accuracy: 0.7887\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5665 - accuracy: 0.8451\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6229 - accuracy: 0.8028\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6028 - accuracy: 0.7746\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6457 - accuracy: 0.7465\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6572 - accuracy: 0.8028\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.5988 - accuracy: 0.7887\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5814 - accuracy: 0.8310\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6371 - accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6507 - accuracy: 0.7606\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5844 - accuracy: 0.8028\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6396 - accuracy: 0.7606\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5643 - accuracy: 0.8310\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.7121 - accuracy: 0.6667\n",
      "--- Starting trial: run-49\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 3.1548 - accuracy: 0.3803\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 3.1582 - accuracy: 0.3803\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.9547 - accuracy: 0.4366\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 2.6255 - accuracy: 0.4085\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 2.7607 - accuracy: 0.3944\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.6311 - accuracy: 0.4085\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 2.4513 - accuracy: 0.4085\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 2.6654 - accuracy: 0.4085\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 2.2141 - accuracy: 0.4789\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.2391 - accuracy: 0.3803\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.1180 - accuracy: 0.4225\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.1300 - accuracy: 0.4085\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.0914 - accuracy: 0.3662\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.8038 - accuracy: 0.4366\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.8100 - accuracy: 0.4366\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.8681 - accuracy: 0.4930\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6951 - accuracy: 0.4225\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.7382 - accuracy: 0.4789\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6924 - accuracy: 0.4366\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.6034 - accuracy: 0.4648\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.5501 - accuracy: 0.4507\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.4019 - accuracy: 0.4085\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3036 - accuracy: 0.5493\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3520 - accuracy: 0.4930\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.3236 - accuracy: 0.5352\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.3953 - accuracy: 0.4648\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.4717 - accuracy: 0.5070\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.4818 - accuracy: 0.4789\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1638 - accuracy: 0.5211\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.2027 - accuracy: 0.5211\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.2212 - accuracy: 0.5493\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1257 - accuracy: 0.5070\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9763 - accuracy: 0.5493\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9341 - accuracy: 0.5775\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0831 - accuracy: 0.5070\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0796 - accuracy: 0.5352\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0427 - accuracy: 0.4930\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1405 - accuracy: 0.4930\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 1.0179 - accuracy: 0.5352\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0106 - accuracy: 0.5352\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.9378 - accuracy: 0.5775\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.0210 - accuracy: 0.5634\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.0076 - accuracy: 0.5070\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.1021 - accuracy: 0.5775\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8060 - accuracy: 0.6479\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9971 - accuracy: 0.5493\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8988 - accuracy: 0.6197\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9143 - accuracy: 0.5352\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9024 - accuracy: 0.5915\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7903 - accuracy: 0.6197\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7852 - accuracy: 0.6056\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8680 - accuracy: 0.6338\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8191 - accuracy: 0.6479\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8836 - accuracy: 0.5775\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8569 - accuracy: 0.5775\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8027 - accuracy: 0.6197\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7141 - accuracy: 0.6338\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7350 - accuracy: 0.6056\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8264 - accuracy: 0.5634\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7196 - accuracy: 0.6338\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9114 - accuracy: 0.4789\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6762 - accuracy: 0.6761\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8110 - accuracy: 0.6056\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7762 - accuracy: 0.6620\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7737 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6909 - accuracy: 0.6479\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7366 - accuracy: 0.5775\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6206 - accuracy: 0.6620\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7013 - accuracy: 0.6338\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6938 - accuracy: 0.6479\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7434 - accuracy: 0.6056\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7880 - accuracy: 0.6479\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6533 - accuracy: 0.6338\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8324 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6856 - accuracy: 0.6197\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7122 - accuracy: 0.6338\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6058 - accuracy: 0.6901\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6530 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7407 - accuracy: 0.6197\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8271 - accuracy: 0.6338\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7387 - accuracy: 0.6479\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6289 - accuracy: 0.7465\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6764 - accuracy: 0.6761\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5542 - accuracy: 0.7183\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5809 - accuracy: 0.7887\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5708 - accuracy: 0.7183\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8385 - accuracy: 0.6479\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5909 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6913 - accuracy: 0.6901\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6480 - accuracy: 0.7042\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7135 - accuracy: 0.6197\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6899 - accuracy: 0.7183\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5931 - accuracy: 0.7042\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6907 - accuracy: 0.7183\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5835 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5683 - accuracy: 0.7042\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5894 - accuracy: 0.7465\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5541 - accuracy: 0.7465\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6664 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6654 - accuracy: 0.7465\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.3599 - accuracy: 0.5000\n",
      "--- Starting trial: run-50\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.5418 - accuracy: 0.4085\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6234 - accuracy: 0.5070\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3112 - accuracy: 0.5775\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0690 - accuracy: 0.6479\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0176 - accuracy: 0.6197\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2039 - accuracy: 0.5634\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.9042 - accuracy: 0.6056\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0016 - accuracy: 0.5915\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9958 - accuracy: 0.5775\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9848 - accuracy: 0.5775\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8547 - accuracy: 0.5634\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8387 - accuracy: 0.6338\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7775 - accuracy: 0.6479\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7477 - accuracy: 0.6479\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6719 - accuracy: 0.6901\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6872 - accuracy: 0.7465\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7215 - accuracy: 0.6479\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6582 - accuracy: 0.7465\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6725 - accuracy: 0.6620\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7058 - accuracy: 0.6761\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6234 - accuracy: 0.6901\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5715 - accuracy: 0.7606\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6081 - accuracy: 0.7465\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5681 - accuracy: 0.7324\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6049 - accuracy: 0.6901\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5683 - accuracy: 0.7606\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5520 - accuracy: 0.7746\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4972 - accuracy: 0.7465\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5520 - accuracy: 0.7465\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6587 - accuracy: 0.6901\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5689 - accuracy: 0.7324\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5341 - accuracy: 0.7183\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5148 - accuracy: 0.7324\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5491 - accuracy: 0.7042\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4822 - accuracy: 0.7746\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4859 - accuracy: 0.7606\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4738 - accuracy: 0.7606\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5030 - accuracy: 0.7606\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5243 - accuracy: 0.7606\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5226 - accuracy: 0.7606\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5549 - accuracy: 0.7606\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5661 - accuracy: 0.7183\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5547 - accuracy: 0.7042\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4407 - accuracy: 0.8028\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4714 - accuracy: 0.7746\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5320 - accuracy: 0.7465\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4651 - accuracy: 0.7465\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5134 - accuracy: 0.7746\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4344 - accuracy: 0.8028\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.4919 - accuracy: 0.7606\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5178 - accuracy: 0.7183\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4767 - accuracy: 0.7465\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5155 - accuracy: 0.7324\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4458 - accuracy: 0.7887\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4434 - accuracy: 0.7746\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5919 - accuracy: 0.7324\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4773 - accuracy: 0.7606\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4967 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4605 - accuracy: 0.7746\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.75 - 0s 64us/sample - loss: 0.5200 - accuracy: 0.7324\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5482 - accuracy: 0.7746\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5087 - accuracy: 0.7465\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.4495 - accuracy: 0.7887\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5236 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4648 - accuracy: 0.7183\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5090 - accuracy: 0.7465\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4384 - accuracy: 0.7606\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4395 - accuracy: 0.7465\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5259 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4584 - accuracy: 0.7746\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4373 - accuracy: 0.7606\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4659 - accuracy: 0.7465\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4901 - accuracy: 0.7746\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.4741 - accuracy: 0.7606\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5084 - accuracy: 0.7606\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5039 - accuracy: 0.7324\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3948 - accuracy: 0.8169\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.3940 - accuracy: 0.8028\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4068 - accuracy: 0.8169\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5588 - accuracy: 0.7746\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4393 - accuracy: 0.8028\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4921 - accuracy: 0.7887\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.3978 - accuracy: 0.8592\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4874 - accuracy: 0.7465\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4183 - accuracy: 0.8169\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4074 - accuracy: 0.8028\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4191 - accuracy: 0.8169\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4277 - accuracy: 0.7746\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4152 - accuracy: 0.7887\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4290 - accuracy: 0.8169\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5245 - accuracy: 0.7324\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4224 - accuracy: 0.7746\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4161 - accuracy: 0.8310\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4506 - accuracy: 0.8028\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4523 - accuracy: 0.7606\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3704 - accuracy: 0.8310\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4089 - accuracy: 0.8028\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4120 - accuracy: 0.7887\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3689 - accuracy: 0.8310\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.3841 - accuracy: 0.8310\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.9606 - accuracy: 0.5556\n",
      "--- Starting trial: run-51\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.0741 - accuracy: 0.6338\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0745 - accuracy: 0.7324\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.0490 - accuracy: 0.7324\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8607 - accuracy: 0.7183\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8817 - accuracy: 0.7465\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7459 - accuracy: 0.7746\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9488 - accuracy: 0.7042\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7951 - accuracy: 0.7746\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7946 - accuracy: 0.7324\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7596 - accuracy: 0.7042\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6187 - accuracy: 0.7887\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7559 - accuracy: 0.7183\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6943 - accuracy: 0.7746\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7058 - accuracy: 0.8028\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6037 - accuracy: 0.7887\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6942 - accuracy: 0.7887\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7002 - accuracy: 0.7887\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6678 - accuracy: 0.7746\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6332 - accuracy: 0.7746\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5870 - accuracy: 0.7606\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6003 - accuracy: 0.7746\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5487 - accuracy: 0.8028\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5735 - accuracy: 0.7887\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6294 - accuracy: 0.7746\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5218 - accuracy: 0.8028\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5457 - accuracy: 0.7606\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5184 - accuracy: 0.7746\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5384 - accuracy: 0.7887\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5282 - accuracy: 0.7465\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6130 - accuracy: 0.7887\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4650 - accuracy: 0.8451\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6073 - accuracy: 0.7606\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4843 - accuracy: 0.8169\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4463 - accuracy: 0.8028\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4193 - accuracy: 0.8028\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4690 - accuracy: 0.8169\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4436 - accuracy: 0.8169\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4416 - accuracy: 0.8310\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3974 - accuracy: 0.8592\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4720 - accuracy: 0.8028\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5428 - accuracy: 0.7887\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3951 - accuracy: 0.8310\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3711 - accuracy: 0.8592\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3935 - accuracy: 0.8451\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3785 - accuracy: 0.8451\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4369 - accuracy: 0.8028\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4406 - accuracy: 0.7746\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4118 - accuracy: 0.8451\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3674 - accuracy: 0.8451\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3990 - accuracy: 0.8310\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4412 - accuracy: 0.8169\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4773 - accuracy: 0.7887\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.3477 - accuracy: 0.8592\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4439 - accuracy: 0.8310\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4468 - accuracy: 0.8451\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.3701 - accuracy: 0.8310\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.3373 - accuracy: 0.8732\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.3639 - accuracy: 0.8451\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5250 - accuracy: 0.8310\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3483 - accuracy: 0.8451\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.3914 - accuracy: 0.8451\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4147 - accuracy: 0.8451\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3172 - accuracy: 0.8873\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.3441 - accuracy: 0.8732\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3741 - accuracy: 0.8451\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3574 - accuracy: 0.8310\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3087 - accuracy: 0.9014\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.2854 - accuracy: 0.8451\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3016 - accuracy: 0.8732\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.3469 - accuracy: 0.8451\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3584 - accuracy: 0.8028\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3973 - accuracy: 0.8592\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.3038 - accuracy: 0.8592\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.3211 - accuracy: 0.8732\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3010 - accuracy: 0.8732\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.3944 - accuracy: 0.8451\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3094 - accuracy: 0.8873\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.3107 - accuracy: 0.8592\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.2895 - accuracy: 0.8873\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3347 - accuracy: 0.8310\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3015 - accuracy: 0.9014\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.2442 - accuracy: 0.9014\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.2826 - accuracy: 0.8732\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.2612 - accuracy: 0.8873\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.3559 - accuracy: 0.8169\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3151 - accuracy: 0.8592\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.2842 - accuracy: 0.9296\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3185 - accuracy: 0.8592\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.2832 - accuracy: 0.9014\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 65us/sample - loss: 0.2963 - accuracy: 0.8873\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.3045 - accuracy: 0.9014\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.2808 - accuracy: 0.8873\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.3112 - accuracy: 0.9014\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.3505 - accuracy: 0.8451\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.2739 - accuracy: 0.9014\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.2606 - accuracy: 0.9155\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.2359 - accuracy: 0.9437\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.2271 - accuracy: 0.9296\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.2371 - accuracy: 0.9296\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.3801 - accuracy: 0.8592\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 2.7664 - accuracy: 0.3333\n",
      "--- Starting trial: run-52\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 3.8847 - accuracy: 0.3521\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.8174 - accuracy: 0.3662\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 3.7205 - accuracy: 0.3380\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 3.4716 - accuracy: 0.3380\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 3.4504 - accuracy: 0.3380\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.6728 - accuracy: 0.3380\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 3.0025 - accuracy: 0.3239\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.7691 - accuracy: 0.3521\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 2.5557 - accuracy: 0.3521\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.6616 - accuracy: 0.3380\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.2875 - accuracy: 0.3803\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.3128 - accuracy: 0.4225\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.0006 - accuracy: 0.3944\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.2833 - accuracy: 0.4085\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.8712 - accuracy: 0.4366\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.7525 - accuracy: 0.4930\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.9772 - accuracy: 0.4366\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.6983 - accuracy: 0.4225\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6232 - accuracy: 0.4648\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.7444 - accuracy: 0.5211\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6227 - accuracy: 0.4930\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.4804 - accuracy: 0.5493\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3227 - accuracy: 0.5211\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3678 - accuracy: 0.5070\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.1642 - accuracy: 0.5493\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.4161 - accuracy: 0.5493\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.1672 - accuracy: 0.5493\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2597 - accuracy: 0.5493\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0563 - accuracy: 0.6197\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0234 - accuracy: 0.5915\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0761 - accuracy: 0.5493\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0326 - accuracy: 0.6056\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0108 - accuracy: 0.5775\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9413 - accuracy: 0.6197\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0297 - accuracy: 0.5775\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7726 - accuracy: 0.6761\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9829 - accuracy: 0.6479\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8309 - accuracy: 0.5775\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8930 - accuracy: 0.5915\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9226 - accuracy: 0.6197\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8464 - accuracy: 0.6901\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7446 - accuracy: 0.6761\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7915 - accuracy: 0.6479\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7871 - accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8150 - accuracy: 0.6761\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7262 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.7959 - accuracy: 0.6620\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7258 - accuracy: 0.7183\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9074 - accuracy: 0.5493\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7818 - accuracy: 0.6338\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7916 - accuracy: 0.6761\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6760 - accuracy: 0.6761\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8195 - accuracy: 0.6056\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8246 - accuracy: 0.7042\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7463 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8668 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.7133 - accuracy: 0.6338\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9254 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.7097 - accuracy: 0.6761\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6550 - accuracy: 0.7042\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7183 - accuracy: 0.6901\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8295 - accuracy: 0.6479\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7218 - accuracy: 0.7183\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7243 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6953 - accuracy: 0.6620\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5995 - accuracy: 0.7324\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6419 - accuracy: 0.7183\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6746 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6559 - accuracy: 0.6901\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7699 - accuracy: 0.6901\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6290 - accuracy: 0.7042\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6080 - accuracy: 0.7183\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6543 - accuracy: 0.6901\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6785 - accuracy: 0.7465\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6529 - accuracy: 0.6620\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.6121 - accuracy: 0.7183\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6998 - accuracy: 0.6620\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6551 - accuracy: 0.6901\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6486 - accuracy: 0.6901\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6377 - accuracy: 0.7042\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6709 - accuracy: 0.6761\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7002 - accuracy: 0.6620\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6348 - accuracy: 0.7183\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6424 - accuracy: 0.7324\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6691 - accuracy: 0.7183\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6786 - accuracy: 0.6901\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6140 - accuracy: 0.7465\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5967 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6595 - accuracy: 0.7183\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5515 - accuracy: 0.7606\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5927 - accuracy: 0.7324\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5665 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5668 - accuracy: 0.7465\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6079 - accuracy: 0.7042\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6203 - accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5613 - accuracy: 0.7606\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6377 - accuracy: 0.7183\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6034 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6034 - accuracy: 0.7042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6002 - accuracy: 0.7324\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.2925 - accuracy: 0.6111\n",
      "--- Starting trial: run-53\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.0470 - accuracy: 0.4648\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.6730 - accuracy: 0.4366\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.2882 - accuracy: 0.5070\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0052 - accuracy: 0.5493\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8551 - accuracy: 0.5352\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8700 - accuracy: 0.5493\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7990 - accuracy: 0.5352\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7298 - accuracy: 0.6197\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7192 - accuracy: 0.6056\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6658 - accuracy: 0.6197\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6984 - accuracy: 0.5493\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5666 - accuracy: 0.6479\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6330 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6891 - accuracy: 0.5634\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6092 - accuracy: 0.6761\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6292 - accuracy: 0.5915\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5539 - accuracy: 0.6479\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6143 - accuracy: 0.6338\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5877 - accuracy: 0.6056\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5017 - accuracy: 0.7324\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5525 - accuracy: 0.6620\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5142 - accuracy: 0.6620\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4846 - accuracy: 0.7042\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5950 - accuracy: 0.6056\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5291 - accuracy: 0.7042\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4970 - accuracy: 0.7042\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5496 - accuracy: 0.6338\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5458 - accuracy: 0.6901\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5011 - accuracy: 0.6197\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5338 - accuracy: 0.6479\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4924 - accuracy: 0.7183\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4848 - accuracy: 0.6620\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4614 - accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4996 - accuracy: 0.6901\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5144 - accuracy: 0.7183\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5342 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4985 - accuracy: 0.7324\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5024 - accuracy: 0.6901\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4583 - accuracy: 0.7465\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5004 - accuracy: 0.7042\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4624 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4607 - accuracy: 0.7042\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4978 - accuracy: 0.7042\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5056 - accuracy: 0.6901\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4778 - accuracy: 0.7324\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4824 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4704 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4742 - accuracy: 0.7183\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.4910 - accuracy: 0.7183\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4675 - accuracy: 0.7324\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4611 - accuracy: 0.7324\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4176 - accuracy: 0.7324\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4597 - accuracy: 0.7042\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4459 - accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5362 - accuracy: 0.6901\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4584 - accuracy: 0.7183\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4741 - accuracy: 0.7183\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4780 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5021 - accuracy: 0.7042\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5181 - accuracy: 0.7183\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4998 - accuracy: 0.7324\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4587 - accuracy: 0.7465\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.4652 - accuracy: 0.7183\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4621 - accuracy: 0.7606\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4717 - accuracy: 0.7183\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5212 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4085 - accuracy: 0.7887\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4606 - accuracy: 0.7465\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.4902 - accuracy: 0.7606\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4839 - accuracy: 0.7606\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4336 - accuracy: 0.7465\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4443 - accuracy: 0.7606\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4571 - accuracy: 0.7465\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4563 - accuracy: 0.7746\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4118 - accuracy: 0.7465\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4319 - accuracy: 0.7746\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.81 - 0s 63us/sample - loss: 0.4287 - accuracy: 0.7465\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5035 - accuracy: 0.7746\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.78 - 0s 70us/sample - loss: 0.4432 - accuracy: 0.8028\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4374 - accuracy: 0.7606\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4287 - accuracy: 0.7465\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4690 - accuracy: 0.7324\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4246 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4363 - accuracy: 0.7465\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4302 - accuracy: 0.7887\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4119 - accuracy: 0.7606\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4154 - accuracy: 0.7887\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4280 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4506 - accuracy: 0.7465\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4035 - accuracy: 0.7887\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4647 - accuracy: 0.7606\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4298 - accuracy: 0.7606\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4225 - accuracy: 0.7606\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4289 - accuracy: 0.7606\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4002 - accuracy: 0.7887\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4174 - accuracy: 0.8310\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.4184 - accuracy: 0.8169\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4157 - accuracy: 0.7887\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4186 - accuracy: 0.7887\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4133 - accuracy: 0.7887\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 2.1889 - accuracy: 0.5000\n",
      "--- Starting trial: run-54\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 2.2736 - accuracy: 0.4507\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.3035 - accuracy: 0.5915\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.1168 - accuracy: 0.5211\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.8214 - accuracy: 0.4789\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1976 - accuracy: 0.5352\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.9205 - accuracy: 0.4648\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.7844 - accuracy: 0.5352\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.4227 - accuracy: 0.5070\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.8531 - accuracy: 0.5915\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.5403 - accuracy: 0.4648\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.5898 - accuracy: 0.4507\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.6012 - accuracy: 0.5070\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.4182 - accuracy: 0.4789\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1659 - accuracy: 0.5211\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.5477 - accuracy: 0.5211\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0806 - accuracy: 0.4507\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3779 - accuracy: 0.5352\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5574 - accuracy: 0.4789\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3815 - accuracy: 0.5775\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 1.3252 - accuracy: 0.4930\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.5375 - accuracy: 0.4507\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2641 - accuracy: 0.4789\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1664 - accuracy: 0.5211\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.0459 - accuracy: 0.5634\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.2246 - accuracy: 0.5352\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.1619 - accuracy: 0.5634\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1598 - accuracy: 0.6056\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.3715 - accuracy: 0.5070\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8906 - accuracy: 0.6056\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9335 - accuracy: 0.6479\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2174 - accuracy: 0.5352\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9350 - accuracy: 0.5634\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1609 - accuracy: 0.5493\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9373 - accuracy: 0.5493\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3262 - accuracy: 0.5352\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8505 - accuracy: 0.6197\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7994 - accuracy: 0.6761\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9665 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8840 - accuracy: 0.5352\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9283 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9299 - accuracy: 0.5634\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8849 - accuracy: 0.5915\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7386 - accuracy: 0.6338\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9007 - accuracy: 0.5775\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8948 - accuracy: 0.6197\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9105 - accuracy: 0.6338\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5997 - accuracy: 0.7042\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7790 - accuracy: 0.5775\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7432 - accuracy: 0.5352\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7184 - accuracy: 0.6338\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7175 - accuracy: 0.5915\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7602 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8423 - accuracy: 0.6197\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7531 - accuracy: 0.6761\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8468 - accuracy: 0.6901\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9991 - accuracy: 0.5915\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7708 - accuracy: 0.6056\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6220 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8618 - accuracy: 0.6338\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6100 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8260 - accuracy: 0.6338\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8936 - accuracy: 0.6056\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6420 - accuracy: 0.7183\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.0245 - accuracy: 0.5634\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6748 - accuracy: 0.6479\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6881 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8101 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7522 - accuracy: 0.6338\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5434 - accuracy: 0.8169\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6871 - accuracy: 0.6479\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6478 - accuracy: 0.7465\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7932 - accuracy: 0.6761\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6114 - accuracy: 0.7042\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5074 - accuracy: 0.7324\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5958 - accuracy: 0.6479\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5631 - accuracy: 0.6479\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6501 - accuracy: 0.5634\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6609 - accuracy: 0.7606\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6118 - accuracy: 0.6761\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6381 - accuracy: 0.6901\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6874 - accuracy: 0.6338\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5688 - accuracy: 0.6620\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5689 - accuracy: 0.7042\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5346 - accuracy: 0.7183\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4799 - accuracy: 0.7606\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7904 - accuracy: 0.6056\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5727 - accuracy: 0.7606\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6070 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7114 - accuracy: 0.6620\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5414 - accuracy: 0.7183\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5973 - accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7322 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6666 - accuracy: 0.7042\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7643 - accuracy: 0.6901\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6316 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5629 - accuracy: 0.7042\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5077 - accuracy: 0.7606\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5462 - accuracy: 0.7465\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4625 - accuracy: 0.7606\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5704 - accuracy: 0.6901\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8108 - accuracy: 0.5556\n",
      "--- Starting trial: run-55\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.6622 - accuracy: 0.3803\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 3.0801 - accuracy: 0.3944\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.7957 - accuracy: 0.3239\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.2896 - accuracy: 0.3662\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.5613 - accuracy: 0.3803\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.1810 - accuracy: 0.4085\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.0185 - accuracy: 0.3944\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.0515 - accuracy: 0.3944\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.4993 - accuracy: 0.3521\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.8181 - accuracy: 0.3662\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.3501 - accuracy: 0.3944\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.9286 - accuracy: 0.3239\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 2.1765 - accuracy: 0.4085\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.0032 - accuracy: 0.4225\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.6860 - accuracy: 0.3803\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.0088 - accuracy: 0.4085\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.9956 - accuracy: 0.3662\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.8758 - accuracy: 0.3521\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.5608 - accuracy: 0.4507\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.6748 - accuracy: 0.4085\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5219 - accuracy: 0.4225\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4036 - accuracy: 0.3239\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.5460 - accuracy: 0.4507\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 1.4692 - accuracy: 0.4930\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3887 - accuracy: 0.4085\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1447 - accuracy: 0.5070\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3286 - accuracy: 0.4789\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1790 - accuracy: 0.5211\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0856 - accuracy: 0.3662\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1271 - accuracy: 0.4930\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.4796 - accuracy: 0.4366\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1590 - accuracy: 0.3521\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0089 - accuracy: 0.4789\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1376 - accuracy: 0.4930\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0898 - accuracy: 0.5352\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.2599 - accuracy: 0.5352\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0772 - accuracy: 0.5211\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8321 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9271 - accuracy: 0.4507\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1016 - accuracy: 0.5211\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.1383 - accuracy: 0.4930\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1442 - accuracy: 0.4930\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2215 - accuracy: 0.4085\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8669 - accuracy: 0.5493\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0329 - accuracy: 0.5493\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0880 - accuracy: 0.4930\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2783 - accuracy: 0.5775\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0451 - accuracy: 0.5352\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0782 - accuracy: 0.5070\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0420 - accuracy: 0.5915\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1126 - accuracy: 0.5634\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9463 - accuracy: 0.5493\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9038 - accuracy: 0.5352\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.8203 - accuracy: 0.5070\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8546 - accuracy: 0.5352\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9225 - accuracy: 0.5493\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.1520 - accuracy: 0.5211\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7392 - accuracy: 0.5211\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9794 - accuracy: 0.5211\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7333 - accuracy: 0.53 - 0s 68us/sample - loss: 1.0114 - accuracy: 0.4648\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0023 - accuracy: 0.5211\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7234 - accuracy: 0.5352\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9367 - accuracy: 0.5352\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8133 - accuracy: 0.5775\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9653 - accuracy: 0.5211\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7467 - accuracy: 0.5493\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9494 - accuracy: 0.5493\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8212 - accuracy: 0.4789\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6657 - accuracy: 0.6479\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8543 - accuracy: 0.6197\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0147 - accuracy: 0.5634\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9127 - accuracy: 0.5634\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8996 - accuracy: 0.5493\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0220 - accuracy: 0.5634\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8070 - accuracy: 0.5775\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8073 - accuracy: 0.6338\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9230 - accuracy: 0.5493\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8612 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8628 - accuracy: 0.4789\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8610 - accuracy: 0.5493\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8833 - accuracy: 0.6056\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.9827 - accuracy: 0.6338\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8375 - accuracy: 0.6056\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7098 - accuracy: 0.5211\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8962 - accuracy: 0.5915\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7587 - accuracy: 0.5775\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7815 - accuracy: 0.6479\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8156 - accuracy: 0.6479\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7198 - accuracy: 0.5634\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8240 - accuracy: 0.5775\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8296 - accuracy: 0.5915\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8110 - accuracy: 0.5915\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7799 - accuracy: 0.5634\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6700 - accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7966 - accuracy: 0.6056\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6521 - accuracy: 0.5915\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8155 - accuracy: 0.5493\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6963 - accuracy: 0.5634\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7824 - accuracy: 0.5775\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7634 - accuracy: 0.5775\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8239 - accuracy: 0.6111\n",
      "--- Starting trial: run-56\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.0004 - accuracy: 0.4789\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.6658 - accuracy: 0.5070\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.3422 - accuracy: 0.5493\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2093 - accuracy: 0.5070\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 1.0368 - accuracy: 0.5493\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0865 - accuracy: 0.5493\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9031 - accuracy: 0.5915\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.0890 - accuracy: 0.5634\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8839 - accuracy: 0.6479\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7377 - accuracy: 0.6479\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9600 - accuracy: 0.5634\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0337 - accuracy: 0.5915\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8400 - accuracy: 0.6479\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7378 - accuracy: 0.6479\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7012 - accuracy: 0.6620\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6536 - accuracy: 0.7042\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8015 - accuracy: 0.6479\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7174 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6738 - accuracy: 0.7042\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6675 - accuracy: 0.6901\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6270 - accuracy: 0.7042\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7647 - accuracy: 0.6901\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7342 - accuracy: 0.6901\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6780 - accuracy: 0.6761\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7025 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5904 - accuracy: 0.7042\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7089 - accuracy: 0.7042\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6314 - accuracy: 0.6479\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6336 - accuracy: 0.7606\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7223 - accuracy: 0.6479\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6403 - accuracy: 0.7042\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4824 - accuracy: 0.7465\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5558 - accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5832 - accuracy: 0.7324\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6796 - accuracy: 0.6620\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6179 - accuracy: 0.7465\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5795 - accuracy: 0.6901\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5329 - accuracy: 0.7042\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5776 - accuracy: 0.7042\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6039 - accuracy: 0.6901\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8335 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6075 - accuracy: 0.6901\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6143 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5662 - accuracy: 0.7324\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5600 - accuracy: 0.7042\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5938 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5683 - accuracy: 0.7606\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5821 - accuracy: 0.7324\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4980 - accuracy: 0.7746\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5587 - accuracy: 0.7465\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5923 - accuracy: 0.6901\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5947 - accuracy: 0.7183\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 59us/sample - loss: 0.5532 - accuracy: 0.6901\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5019 - accuracy: 0.7465\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5660 - accuracy: 0.6338\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5655 - accuracy: 0.7606\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5535 - accuracy: 0.7887\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6460 - accuracy: 0.7042\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6806 - accuracy: 0.6338\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4959 - accuracy: 0.7324\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5242 - accuracy: 0.7183\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.75 - 0s 71us/sample - loss: 0.5520 - accuracy: 0.7042\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5443 - accuracy: 0.7465\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5609 - accuracy: 0.7183\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5833 - accuracy: 0.7042\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4969 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5300 - accuracy: 0.6901\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5264 - accuracy: 0.6901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5407 - accuracy: 0.7324\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5366 - accuracy: 0.7042\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5561 - accuracy: 0.7324\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5040 - accuracy: 0.7606\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5420 - accuracy: 0.7183\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5890 - accuracy: 0.7183\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5382 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5883 - accuracy: 0.6901\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.4993 - accuracy: 0.7324\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4879 - accuracy: 0.7606\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5298 - accuracy: 0.7183\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5398 - accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 100us/sample - loss: 0.5151 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 0.4871 - accuracy: 0.7746\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5604 - accuracy: 0.6479\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.5265 - accuracy: 0.7324\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5220 - accuracy: 0.7606\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5086 - accuracy: 0.7324\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 0.5334 - accuracy: 0.7042\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5534 - accuracy: 0.7183\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.4809 - accuracy: 0.7746\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5018 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5581 - accuracy: 0.7042\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 93us/sample - loss: 0.5062 - accuracy: 0.7183\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5178 - accuracy: 0.7606\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.5029 - accuracy: 0.6901\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 96us/sample - loss: 0.5194 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5402 - accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.4710 - accuracy: 0.7606\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5150 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5123 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5404 - accuracy: 0.7042\n",
      "18/18 [==============================] - 0s 5ms/sample - loss: 1.5008 - accuracy: 0.5556\n",
      "--- Starting trial: run-57\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 6ms/sample - loss: 1.8025 - accuracy: 0.5352\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.0031 - accuracy: 0.4366\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.8969 - accuracy: 0.4930\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.1000 - accuracy: 0.4507\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.8786 - accuracy: 0.5070\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.7937 - accuracy: 0.4930\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.9749 - accuracy: 0.4648\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6280 - accuracy: 0.4789\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.6080 - accuracy: 0.5211\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.4705 - accuracy: 0.4507\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.4676 - accuracy: 0.5915\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.8963 - accuracy: 0.4507\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.4923 - accuracy: 0.5493\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.4380 - accuracy: 0.5211\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.3399 - accuracy: 0.5493\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.2601 - accuracy: 0.5775\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2866 - accuracy: 0.5775\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2190 - accuracy: 0.5634\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1629 - accuracy: 0.5070\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0250 - accuracy: 0.6056\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.3901 - accuracy: 0.4507\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.5106 - accuracy: 0.4789\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0121 - accuracy: 0.6056\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.1952 - accuracy: 0.5352\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9939 - accuracy: 0.5775\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.3233 - accuracy: 0.4789\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.0848 - accuracy: 0.5070\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.0642 - accuracy: 0.5352\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9643 - accuracy: 0.5634\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8799 - accuracy: 0.6620\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9545 - accuracy: 0.5915\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.0095 - accuracy: 0.5352\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8246 - accuracy: 0.6056\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1511 - accuracy: 0.5070\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7815 - accuracy: 0.5634\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1660 - accuracy: 0.5775\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9493 - accuracy: 0.5775\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7082 - accuracy: 0.6901\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.0170 - accuracy: 0.5493\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9599 - accuracy: 0.5352\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9461 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9690 - accuracy: 0.5070\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7724 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9596 - accuracy: 0.6197\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7417 - accuracy: 0.6338\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8242 - accuracy: 0.6479\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7852 - accuracy: 0.6197\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8742 - accuracy: 0.5775\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7994 - accuracy: 0.6197\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9295 - accuracy: 0.5915\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7291 - accuracy: 0.6338\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8189 - accuracy: 0.5775\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8811 - accuracy: 0.5915\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8961 - accuracy: 0.5211\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8756 - accuracy: 0.5634\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7263 - accuracy: 0.5775\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6739 - accuracy: 0.6901\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6466 - accuracy: 0.6620\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6917 - accuracy: 0.6479\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7553 - accuracy: 0.5634\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7305 - accuracy: 0.5915\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7685 - accuracy: 0.6197\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7341 - accuracy: 0.6197\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6445 - accuracy: 0.6338\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7948 - accuracy: 0.5634\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6639 - accuracy: 0.7183\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.5944 - accuracy: 0.7042\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5375 - accuracy: 0.7606\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6463 - accuracy: 0.6479\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7344 - accuracy: 0.6338\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7447 - accuracy: 0.6197\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6739 - accuracy: 0.6479\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7371 - accuracy: 0.6479\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5786 - accuracy: 0.6901\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6219 - accuracy: 0.6056\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6513 - accuracy: 0.7183\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5661 - accuracy: 0.7183\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5694 - accuracy: 0.6620\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5296 - accuracy: 0.7042\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5265 - accuracy: 0.7887\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6427 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4749 - accuracy: 0.7887\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7486 - accuracy: 0.5915\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5273 - accuracy: 0.7324\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4705 - accuracy: 0.7465\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5332 - accuracy: 0.7746\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5183 - accuracy: 0.7465\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6260 - accuracy: 0.6901\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4580 - accuracy: 0.7746\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4890 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6610 - accuracy: 0.6761\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4985 - accuracy: 0.7465\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4993 - accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5660 - accuracy: 0.7746\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4963 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5584 - accuracy: 0.7042\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5242 - accuracy: 0.7606\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6089 - accuracy: 0.6338\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5994 - accuracy: 0.7042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4576 - accuracy: 0.7746\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8378 - accuracy: 0.6111\n",
      "--- Starting trial: run-58\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.0386 - accuracy: 0.5070\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 2.0308 - accuracy: 0.4366\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 56us/sample - loss: 1.9481 - accuracy: 0.4366\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.7865 - accuracy: 0.5775\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.8310 - accuracy: 0.5775\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.8958 - accuracy: 0.4789\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 57us/sample - loss: 1.1807 - accuracy: 0.5352\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.6470 - accuracy: 0.5352\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 1.5812 - accuracy: 0.5352\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.7644 - accuracy: 0.5070\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.5851 - accuracy: 0.5352\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.6405 - accuracy: 0.6056\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.3409 - accuracy: 0.5634\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.3662 - accuracy: 0.5634\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.3036 - accuracy: 0.5493\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2953 - accuracy: 0.5775\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2629 - accuracy: 0.5070\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.2962 - accuracy: 0.5352\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.4463 - accuracy: 0.6056\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.4738 - accuracy: 0.4930\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.2347 - accuracy: 0.5775\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9898 - accuracy: 0.5634\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1714 - accuracy: 0.6901\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.7649 - accuracy: 0.6761\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.8440 - accuracy: 0.6197\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 1.2578 - accuracy: 0.6056\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.2595 - accuracy: 0.5775\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.0483 - accuracy: 0.5634\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8694 - accuracy: 0.6197\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7854 - accuracy: 0.6056\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9522 - accuracy: 0.6197\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0536 - accuracy: 0.5634\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 1.0226 - accuracy: 0.6338\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9242 - accuracy: 0.6338\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.7098 - accuracy: 0.7042\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6627 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9115 - accuracy: 0.6338\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.8617 - accuracy: 0.6761\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8884 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.9965 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9111 - accuracy: 0.5775\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8233 - accuracy: 0.5915\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.0405 - accuracy: 0.6197\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9362 - accuracy: 0.5915\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.1148 - accuracy: 0.6338\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.7771 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.9724 - accuracy: 0.6620\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.6940 - accuracy: 0.6901\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.9004 - accuracy: 0.5493\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 55us/sample - loss: 0.6891 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.8622 - accuracy: 0.6761\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8571 - accuracy: 0.5634\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6525 - accuracy: 0.6620\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7382 - accuracy: 0.6901\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 0.6151 - accuracy: 0.6620\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7011 - accuracy: 0.7324\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.8790 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8596 - accuracy: 0.6197\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6419 - accuracy: 0.6620\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6642 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7182 - accuracy: 0.6761\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8007 - accuracy: 0.6620\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8712 - accuracy: 0.5493\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7509 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6653 - accuracy: 0.6479\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 95us/sample - loss: 0.6211 - accuracy: 0.7465\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8918 - accuracy: 0.6338\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7441 - accuracy: 0.6197\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7294 - accuracy: 0.6620\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6479 - accuracy: 0.7183\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8050 - accuracy: 0.6197\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7039 - accuracy: 0.6761\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7461 - accuracy: 0.6620\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6712 - accuracy: 0.7042\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6513 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6086 - accuracy: 0.7465\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6606 - accuracy: 0.7465\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6592 - accuracy: 0.6761\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5953 - accuracy: 0.7042\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5825 - accuracy: 0.6761\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7019 - accuracy: 0.7042\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7962 - accuracy: 0.6901\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6106 - accuracy: 0.7465\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7173 - accuracy: 0.7042\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5535 - accuracy: 0.7042\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7058 - accuracy: 0.6338\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6659 - accuracy: 0.6901\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6571 - accuracy: 0.7465\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8071 - accuracy: 0.6197\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7524 - accuracy: 0.6338\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6844 - accuracy: 0.7042\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6205 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5561 - accuracy: 0.7042\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5500 - accuracy: 0.7324\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6759 - accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6091 - accuracy: 0.7183\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5837 - accuracy: 0.7324\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6159 - accuracy: 0.6620\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7748 - accuracy: 0.6620\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6026 - accuracy: 0.7465\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.8601 - accuracy: 0.5556\n",
      "--- Starting trial: run-59\n",
      "{'num_units 1': 16, 'num_units 2': 4, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 4.5584 - accuracy: 0.3239\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.8886 - accuracy: 0.3380\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.9312 - accuracy: 0.3803\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.0798 - accuracy: 0.3239\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 1.4185 - accuracy: 0.4225\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.6202 - accuracy: 0.3944\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2132 - accuracy: 0.4366\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9914 - accuracy: 0.5352\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9614 - accuracy: 0.4930\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9079 - accuracy: 0.4789\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9324 - accuracy: 0.4930\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.9542 - accuracy: 0.3662\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8446 - accuracy: 0.5070\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8451 - accuracy: 0.5493\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7581 - accuracy: 0.5915\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.8371 - accuracy: 0.5211\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7794 - accuracy: 0.5493\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7716 - accuracy: 0.5211\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6974 - accuracy: 0.6338\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7466 - accuracy: 0.4930\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7746 - accuracy: 0.5775\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7777 - accuracy: 0.5915\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7536 - accuracy: 0.5634\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7560 - accuracy: 0.5634\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7194 - accuracy: 0.5634\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8096 - accuracy: 0.6197\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7851 - accuracy: 0.5634\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6862 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7254 - accuracy: 0.6197\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6997 - accuracy: 0.6620\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7533 - accuracy: 0.5634\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6885 - accuracy: 0.5915\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7514 - accuracy: 0.5775\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7382 - accuracy: 0.6056\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6789 - accuracy: 0.6338\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6692 - accuracy: 0.7183\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6954 - accuracy: 0.5493\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6911 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6848 - accuracy: 0.6338\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6777 - accuracy: 0.6056\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7171 - accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6797 - accuracy: 0.6479\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6910 - accuracy: 0.6479\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6867 - accuracy: 0.6338\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.7004 - accuracy: 0.6197\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6885 - accuracy: 0.6479\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6777 - accuracy: 0.6479\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6797 - accuracy: 0.6479\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6500 - accuracy: 0.7042\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6916 - accuracy: 0.6620\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6771 - accuracy: 0.6479\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6739 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6594 - accuracy: 0.6901\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6945 - accuracy: 0.6338\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6563 - accuracy: 0.6761\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6582 - accuracy: 0.6056\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6732 - accuracy: 0.6338\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6672 - accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6510 - accuracy: 0.6620\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6755 - accuracy: 0.6620\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6688 - accuracy: 0.6620\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6914 - accuracy: 0.6620\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6710 - accuracy: 0.6479\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6551 - accuracy: 0.6620\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6636 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6734 - accuracy: 0.6338\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6688 - accuracy: 0.6620\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7062 - accuracy: 0.6338\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6737 - accuracy: 0.6479\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6854 - accuracy: 0.6479\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6603 - accuracy: 0.6479\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 57us/sample - loss: 0.6498 - accuracy: 0.6620\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6455 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6530 - accuracy: 0.6620\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6641 - accuracy: 0.6761\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6800 - accuracy: 0.6479\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6714 - accuracy: 0.6197\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6693 - accuracy: 0.6479\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6495 - accuracy: 0.6620\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6620 - accuracy: 0.6479\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6304 - accuracy: 0.6901\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6651 - accuracy: 0.6479\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6648 - accuracy: 0.6479\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6550 - accuracy: 0.6479\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6480 - accuracy: 0.6761\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6417 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6620 - accuracy: 0.6761\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6492 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6551 - accuracy: 0.6761\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6805 - accuracy: 0.6338\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6633 - accuracy: 0.6338\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6592 - accuracy: 0.6620\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6462 - accuracy: 0.6761\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6673 - accuracy: 0.6479\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6249 - accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6248 - accuracy: 0.6901\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6699 - accuracy: 0.6479\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6393 - accuracy: 0.6620\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6576 - accuracy: 0.6479\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6663 - accuracy: 0.6197\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.6390 - accuracy: 0.6111\n",
      "--- Starting trial: run-60\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 1.8152 - accuracy: 0.4648\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 1.8500 - accuracy: 0.4648\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.4513 - accuracy: 0.5211\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.4981 - accuracy: 0.4507\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3334 - accuracy: 0.5211\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.4413 - accuracy: 0.5493\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3050 - accuracy: 0.5775\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.4167 - accuracy: 0.4789\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0949 - accuracy: 0.5070\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9838 - accuracy: 0.5634\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.0678 - accuracy: 0.5070\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.2607 - accuracy: 0.4930\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.1141 - accuracy: 0.6056\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.9553 - accuracy: 0.5352\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6386 - accuracy: 0.6761\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9286 - accuracy: 0.6338\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9320 - accuracy: 0.6338\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7897 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9327 - accuracy: 0.5915\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7957 - accuracy: 0.6761\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6514 - accuracy: 0.7042\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7882 - accuracy: 0.6620\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7699 - accuracy: 0.6620\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7200 - accuracy: 0.6479\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.8581 - accuracy: 0.6479\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7754 - accuracy: 0.6761\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6406 - accuracy: 0.7183\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6574 - accuracy: 0.7887\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7050 - accuracy: 0.6620\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6547 - accuracy: 0.7746\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6126 - accuracy: 0.7324\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7422 - accuracy: 0.7183\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7384 - accuracy: 0.6197\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7075 - accuracy: 0.6620\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5932 - accuracy: 0.7465\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6452 - accuracy: 0.6761\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.7825 - accuracy: 0.7042\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7534 - accuracy: 0.7042\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6279 - accuracy: 0.7042\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4802 - accuracy: 0.8310\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6427 - accuracy: 0.7042\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6501 - accuracy: 0.7183\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5789 - accuracy: 0.7042\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6311 - accuracy: 0.7465\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5172 - accuracy: 0.8028\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5467 - accuracy: 0.7606\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5050 - accuracy: 0.7746\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5356 - accuracy: 0.7606\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4872 - accuracy: 0.8169\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6964 - accuracy: 0.7606\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5377 - accuracy: 0.7324\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6133 - accuracy: 0.7183\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5183 - accuracy: 0.7606\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4616 - accuracy: 0.8028\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4476 - accuracy: 0.7887\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4444 - accuracy: 0.7465\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4664 - accuracy: 0.7887\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5101 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4905 - accuracy: 0.8169\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4880 - accuracy: 0.8028\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5105 - accuracy: 0.7746\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4812 - accuracy: 0.8028\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5567 - accuracy: 0.7746\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4531 - accuracy: 0.7746\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4481 - accuracy: 0.7887\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4761 - accuracy: 0.7746\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4147 - accuracy: 0.8028\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4142 - accuracy: 0.8451\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4022 - accuracy: 0.8592\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3493 - accuracy: 0.8732\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5380 - accuracy: 0.7606\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4689 - accuracy: 0.7746\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4087 - accuracy: 0.8028\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3946 - accuracy: 0.7746\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5447 - accuracy: 0.7746\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5476 - accuracy: 0.7606\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.3936 - accuracy: 0.8732\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.4115 - accuracy: 0.8169\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4205 - accuracy: 0.8169\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3746 - accuracy: 0.8873\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3970 - accuracy: 0.8169\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3898 - accuracy: 0.8592\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3604 - accuracy: 0.8451\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.3349 - accuracy: 0.8732\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3905 - accuracy: 0.8310\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4034 - accuracy: 0.8169\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4506 - accuracy: 0.8169\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.3794 - accuracy: 0.8310\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.4609 - accuracy: 0.8310\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.3773 - accuracy: 0.8592\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4604 - accuracy: 0.7746\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3986 - accuracy: 0.8310\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.3812 - accuracy: 0.8310\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3854 - accuracy: 0.8451\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4903 - accuracy: 0.7887\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.3983 - accuracy: 0.8169\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.2880 - accuracy: 0.8873\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3586 - accuracy: 0.8592\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.3657 - accuracy: 0.8310\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.3366 - accuracy: 0.8592\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.6107 - accuracy: 0.4444\n",
      "--- Starting trial: run-61\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 4.0834 - accuracy: 0.3239\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 3.6729 - accuracy: 0.3803\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 3.5048 - accuracy: 0.3662\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 3.0333 - accuracy: 0.3944\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.6922 - accuracy: 0.4085\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.9832 - accuracy: 0.3521\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.6439 - accuracy: 0.3380\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.7138 - accuracy: 0.3239\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 2.4671 - accuracy: 0.4085\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.3808 - accuracy: 0.4225\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.3761 - accuracy: 0.4225\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.0354 - accuracy: 0.4085\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.8462 - accuracy: 0.5211\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.0628 - accuracy: 0.5070\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.8923 - accuracy: 0.4366\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.7359 - accuracy: 0.4648\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 66us/sample - loss: 1.7257 - accuracy: 0.4789\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.5880 - accuracy: 0.4789\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6845 - accuracy: 0.5211\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5811 - accuracy: 0.5211\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5019 - accuracy: 0.5070\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.3302 - accuracy: 0.6197\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.4270 - accuracy: 0.5211\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2727 - accuracy: 0.5634\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2650 - accuracy: 0.5352\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1485 - accuracy: 0.6479\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1774 - accuracy: 0.5634\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0882 - accuracy: 0.5775\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0732 - accuracy: 0.5352\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0830 - accuracy: 0.5634\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0694 - accuracy: 0.5493\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0461 - accuracy: 0.5493\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.8708 - accuracy: 0.5634\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9203 - accuracy: 0.5634\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9721 - accuracy: 0.5634\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0038 - accuracy: 0.5775\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1759 - accuracy: 0.5915\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8648 - accuracy: 0.6338\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8327 - accuracy: 0.6761\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9384 - accuracy: 0.6197\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7465 - accuracy: 0.5915\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7832 - accuracy: 0.6338\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.8255 - accuracy: 0.5915\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8896 - accuracy: 0.6056\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.8776 - accuracy: 0.6056\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7824 - accuracy: 0.6620\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.7721 - accuracy: 0.6761\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9086 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7516 - accuracy: 0.6197\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7566 - accuracy: 0.6479\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9205 - accuracy: 0.6197\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7514 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8814 - accuracy: 0.6338\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6750 - accuracy: 0.6901\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7034 - accuracy: 0.6901\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7266 - accuracy: 0.7042\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6690 - accuracy: 0.6901\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6885 - accuracy: 0.6338\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5847 - accuracy: 0.7324\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7978 - accuracy: 0.6056\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6438 - accuracy: 0.6056\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7498 - accuracy: 0.6901\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7433 - accuracy: 0.6761\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7876 - accuracy: 0.6056\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7447 - accuracy: 0.6197\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7243 - accuracy: 0.6479\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6014 - accuracy: 0.6901\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7767 - accuracy: 0.6197\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7051 - accuracy: 0.6197\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7163 - accuracy: 0.6056\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6474 - accuracy: 0.6479\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6751 - accuracy: 0.7042\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6966 - accuracy: 0.6620\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5476 - accuracy: 0.7183\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6888 - accuracy: 0.6901\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6424 - accuracy: 0.7183\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5885 - accuracy: 0.6901\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4884 - accuracy: 0.7465\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5247 - accuracy: 0.7887\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5342 - accuracy: 0.7183\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5047 - accuracy: 0.7324\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5077 - accuracy: 0.7042\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6644 - accuracy: 0.7042\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4686 - accuracy: 0.7324\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6513 - accuracy: 0.6901\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6719 - accuracy: 0.6620\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5264 - accuracy: 0.7042\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.5045 - accuracy: 0.7465\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4643 - accuracy: 0.7746\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5555 - accuracy: 0.6901\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6371 - accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6512 - accuracy: 0.7042\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4439 - accuracy: 0.7887\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6344 - accuracy: 0.7606\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5003 - accuracy: 0.7042\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5930 - accuracy: 0.7183\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4218 - accuracy: 0.8169\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5145 - accuracy: 0.6761\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5187 - accuracy: 0.7042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4966 - accuracy: 0.7746\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.0559 - accuracy: 0.5000\n",
      "--- Starting trial: run-62\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.5757 - accuracy: 0.6197\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3973 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.4215 - accuracy: 0.6056\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2284 - accuracy: 0.5915\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.2452 - accuracy: 0.6479\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2294 - accuracy: 0.6197\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.0802 - accuracy: 0.6620\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8665 - accuracy: 0.6761\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 1.0547 - accuracy: 0.6338\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.9025 - accuracy: 0.6620\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0013 - accuracy: 0.6197\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8007 - accuracy: 0.6761\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8863 - accuracy: 0.6761\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8548 - accuracy: 0.6901\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7649 - accuracy: 0.6761\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7608 - accuracy: 0.6338\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7903 - accuracy: 0.6761\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7506 - accuracy: 0.6761\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6933 - accuracy: 0.6761\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6749 - accuracy: 0.7042\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6475 - accuracy: 0.7606\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6419 - accuracy: 0.7042\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6469 - accuracy: 0.6901\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6075 - accuracy: 0.6901\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6121 - accuracy: 0.7042\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6098 - accuracy: 0.7606\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5678 - accuracy: 0.7465\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5064 - accuracy: 0.7606\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6027 - accuracy: 0.7324\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6071 - accuracy: 0.7746\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5250 - accuracy: 0.7465\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5112 - accuracy: 0.7606\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5873 - accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5370 - accuracy: 0.7465\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5161 - accuracy: 0.7746\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4994 - accuracy: 0.7746\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4748 - accuracy: 0.8028\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4767 - accuracy: 0.8028\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4709 - accuracy: 0.7746\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4718 - accuracy: 0.8028\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4527 - accuracy: 0.7606\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4901 - accuracy: 0.7324\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5629 - accuracy: 0.7465\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.87 - 0s 62us/sample - loss: 0.4408 - accuracy: 0.8028\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5198 - accuracy: 0.7887\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5254 - accuracy: 0.7746\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4447 - accuracy: 0.8028\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.4458 - accuracy: 0.7887\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4564 - accuracy: 0.8028\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4598 - accuracy: 0.7746\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4029 - accuracy: 0.8310\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4993 - accuracy: 0.7606\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4244 - accuracy: 0.8028\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4025 - accuracy: 0.7887\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5280 - accuracy: 0.7746\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4354 - accuracy: 0.7746\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4823 - accuracy: 0.7183\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4071 - accuracy: 0.8169\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3947 - accuracy: 0.8028\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4012 - accuracy: 0.7887\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4304 - accuracy: 0.7887\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.3820 - accuracy: 0.8310\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4543 - accuracy: 0.7324\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4194 - accuracy: 0.8028\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.3695 - accuracy: 0.8028\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4212 - accuracy: 0.7887\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4184 - accuracy: 0.7887\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3998 - accuracy: 0.8028\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4512 - accuracy: 0.8451\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4049 - accuracy: 0.8451\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4199 - accuracy: 0.8310\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4400 - accuracy: 0.7887\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 62us/sample - loss: 0.3652 - accuracy: 0.8310\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4074 - accuracy: 0.8028\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4856 - accuracy: 0.7887\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4075 - accuracy: 0.8310\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.3460 - accuracy: 0.8873\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4543 - accuracy: 0.7746\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.3923 - accuracy: 0.8169\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.3982 - accuracy: 0.8592\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3764 - accuracy: 0.8310\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.3590 - accuracy: 0.8169\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.3455 - accuracy: 0.8310\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3644 - accuracy: 0.8028\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.3635 - accuracy: 0.8310\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3501 - accuracy: 0.8732\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.3865 - accuracy: 0.7606\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.3908 - accuracy: 0.8028\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3395 - accuracy: 0.8732\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.3773 - accuracy: 0.8169\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.3713 - accuracy: 0.8169\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3811 - accuracy: 0.8873\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.3558 - accuracy: 0.8592\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3782 - accuracy: 0.8028\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.3545 - accuracy: 0.8592\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3911 - accuracy: 0.8310\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4007 - accuracy: 0.8028\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4046 - accuracy: 0.7887\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.3861 - accuracy: 0.8169\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3596 - accuracy: 0.8169\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.0444 - accuracy: 0.6111\n",
      "--- Starting trial: run-63\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 5.5610 - accuracy: 0.3521\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 4.6325 - accuracy: 0.3380\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 4.7630 - accuracy: 0.3521\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 4.2152 - accuracy: 0.3521\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.8962 - accuracy: 0.3521\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 3.7839 - accuracy: 0.3380\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 3.8448 - accuracy: 0.3380\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 3.5790 - accuracy: 0.3099\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 3.3386 - accuracy: 0.3380\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 3.2333 - accuracy: 0.3380\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.9761 - accuracy: 0.3944\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 3.0081 - accuracy: 0.3099\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.7593 - accuracy: 0.3521\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.5889 - accuracy: 0.3944\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.6984 - accuracy: 0.3662\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 2.4012 - accuracy: 0.3803\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 2.1111 - accuracy: 0.4085\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 2.3254 - accuracy: 0.4085\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.0976 - accuracy: 0.4507\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.8479 - accuracy: 0.4789\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.6554 - accuracy: 0.4507\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5275 - accuracy: 0.4789\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3007 - accuracy: 0.4789\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.3978 - accuracy: 0.5352\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3791 - accuracy: 0.4366\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9452 - accuracy: 0.5493\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.2580 - accuracy: 0.6056\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0847 - accuracy: 0.5775\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0150 - accuracy: 0.5634\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0583 - accuracy: 0.5634\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9028 - accuracy: 0.5915\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8397 - accuracy: 0.5915\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9167 - accuracy: 0.6056\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8952 - accuracy: 0.5915\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8914 - accuracy: 0.6479\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8057 - accuracy: 0.6620\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9010 - accuracy: 0.6620\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7628 - accuracy: 0.6056\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7494 - accuracy: 0.6479\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8223 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7049 - accuracy: 0.6901\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6648 - accuracy: 0.7324\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6648 - accuracy: 0.7042\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5787 - accuracy: 0.7042\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7228 - accuracy: 0.7042\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5828 - accuracy: 0.7042\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6071 - accuracy: 0.7465\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4954 - accuracy: 0.7465\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5428 - accuracy: 0.7324\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5216 - accuracy: 0.7746\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5160 - accuracy: 0.7746\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5295 - accuracy: 0.7887\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6146 - accuracy: 0.7606\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4859 - accuracy: 0.8169\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6357 - accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4530 - accuracy: 0.8028\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5031 - accuracy: 0.7606\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5008 - accuracy: 0.8310\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4429 - accuracy: 0.8310\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5112 - accuracy: 0.8028\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4729 - accuracy: 0.7746\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4416 - accuracy: 0.8169\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4368 - accuracy: 0.8592\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4258 - accuracy: 0.8169\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4443 - accuracy: 0.8451\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4706 - accuracy: 0.8169\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4560 - accuracy: 0.7746\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4522 - accuracy: 0.7887\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4285 - accuracy: 0.8028\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.3859 - accuracy: 0.8732\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5878 - accuracy: 0.8028\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.3689 - accuracy: 0.8873\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4221 - accuracy: 0.8169\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4227 - accuracy: 0.8310\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4943 - accuracy: 0.8028\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3972 - accuracy: 0.8169\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3806 - accuracy: 0.8310\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5308 - accuracy: 0.8310\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5419 - accuracy: 0.8451\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.3804 - accuracy: 0.8732\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.4709 - accuracy: 0.7606\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4807 - accuracy: 0.7887\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.3863 - accuracy: 0.8169\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4057 - accuracy: 0.8310\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3163 - accuracy: 0.8873\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.3278 - accuracy: 0.9014\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3487 - accuracy: 0.8873\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.3807 - accuracy: 0.8451\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.3748 - accuracy: 0.8732\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.3853 - accuracy: 0.8732\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.3295 - accuracy: 0.8592\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4027 - accuracy: 0.8028\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.3500 - accuracy: 0.8592\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4368 - accuracy: 0.8451\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.3303 - accuracy: 0.8873\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.3281 - accuracy: 0.8873\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3039 - accuracy: 0.9014\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3675 - accuracy: 0.8592\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4283 - accuracy: 0.8873\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.3285 - accuracy: 0.9014\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.7485 - accuracy: 0.4444\n",
      "--- Starting trial: run-64\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 1s 8ms/sample - loss: 1.4623 - accuracy: 0.3944\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.5437 - accuracy: 0.3944\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.3093 - accuracy: 0.4085\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.3108 - accuracy: 0.4085\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3742 - accuracy: 0.3662\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3981 - accuracy: 0.4085\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2815 - accuracy: 0.3803\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.2089 - accuracy: 0.4789\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1544 - accuracy: 0.4366\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1002 - accuracy: 0.4085\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0541 - accuracy: 0.4648\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 1.0473 - accuracy: 0.4648\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0045 - accuracy: 0.4648\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9385 - accuracy: 0.5070\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8625 - accuracy: 0.4930\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9823 - accuracy: 0.4366\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8016 - accuracy: 0.5493\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8839 - accuracy: 0.5352\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8829 - accuracy: 0.4789\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8297 - accuracy: 0.5352\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8228 - accuracy: 0.4930\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7902 - accuracy: 0.5211\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7496 - accuracy: 0.5352\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8075 - accuracy: 0.4789\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7837 - accuracy: 0.4789\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7286 - accuracy: 0.5352\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7164 - accuracy: 0.5493\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6845 - accuracy: 0.5775\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7880 - accuracy: 0.5211\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6816 - accuracy: 0.5493\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6658 - accuracy: 0.5915\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6907 - accuracy: 0.5634\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6482 - accuracy: 0.6338\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6194 - accuracy: 0.6761\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6538 - accuracy: 0.6479\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6937 - accuracy: 0.5634\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6353 - accuracy: 0.5915\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7250 - accuracy: 0.5915\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5826 - accuracy: 0.6338\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5860 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5613 - accuracy: 0.6901\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6296 - accuracy: 0.6338\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6040 - accuracy: 0.7042\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5958 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6057 - accuracy: 0.6479\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5941 - accuracy: 0.7042\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5659 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5339 - accuracy: 0.6761\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5568 - accuracy: 0.6479\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5672 - accuracy: 0.7042\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5349 - accuracy: 0.6761\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5678 - accuracy: 0.6620\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5229 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5196 - accuracy: 0.7042\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5921 - accuracy: 0.5915\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5025 - accuracy: 0.7324\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5436 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5000 - accuracy: 0.8028\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5278 - accuracy: 0.7042\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.5117 - accuracy: 0.7183\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4983 - accuracy: 0.7183\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5582 - accuracy: 0.7042\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5117 - accuracy: 0.7042\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5078 - accuracy: 0.7606\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5287 - accuracy: 0.6901\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4835 - accuracy: 0.7606\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5678 - accuracy: 0.6620\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5581 - accuracy: 0.6761\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5377 - accuracy: 0.6620\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5355 - accuracy: 0.7042\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4700 - accuracy: 0.7465\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5416 - accuracy: 0.7183\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5073 - accuracy: 0.7606\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5314 - accuracy: 0.7606\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4547 - accuracy: 0.7606\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4918 - accuracy: 0.7042\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4983 - accuracy: 0.7465\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4994 - accuracy: 0.7324\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4740 - accuracy: 0.7606\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4769 - accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4574 - accuracy: 0.7183\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4859 - accuracy: 0.7465\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4474 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.4415 - accuracy: 0.8169\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4509 - accuracy: 0.7887\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.4883 - accuracy: 0.7042\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.84 - 0s 71us/sample - loss: 0.4474 - accuracy: 0.7746\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4816 - accuracy: 0.7606\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4564 - accuracy: 0.7465\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4422 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4645 - accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4422 - accuracy: 0.7887\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4807 - accuracy: 0.7324\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.4602 - accuracy: 0.7465\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.4332 - accuracy: 0.7606\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4103 - accuracy: 0.7887\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4480 - accuracy: 0.7887\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4508 - accuracy: 0.7746\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4259 - accuracy: 0.7887\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4159 - accuracy: 0.8028\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.6459 - accuracy: 0.4444\n",
      "--- Starting trial: run-65\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.1, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.4627 - accuracy: 0.4648\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0492 - accuracy: 0.5352\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.8122 - accuracy: 0.6620\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7583 - accuracy: 0.6761\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7149 - accuracy: 0.6338\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7539 - accuracy: 0.6197\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7136 - accuracy: 0.6479\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6208 - accuracy: 0.6901\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6477 - accuracy: 0.6620\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6782 - accuracy: 0.6338\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6459 - accuracy: 0.6901\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6556 - accuracy: 0.6338\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6359 - accuracy: 0.6620\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6398 - accuracy: 0.6761\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6064 - accuracy: 0.7183\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5758 - accuracy: 0.6761\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5896 - accuracy: 0.7183\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6162 - accuracy: 0.6761\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5546 - accuracy: 0.7324\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5743 - accuracy: 0.7042\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6029 - accuracy: 0.7042\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5575 - accuracy: 0.7465\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6038 - accuracy: 0.7042\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5313 - accuracy: 0.7465\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5185 - accuracy: 0.7746\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5214 - accuracy: 0.7465\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5275 - accuracy: 0.7465\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5200 - accuracy: 0.7183\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5576 - accuracy: 0.7042\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6218 - accuracy: 0.7324\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5235 - accuracy: 0.7324\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5457 - accuracy: 0.7324\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5413 - accuracy: 0.7465\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5460 - accuracy: 0.7465\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5286 - accuracy: 0.7324\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5096 - accuracy: 0.7183\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5129 - accuracy: 0.7465\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4745 - accuracy: 0.7887\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5627 - accuracy: 0.7183\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5367 - accuracy: 0.7465\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4663 - accuracy: 0.8169\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5325 - accuracy: 0.7465\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5273 - accuracy: 0.7465\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4421 - accuracy: 0.7887\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4368 - accuracy: 0.7887\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4575 - accuracy: 0.8169\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5433 - accuracy: 0.7465\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4229 - accuracy: 0.8028\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4631 - accuracy: 0.8028\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4843 - accuracy: 0.7746\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4785 - accuracy: 0.7606\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4595 - accuracy: 0.8028\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4398 - accuracy: 0.7887\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4997 - accuracy: 0.8028\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4656 - accuracy: 0.7887\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4615 - accuracy: 0.7606\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4408 - accuracy: 0.8310\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4212 - accuracy: 0.8169\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4264 - accuracy: 0.7746\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4188 - accuracy: 0.8169\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4430 - accuracy: 0.7746\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4527 - accuracy: 0.7746\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4131 - accuracy: 0.7887\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4434 - accuracy: 0.7606\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4233 - accuracy: 0.7887\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4747 - accuracy: 0.7465\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5115 - accuracy: 0.7324\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4063 - accuracy: 0.8028\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4319 - accuracy: 0.7746\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4115 - accuracy: 0.8028\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4121 - accuracy: 0.8592\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4382 - accuracy: 0.8028\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4064 - accuracy: 0.8169\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.3958 - accuracy: 0.8169\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4264 - accuracy: 0.8169\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4055 - accuracy: 0.8028\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3833 - accuracy: 0.8028\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4401 - accuracy: 0.8028\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.3721 - accuracy: 0.8310\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.3974 - accuracy: 0.8310\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4123 - accuracy: 0.8169\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.3775 - accuracy: 0.8310\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4019 - accuracy: 0.8310\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.3825 - accuracy: 0.8310\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.3967 - accuracy: 0.8310\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4153 - accuracy: 0.8169\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4118 - accuracy: 0.7887\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.3946 - accuracy: 0.8310\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3956 - accuracy: 0.8451\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4074 - accuracy: 0.8028\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.3870 - accuracy: 0.8451\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4213 - accuracy: 0.7887\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.3937 - accuracy: 0.8310\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4068 - accuracy: 0.8028\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.3767 - accuracy: 0.8592\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3784 - accuracy: 0.8592\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.3681 - accuracy: 0.8310\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4283 - accuracy: 0.8169\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.3794 - accuracy: 0.8310\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4182 - accuracy: 0.8310\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.5070 - accuracy: 0.5000\n",
      "--- Starting trial: run-66\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 2.2283 - accuracy: 0.3521\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 2.0676 - accuracy: 0.3521\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.9107 - accuracy: 0.4085\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.6003 - accuracy: 0.3944\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.6022 - accuracy: 0.5070\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.5560 - accuracy: 0.4366\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.5412 - accuracy: 0.4085\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2894 - accuracy: 0.4789\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2657 - accuracy: 0.4930\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2093 - accuracy: 0.5070\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.4571 - accuracy: 0.4789\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.6754 - accuracy: 0.4085\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.1799 - accuracy: 0.5493\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1212 - accuracy: 0.6056\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.1902 - accuracy: 0.5070\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.3688 - accuracy: 0.4648\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8750 - accuracy: 0.6338\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1227 - accuracy: 0.4930\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9736 - accuracy: 0.5634\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0969 - accuracy: 0.5493\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0829 - accuracy: 0.5775\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9168 - accuracy: 0.5775\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9565 - accuracy: 0.5493\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.1413 - accuracy: 0.5070\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0058 - accuracy: 0.5634\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9979 - accuracy: 0.5634\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.0103 - accuracy: 0.5634\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9116 - accuracy: 0.6197\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9276 - accuracy: 0.5352\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8021 - accuracy: 0.6761\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9688 - accuracy: 0.6338\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9011 - accuracy: 0.6056\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8723 - accuracy: 0.6901\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8030 - accuracy: 0.5775\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7774 - accuracy: 0.6479\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.0036 - accuracy: 0.5775\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8682 - accuracy: 0.6056\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8334 - accuracy: 0.6197\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7878 - accuracy: 0.5493\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7706 - accuracy: 0.5493\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8133 - accuracy: 0.5915\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8249 - accuracy: 0.6479\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8898 - accuracy: 0.5352\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6559 - accuracy: 0.6761\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7600 - accuracy: 0.6197\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7461 - accuracy: 0.6197\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8123 - accuracy: 0.6620\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.8783 - accuracy: 0.6197\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8524 - accuracy: 0.7183\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7176 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8670 - accuracy: 0.6479\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6921 - accuracy: 0.7324\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7869 - accuracy: 0.6197\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7092 - accuracy: 0.7042\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7148 - accuracy: 0.6197\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7853 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7822 - accuracy: 0.6338\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7588 - accuracy: 0.5775\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6903 - accuracy: 0.6620\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6737 - accuracy: 0.6901\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7675 - accuracy: 0.6761\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.7251 - accuracy: 0.6338\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8460 - accuracy: 0.6338\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5950 - accuracy: 0.7324\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6878 - accuracy: 0.7183\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6547 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6667 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6726 - accuracy: 0.6761\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.7691 - accuracy: 0.7183\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5959 - accuracy: 0.7042\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7378 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6918 - accuracy: 0.7042\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5514 - accuracy: 0.7746\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5638 - accuracy: 0.7324\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.5908 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5924 - accuracy: 0.7042\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8356 - accuracy: 0.6056\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5756 - accuracy: 0.7042\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6351 - accuracy: 0.7042\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4973 - accuracy: 0.8028\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6652 - accuracy: 0.6620\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4822 - accuracy: 0.7606\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7555 - accuracy: 0.6056\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6751 - accuracy: 0.6901\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5950 - accuracy: 0.6761\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6772 - accuracy: 0.6479\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6648 - accuracy: 0.7324\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6107 - accuracy: 0.6761\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6157 - accuracy: 0.7606\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7479 - accuracy: 0.6761\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5353 - accuracy: 0.7887\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5800 - accuracy: 0.7042\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5553 - accuracy: 0.7042\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5733 - accuracy: 0.7042\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6605 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5328 - accuracy: 0.7465\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5672 - accuracy: 0.6901\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6020 - accuracy: 0.6901\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5476 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4897 - accuracy: 0.8028\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.3130 - accuracy: 0.3889\n",
      "--- Starting trial: run-67\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.2583 - accuracy: 0.4366\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.4629 - accuracy: 0.6056\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 1.5567 - accuracy: 0.5775\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.5945 - accuracy: 0.5493\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.7901 - accuracy: 0.5915\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.3395 - accuracy: 0.6479\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.9695 - accuracy: 0.5493\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.2749 - accuracy: 0.5915\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1818 - accuracy: 0.5915\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.7121 - accuracy: 0.4930\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.5425 - accuracy: 0.5775\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.3538 - accuracy: 0.6479\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2092 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0565 - accuracy: 0.6620\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.2801 - accuracy: 0.5493\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.3911 - accuracy: 0.5775\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.3212 - accuracy: 0.6197\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0763 - accuracy: 0.5915\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1463 - accuracy: 0.6479\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8934 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 1.3342 - accuracy: 0.5634\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1321 - accuracy: 0.6338\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9149 - accuracy: 0.6479\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.0781 - accuracy: 0.6761\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.1537 - accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0075 - accuracy: 0.6197\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8465 - accuracy: 0.6620\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9165 - accuracy: 0.7042\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.3426 - accuracy: 0.5775\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9809 - accuracy: 0.6620\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1447 - accuracy: 0.5775\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 1.0262 - accuracy: 0.6479\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0555 - accuracy: 0.6479\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.0348 - accuracy: 0.6620\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.0763 - accuracy: 0.6197\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7957 - accuracy: 0.6620\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0126 - accuracy: 0.6056\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8633 - accuracy: 0.6901\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9028 - accuracy: 0.6338\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7861 - accuracy: 0.6761\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9701 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8506 - accuracy: 0.7042\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8299 - accuracy: 0.6901\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9974 - accuracy: 0.6197\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6915 - accuracy: 0.7324\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.1246 - accuracy: 0.6197\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7311 - accuracy: 0.7042\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7952 - accuracy: 0.6479\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8666 - accuracy: 0.6761\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8113 - accuracy: 0.6620\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8257 - accuracy: 0.6479\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5902 - accuracy: 0.7746\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6892 - accuracy: 0.6761\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9494 - accuracy: 0.6056\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7870 - accuracy: 0.6338\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9012 - accuracy: 0.6901\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8439 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9625 - accuracy: 0.7042\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8065 - accuracy: 0.6338\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9317 - accuracy: 0.6479\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7650 - accuracy: 0.6338\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8624 - accuracy: 0.6338\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6962 - accuracy: 0.7042\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6867 - accuracy: 0.7606\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6337 - accuracy: 0.6761\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5804 - accuracy: 0.7606\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5667 - accuracy: 0.7606\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6593 - accuracy: 0.7042\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9275 - accuracy: 0.6056\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6809 - accuracy: 0.6901\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5542 - accuracy: 0.6761\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7971 - accuracy: 0.6761\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6145 - accuracy: 0.7042\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.75 - 0s 71us/sample - loss: 0.7476 - accuracy: 0.7183\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7283 - accuracy: 0.6620\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5864 - accuracy: 0.7183\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6400 - accuracy: 0.7606\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6836 - accuracy: 0.6197\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7052 - accuracy: 0.6901\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5658 - accuracy: 0.7042\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6535 - accuracy: 0.7183\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5646 - accuracy: 0.7324\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5997 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6938 - accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5978 - accuracy: 0.7465\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.4885 - accuracy: 0.7746\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7034 - accuracy: 0.6479\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6110 - accuracy: 0.7606\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7122 - accuracy: 0.6620\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5200 - accuracy: 0.7324\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6674 - accuracy: 0.6620\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4713 - accuracy: 0.7606\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6706 - accuracy: 0.6056\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6149 - accuracy: 0.7324\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7361 - accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7620 - accuracy: 0.7324\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5299 - accuracy: 0.7183\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6184 - accuracy: 0.6901\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5301 - accuracy: 0.7183\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6882 - accuracy: 0.6620\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.2232 - accuracy: 0.5000\n",
      "--- Starting trial: run-68\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.001, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 3.4703 - accuracy: 0.3521\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.6319 - accuracy: 0.3803\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.7403 - accuracy: 0.4507\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.0388 - accuracy: 0.5493\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.2199 - accuracy: 0.5493\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0869 - accuracy: 0.5493\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8036 - accuracy: 0.6197\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9992 - accuracy: 0.5493\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9982 - accuracy: 0.6056\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6441 - accuracy: 0.6056\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6643 - accuracy: 0.7465\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8115 - accuracy: 0.6620\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6527 - accuracy: 0.6901\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9048 - accuracy: 0.5775\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.7792 - accuracy: 0.6056\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7866 - accuracy: 0.6620\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6407 - accuracy: 0.6620\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5830 - accuracy: 0.6761\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6349 - accuracy: 0.6761\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5459 - accuracy: 0.7183\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7347 - accuracy: 0.5915\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6649 - accuracy: 0.6620\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5439 - accuracy: 0.7042\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6661 - accuracy: 0.6761\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5621 - accuracy: 0.7183\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6303 - accuracy: 0.7042\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5796 - accuracy: 0.7183\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5107 - accuracy: 0.7324\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6661 - accuracy: 0.6761\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4162 - accuracy: 0.7746\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6284 - accuracy: 0.6761\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5166 - accuracy: 0.7746\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5539 - accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5836 - accuracy: 0.7042\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4776 - accuracy: 0.7606\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6409 - accuracy: 0.6338\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5171 - accuracy: 0.7606\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5632 - accuracy: 0.7042\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5199 - accuracy: 0.7183\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5613 - accuracy: 0.6901\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5631 - accuracy: 0.7746\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5380 - accuracy: 0.7324\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5779 - accuracy: 0.6901\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5342 - accuracy: 0.7746\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4448 - accuracy: 0.7887\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5316 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5267 - accuracy: 0.7042\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6266 - accuracy: 0.6901\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4807 - accuracy: 0.7606\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5176 - accuracy: 0.7746\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4388 - accuracy: 0.8028\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5587 - accuracy: 0.7042\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4910 - accuracy: 0.7606\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5141 - accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4564 - accuracy: 0.7746\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4906 - accuracy: 0.7324\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5469 - accuracy: 0.7324\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5168 - accuracy: 0.7465\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4061 - accuracy: 0.8028\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4015 - accuracy: 0.7887\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5055 - accuracy: 0.7183\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4786 - accuracy: 0.7324\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4513 - accuracy: 0.7465\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4930 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5065 - accuracy: 0.7465\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4987 - accuracy: 0.7042\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4429 - accuracy: 0.7183\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.4860 - accuracy: 0.7183\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4477 - accuracy: 0.7465\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.5182 - accuracy: 0.6901\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.4980 - accuracy: 0.7324\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.3933 - accuracy: 0.7606\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.4621 - accuracy: 0.7465\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4771 - accuracy: 0.7465\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.5189 - accuracy: 0.6761\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4746 - accuracy: 0.7324\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4349 - accuracy: 0.7746\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4666 - accuracy: 0.7465\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4764 - accuracy: 0.7324\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4063 - accuracy: 0.7606\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4128 - accuracy: 0.7606\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4872 - accuracy: 0.7183\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4322 - accuracy: 0.7606\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4412 - accuracy: 0.7606\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.4318 - accuracy: 0.7465\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3928 - accuracy: 0.8169\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4281 - accuracy: 0.8028\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4091 - accuracy: 0.7606\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4472 - accuracy: 0.7324\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4044 - accuracy: 0.7746\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4887 - accuracy: 0.7324\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.4528 - accuracy: 0.7606\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4697 - accuracy: 0.7324\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4828 - accuracy: 0.7465\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4310 - accuracy: 0.7746\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4724 - accuracy: 0.7465\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.3843 - accuracy: 0.7465\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4110 - accuracy: 0.7887\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.3957 - accuracy: 0.7746\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.3520 - accuracy: 0.8592\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.1725 - accuracy: 0.5000\n",
      "--- Starting trial: run-69\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 5ms/sample - loss: 3.1570 - accuracy: 0.3380\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.7222 - accuracy: 0.3380\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.4631 - accuracy: 0.3239\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 2.4659 - accuracy: 0.3380\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.2428 - accuracy: 0.3380\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 2.1698 - accuracy: 0.3380\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.1747 - accuracy: 0.3662\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 2.1408 - accuracy: 0.3521\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 1.7190 - accuracy: 0.3944\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6515 - accuracy: 0.3239\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6560 - accuracy: 0.3239\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.8112 - accuracy: 0.3380\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.8631 - accuracy: 0.3803\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.5467 - accuracy: 0.3944\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.5515 - accuracy: 0.3521\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3978 - accuracy: 0.3380\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.4516 - accuracy: 0.4789\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.2612 - accuracy: 0.4507\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.4447 - accuracy: 0.3662\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.3249 - accuracy: 0.4225\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 1.3906 - accuracy: 0.3803\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.2577 - accuracy: 0.4366\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.1241 - accuracy: 0.4366\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.2315 - accuracy: 0.4507\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.0033 - accuracy: 0.5634\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.2405 - accuracy: 0.5070\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.9994 - accuracy: 0.4648\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9948 - accuracy: 0.5070\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.1434 - accuracy: 0.3944\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.9743 - accuracy: 0.4507\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0653 - accuracy: 0.5775\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1355 - accuracy: 0.3944\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9301 - accuracy: 0.4648\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8623 - accuracy: 0.4930\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8721 - accuracy: 0.4648\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9553 - accuracy: 0.5493\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.9883 - accuracy: 0.3944\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8005 - accuracy: 0.5775\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8650 - accuracy: 0.5211\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7588 - accuracy: 0.5493\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.8307 - accuracy: 0.5915\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.8555 - accuracy: 0.5352\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8136 - accuracy: 0.6056\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7553 - accuracy: 0.5915\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7843 - accuracy: 0.6056\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7537 - accuracy: 0.5775\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8306 - accuracy: 0.6056\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7585 - accuracy: 0.6056\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8183 - accuracy: 0.5493\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7566 - accuracy: 0.5634\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8250 - accuracy: 0.5211\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8155 - accuracy: 0.5915\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8166 - accuracy: 0.5211\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7302 - accuracy: 0.5634\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7439 - accuracy: 0.5634\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8380 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7312 - accuracy: 0.5775\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6442 - accuracy: 0.6620\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6734 - accuracy: 0.6901\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6403 - accuracy: 0.6479\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6786 - accuracy: 0.6056\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.7101 - accuracy: 0.6479\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7526 - accuracy: 0.5915\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6243 - accuracy: 0.6338\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7053 - accuracy: 0.5915\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6784 - accuracy: 0.6761\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7165 - accuracy: 0.6056\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6693 - accuracy: 0.6056\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6870 - accuracy: 0.5915\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6865 - accuracy: 0.6761\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6755 - accuracy: 0.6620\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6081 - accuracy: 0.6901\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6202 - accuracy: 0.6761\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6289 - accuracy: 0.6761\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6143 - accuracy: 0.7183\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6303 - accuracy: 0.6901\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6687 - accuracy: 0.6620\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5826 - accuracy: 0.7606\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5923 - accuracy: 0.7042\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6423 - accuracy: 0.6620\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5997 - accuracy: 0.7183\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6591 - accuracy: 0.6761\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5596 - accuracy: 0.7465\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6182 - accuracy: 0.7042\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5970 - accuracy: 0.7324\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6127 - accuracy: 0.7324\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5878 - accuracy: 0.7183\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6193 - accuracy: 0.6620\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6154 - accuracy: 0.7042\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6124 - accuracy: 0.7465\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6487 - accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6248 - accuracy: 0.7183\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5443 - accuracy: 0.7465\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5638 - accuracy: 0.7324\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5588 - accuracy: 0.7465\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5328 - accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5455 - accuracy: 0.7887\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5937 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5901 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.6310 - accuracy: 0.7042\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 0.7867 - accuracy: 0.6111\n",
      "--- Starting trial: run-70\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'adam'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.4898 - accuracy: 0.4225\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.5266 - accuracy: 0.4366\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 2.4688 - accuracy: 0.4930\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.6911 - accuracy: 0.4648\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.6721 - accuracy: 0.5211\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 2.0842 - accuracy: 0.4930\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.4399 - accuracy: 0.5634\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.5656 - accuracy: 0.5775\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 1.6246 - accuracy: 0.4507\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 1.5580 - accuracy: 0.5211\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9928 - accuracy: 0.5352\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 1.1743 - accuracy: 0.5634\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.1937 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.3668 - accuracy: 0.6056\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.8892 - accuracy: 0.6338\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.9730 - accuracy: 0.6761\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1349 - accuracy: 0.5493\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0739 - accuracy: 0.6620\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8529 - accuracy: 0.7183\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.9310 - accuracy: 0.6479\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.0996 - accuracy: 0.6338\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 1.1058 - accuracy: 0.6338\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8639 - accuracy: 0.6901\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9905 - accuracy: 0.6901\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6824 - accuracy: 0.6761\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.9050 - accuracy: 0.6197\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 1.1310 - accuracy: 0.6197\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.1302 - accuracy: 0.6338\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8355 - accuracy: 0.7042\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9507 - accuracy: 0.6620\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.9195 - accuracy: 0.6761\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.9233 - accuracy: 0.7042\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7501 - accuracy: 0.6761\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.8940 - accuracy: 0.6901\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7045 - accuracy: 0.6901\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6720 - accuracy: 0.7465\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9123 - accuracy: 0.7042\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6701 - accuracy: 0.7042\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.8111 - accuracy: 0.6620\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7679 - accuracy: 0.6338\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.7563 - accuracy: 0.7324\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7408 - accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.8072 - accuracy: 0.7324\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9139 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 86us/sample - loss: 0.7160 - accuracy: 0.7324\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7837 - accuracy: 0.7183\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6787 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.8262 - accuracy: 0.6338\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.9336 - accuracy: 0.7042\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7091 - accuracy: 0.6901\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7326 - accuracy: 0.7887\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7535 - accuracy: 0.6479\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6981 - accuracy: 0.7324\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7385 - accuracy: 0.6620\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6788 - accuracy: 0.7042\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.8184 - accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6723 - accuracy: 0.7183\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.4531 - accuracy: 0.7746\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6041 - accuracy: 0.7183\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.6140 - accuracy: 0.6761\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6883 - accuracy: 0.7042\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6557 - accuracy: 0.6901\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5158 - accuracy: 0.7324\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5313 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.6674 - accuracy: 0.7183\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6175 - accuracy: 0.7324\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6138 - accuracy: 0.6761\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.7329 - accuracy: 0.6620\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7681 - accuracy: 0.7042\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6719 - accuracy: 0.7183\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6887 - accuracy: 0.6901\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7556 - accuracy: 0.6338\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7613 - accuracy: 0.6197\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6768 - accuracy: 0.7183\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5735 - accuracy: 0.7042\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.5986 - accuracy: 0.7465\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5639 - accuracy: 0.7324\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5690 - accuracy: 0.7183\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6110 - accuracy: 0.7042\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6048 - accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5792 - accuracy: 0.7887\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6009 - accuracy: 0.7465\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6015 - accuracy: 0.7324\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4698 - accuracy: 0.7746\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5790 - accuracy: 0.7887\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6064 - accuracy: 0.7465\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6127 - accuracy: 0.7042\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5316 - accuracy: 0.7465\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5087 - accuracy: 0.7465\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6188 - accuracy: 0.7042\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4703 - accuracy: 0.7887\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.5807 - accuracy: 0.7042\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5076 - accuracy: 0.7324\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4732 - accuracy: 0.7746\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5844 - accuracy: 0.7465\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5752 - accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.81 - 0s 65us/sample - loss: 0.5573 - accuracy: 0.7183\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4408 - accuracy: 0.8169\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4410 - accuracy: 0.8310\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5061 - accuracy: 0.7324\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.3885 - accuracy: 0.5000\n",
      "--- Starting trial: run-71\n",
      "{'num_units 1': 16, 'num_units 2': 8, 'dropout': 0.3, 'l2 regularizer': 0.01, 'optimizer': 'sgd'}\n",
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 1.2475 - accuracy: 0.5634\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 1.1008 - accuracy: 0.5915\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.0377 - accuracy: 0.6338\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 1.1349 - accuracy: 0.5915\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 1.0924 - accuracy: 0.5915\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.2145 - accuracy: 0.6197\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 1.0522 - accuracy: 0.6056\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.9808 - accuracy: 0.6479\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 1.0956 - accuracy: 0.5634\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.8854 - accuracy: 0.6338\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.9377 - accuracy: 0.5775\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6941 - accuracy: 0.7042\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.9527 - accuracy: 0.6197\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.7307 - accuracy: 0.6901\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6928 - accuracy: 0.6901\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7536 - accuracy: 0.5634\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.7714 - accuracy: 0.6479\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.7122 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6811 - accuracy: 0.6056\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.6680 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6532 - accuracy: 0.6901\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5337 - accuracy: 0.7324\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6760 - accuracy: 0.6056\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 56us/sample - loss: 0.5594 - accuracy: 0.6901\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6738 - accuracy: 0.6620\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5782 - accuracy: 0.7465\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6711 - accuracy: 0.7183\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6012 - accuracy: 0.7042\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.6235 - accuracy: 0.6761\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6371 - accuracy: 0.6338\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.6177 - accuracy: 0.6620\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6240 - accuracy: 0.6620\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5955 - accuracy: 0.6338\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5105 - accuracy: 0.7324\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6591 - accuracy: 0.6197\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5737 - accuracy: 0.7465\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5046 - accuracy: 0.7465\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4934 - accuracy: 0.7465\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.6166 - accuracy: 0.7183\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5985 - accuracy: 0.7324\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5908 - accuracy: 0.6620\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5679 - accuracy: 0.6761\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6256 - accuracy: 0.7042\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5527 - accuracy: 0.7324\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5587 - accuracy: 0.7042\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5924 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.5767 - accuracy: 0.6761\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.4505 - accuracy: 0.7465\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5125 - accuracy: 0.7324\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5203 - accuracy: 0.7465\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5985 - accuracy: 0.6479\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4495 - accuracy: 0.7746\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5937 - accuracy: 0.6901\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5332 - accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.5518 - accuracy: 0.7324\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4854 - accuracy: 0.7887\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.4994 - accuracy: 0.7324\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5031 - accuracy: 0.7183\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5939 - accuracy: 0.6761\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.5549 - accuracy: 0.7183\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5270 - accuracy: 0.7746\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.4735 - accuracy: 0.7465\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.4553 - accuracy: 0.7746\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5055 - accuracy: 0.7042\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4717 - accuracy: 0.7465\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.5216 - accuracy: 0.7324\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5342 - accuracy: 0.7465\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.4895 - accuracy: 0.7746\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5005 - accuracy: 0.7465\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4437 - accuracy: 0.7465\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.5172 - accuracy: 0.7183\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.4541 - accuracy: 0.7746\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4282 - accuracy: 0.8028\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4349 - accuracy: 0.7746\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.4009 - accuracy: 0.8451\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5161 - accuracy: 0.7042\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5212 - accuracy: 0.7465\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5037 - accuracy: 0.7465\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.4594 - accuracy: 0.7746\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4523 - accuracy: 0.8028\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4540 - accuracy: 0.7606\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4713 - accuracy: 0.7887\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4528 - accuracy: 0.7887\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4775 - accuracy: 0.7887\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.3988 - accuracy: 0.8310\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.4370 - accuracy: 0.7746\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4583 - accuracy: 0.7746\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.4502 - accuracy: 0.7746\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.4937 - accuracy: 0.6761\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.4557 - accuracy: 0.7606\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.4059 - accuracy: 0.7746\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.4828 - accuracy: 0.7183\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.4225 - accuracy: 0.8028\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.3573 - accuracy: 0.8451\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.4041 - accuracy: 0.8451\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.4300 - accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.4201 - accuracy: 0.8028\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 59us/sample - loss: 0.4435 - accuracy: 0.8028\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 56us/sample - loss: 0.4787 - accuracy: 0.7465\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.4968 - accuracy: 0.7324\n",
      "18/18 [==============================] - 0s 4ms/sample - loss: 1.4325 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "for num_units1 in HP_NUM_UNITS1.domain.values:\n",
    "    for num_units2 in HP_NUM_UNITS2.domain.values:\n",
    "        for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "            for l2 in (HP_L2.domain.min_value, HP_L2.domain.max_value):\n",
    "                for optimizer in HP_OPTIMIZER.domain.values:\n",
    "\n",
    "                    hparams = {\n",
    "                        HP_NUM_UNITS1: num_units1,\n",
    "                        HP_NUM_UNITS2: num_units2,\n",
    "                        HP_DROPOUT: dropout_rate,\n",
    "                        HP_L2: l2,\n",
    "                        HP_OPTIMIZER: optimizer\n",
    "                    }\n",
    "                    run_name = \"run-%d\" % session_num\n",
    "                    print('--- Starting trial: %s' % run_name)\n",
    "                    print({h.name: hparams[h] for h in hparams})\n",
    "                    run('logs/hparam_tuning/' + run_name, hparams)\n",
    "                    session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e864e59de4341625\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e864e59de4341625\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6007;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape = 19),\n",
    "    layers.Dense(8, kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(4, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation=tf.nn.relu),\n",
    "    layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71 samples\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 4ms/sample - loss: 2.4093 - accuracy: 0.4648\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 2.4584 - accuracy: 0.5070\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.6989 - accuracy: 0.5493\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 1.5127 - accuracy: 0.5493\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 1.2310 - accuracy: 0.4930\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 1.0431 - accuracy: 0.5493\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 1.2115 - accuracy: 0.5634\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.9111 - accuracy: 0.5493\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 89us/sample - loss: 1.0083 - accuracy: 0.5352\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.9466 - accuracy: 0.5915\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.7787 - accuracy: 0.6338\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.9172 - accuracy: 0.5211\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7910 - accuracy: 0.6761\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.8096 - accuracy: 0.6197\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.8525 - accuracy: 0.5634\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.8319 - accuracy: 0.6197\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 92us/sample - loss: 0.6798 - accuracy: 0.7465\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 73us/sample - loss: 0.7915 - accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.7173 - accuracy: 0.6620\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.8557 - accuracy: 0.6338\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.7602 - accuracy: 0.6620\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7991 - accuracy: 0.6338\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6730 - accuracy: 0.6901\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.7624 - accuracy: 0.6901\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.8744 - accuracy: 0.5352\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6915 - accuracy: 0.6761\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.7669 - accuracy: 0.6761\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.7168 - accuracy: 0.6620\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 85us/sample - loss: 0.6887 - accuracy: 0.6901\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6488 - accuracy: 0.7183\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7124 - accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.7547 - accuracy: 0.7042\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6260 - accuracy: 0.7183\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 115us/sample - loss: 0.6735 - accuracy: 0.7042\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 83us/sample - loss: 0.7344 - accuracy: 0.5915\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 80us/sample - loss: 0.6159 - accuracy: 0.6901\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6572 - accuracy: 0.6620\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 87us/sample - loss: 0.6562 - accuracy: 0.6761\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 82us/sample - loss: 0.6190 - accuracy: 0.7183\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.7225 - accuracy: 0.7465\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.7502 - accuracy: 0.5915\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 84us/sample - loss: 0.6398 - accuracy: 0.6901\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6683 - accuracy: 0.6761\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6721 - accuracy: 0.5915\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 67us/sample - loss: 0.7318 - accuracy: 0.6197\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 90us/sample - loss: 0.7088 - accuracy: 0.6338\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6364 - accuracy: 0.6901\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6639 - accuracy: 0.6761\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 114us/sample - loss: 0.6415 - accuracy: 0.7183\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.6830 - accuracy: 0.6761\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 99us/sample - loss: 0.7270 - accuracy: 0.6197\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 79us/sample - loss: 0.7248 - accuracy: 0.6338\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6055 - accuracy: 0.7324\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6196 - accuracy: 0.6901\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 62us/sample - loss: 0.5914 - accuracy: 0.7465\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 60us/sample - loss: 0.6483 - accuracy: 0.7606\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.6766 - accuracy: 0.6197\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6033 - accuracy: 0.7324\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.6436 - accuracy: 0.7183\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6679 - accuracy: 0.7042\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6104 - accuracy: 0.6901\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5902 - accuracy: 0.7183\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6763 - accuracy: 0.6620\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5676 - accuracy: 0.8169\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6117 - accuracy: 0.7465\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.7292 - accuracy: 0.6620\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 76us/sample - loss: 0.5941 - accuracy: 0.7324\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6022 - accuracy: 0.7606\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6178 - accuracy: 0.6901\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6244 - accuracy: 0.7183\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 74us/sample - loss: 0.6237 - accuracy: 0.7183\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5493 - accuracy: 0.7746\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6439 - accuracy: 0.7042\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5832 - accuracy: 0.8310\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 81us/sample - loss: 0.6184 - accuracy: 0.7746\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6403 - accuracy: 0.7465\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.6270 - accuracy: 0.7042\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.6038 - accuracy: 0.7042\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.6049 - accuracy: 0.7042\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 69us/sample - loss: 0.5855 - accuracy: 0.7606\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 72us/sample - loss: 0.5848 - accuracy: 0.8028\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5773 - accuracy: 0.7324\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 65us/sample - loss: 0.5565 - accuracy: 0.7465\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 66us/sample - loss: 0.5800 - accuracy: 0.7606\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6441 - accuracy: 0.7042\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 88us/sample - loss: 0.6044 - accuracy: 0.7887\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.5603 - accuracy: 0.7606\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 63us/sample - loss: 0.5135 - accuracy: 0.7887\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 58us/sample - loss: 0.6191 - accuracy: 0.7465\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5946 - accuracy: 0.7324\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 61us/sample - loss: 0.6110 - accuracy: 0.7746\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 64us/sample - loss: 0.6041 - accuracy: 0.7183\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 78us/sample - loss: 0.6818 - accuracy: 0.6901\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 70us/sample - loss: 0.6191 - accuracy: 0.7042\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 69us/sample - loss: 0.6683 - accuracy: 0.7042\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 77us/sample - loss: 0.6138 - accuracy: 0.7606\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 71us/sample - loss: 0.5712 - accuracy: 0.7183\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 91us/sample - loss: 0.5527 - accuracy: 0.7183\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 75us/sample - loss: 0.6285 - accuracy: 0.7465\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 68us/sample - loss: 0.5604 - accuracy: 0.7465\n",
      "18/18 [==============================] - 0s 5ms/sample - loss: 0.8455 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100) \n",
    "_, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.squeeze(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[ predictions > 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       1.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 19)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=10,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6894607\ttotal: 1.25ms\tremaining: 11.3ms\n",
      "1:\tlearn: 0.6836695\ttotal: 2.31ms\tremaining: 9.25ms\n",
      "2:\tlearn: 0.6784741\ttotal: 3.15ms\tremaining: 7.36ms\n",
      "3:\tlearn: 0.6752669\ttotal: 4.13ms\tremaining: 6.19ms\n",
      "4:\tlearn: 0.6712729\ttotal: 5.25ms\tremaining: 5.25ms\n",
      "5:\tlearn: 0.6672304\ttotal: 6.58ms\tremaining: 4.39ms\n",
      "6:\tlearn: 0.6628859\ttotal: 7.7ms\tremaining: 3.3ms\n",
      "7:\tlearn: 0.6591012\ttotal: 8.62ms\tremaining: 2.15ms\n",
      "8:\tlearn: 0.6545000\ttotal: 9.34ms\tremaining: 1.04ms\n",
      "9:\tlearn: 0.6487748\ttotal: 10.6ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fc5f388dcc0>"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_raw = model.predict(X_test, prediction_type='RawFormulaVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4762469 , 0.5237531 ],\n",
       "       [0.48894628, 0.51105372],\n",
       "       [0.49822824, 0.50177176],\n",
       "       [0.47421904, 0.52578096],\n",
       "       [0.47888567, 0.52111433],\n",
       "       [0.4786179 , 0.5213821 ],\n",
       "       [0.51629228, 0.48370772],\n",
       "       [0.48022062, 0.51977938],\n",
       "       [0.50828489, 0.49171511],\n",
       "       [0.49430938, 0.50569062],\n",
       "       [0.50369234, 0.49630766],\n",
       "       [0.48243872, 0.51756128],\n",
       "       [0.48020369, 0.51979631],\n",
       "       [0.49645075, 0.50354925],\n",
       "       [0.50716748, 0.49283252],\n",
       "       [0.48083215, 0.51916785],\n",
       "       [0.49413365, 0.50586635],\n",
       "       [0.4967533 , 0.5032467 ],\n",
       "       [0.48436198, 0.51563802],\n",
       "       [0.48766687, 0.51233313],\n",
       "       [0.47961861, 0.52038139],\n",
       "       [0.49560627, 0.50439373],\n",
       "       [0.4783128 , 0.5216872 ],\n",
       "       [0.50128318, 0.49871682],\n",
       "       [0.50644833, 0.49355167],\n",
       "       [0.48860819, 0.51139181],\n",
       "       [0.48824142, 0.51175858],\n",
       "       [0.48272324, 0.51727676],\n",
       "       [0.47635254, 0.52364746],\n",
       "       [0.48976925, 0.51023075]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09508397,  0.04422207,  0.00708706,  0.10321536,  0.08450758,\n",
       "        0.08558059, -0.0651922 ,  0.07915884, -0.0331426 ,  0.02276345,\n",
       "       -0.01476963,  0.07027404,  0.07922665,  0.01419725, -0.02867189,\n",
       "        0.07670898,  0.02346648,  0.01298698,  0.0625725 ,  0.04934255,\n",
       "        0.08157076,  0.01757538,  0.08680328, -0.00513272, -0.02579477,\n",
       "        0.04557514,  0.047043  ,  0.06913458,  0.09466047,  0.04092872])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[pl<0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[pl>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.append(list(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8.391181630940103,\n",
       "  11.432926829268997,\n",
       "  -13.703844689760825,\n",
       "  -15.247388884652713,\n",
       "  10.68947087119243,\n",
       "  2.2881549843623006,\n",
       "  -31.264297697117804,\n",
       "  -42.07144496289894,\n",
       "  1.536334306344589,\n",
       "  3.0721966205859985,\n",
       "  17.65970515970494,\n",
       "  -66.68199586111756,\n",
       "  -54.78395061728425,\n",
       "  4.655132283342134,\n",
       "  0.7754943776672185,\n",
       "  15.508684863523303,\n",
       "  5.41963456178296,\n",
       "  -26.309680414764447,\n",
       "  7.7585538055724435]]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = data.iloc[i-20:i,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515    131.09\n",
       "516    131.20\n",
       "517    131.35\n",
       "518    131.17\n",
       "519    130.97\n",
       "520    131.11\n",
       "521    131.14\n",
       "522    130.73\n",
       "523    130.18\n",
       "524    130.20\n",
       "525    130.24\n",
       "526    130.47\n",
       "527    129.60\n",
       "528    128.89\n",
       "529    128.95\n",
       "530    128.96\n",
       "531    129.16\n",
       "532    129.23\n",
       "533    128.89\n",
       "534    128.99\n",
       "Name: Low, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (price[1:]/price[:-1].values -1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515   -0.000838\n",
       "516   -0.001142\n",
       "517    0.001372\n",
       "518    0.001527\n",
       "519   -0.001068\n",
       "520   -0.000229\n",
       "521    0.003136\n",
       "522    0.004225\n",
       "523   -0.000154\n",
       "524   -0.000307\n",
       "525   -0.001763\n",
       "526    0.006713\n",
       "527    0.005509\n",
       "528   -0.000465\n",
       "529   -0.000078\n",
       "530   -0.001548\n",
       "531   -0.000542\n",
       "532    0.002638\n",
       "533   -0.000775\n",
       "Name: Low, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price[:-1] / price[1:].values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              115034\n",
       "Time          2018.11.15 04:37\n",
       "Open                   145.313\n",
       "High                   145.313\n",
       "Low                    144.873\n",
       "Close                   145.04\n",
       "Volume                       0\n",
       "Name: 115034, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[115034,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0388cd6128>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "f.set_figheight(15)\n",
    "f.set_figwidth(15)\n",
    "ax.plot(p.accumPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000.0\n",
      "10920.000000000015\n",
      "15288.00000000002\n",
      "21403.200000000026\n",
      "12841.920000000016\n",
      "17978.688000000024\n",
      "25170.16320000003\n",
      "35238.22848000005\n",
      "49333.51987200007\n",
      "69066.9278208001\n",
      "96693.69894912015\n",
      "67298.8144685877\n",
      "36139.46336963163\n",
      "50595.24871748428\n",
      "70833.348204478\n",
      "99166.68748626919\n",
      "138833.36248077685\n",
      "194366.7074730876\n",
      "272113.3904623226\n",
      "189390.91976177678\n",
      "111551.25173968679\n",
      "104077.31787312792\n",
      "66401.32880305557\n",
      "31540.631181451397\n",
      "44156.88365403196\n",
      "28039.621120310396\n",
      "39255.46956843455\n",
      "54957.65739580837\n",
      "76940.72035413171\n",
      "53550.74136647573\n",
      "74971.03791306603\n",
      "104959.45307829244\n",
      "59239.11531738846\n",
      "82934.76144434384\n",
      "116108.66602208136\n",
      "162552.13243091392\n",
      "227572.98540327948\n",
      "318602.17956459126\n",
      "191161.30773875475\n",
      "133048.27018617344\n",
      "72178.68657599925\n",
      "37359.688171737325\n",
      "27907.687064287777\n",
      "39070.76189000289\n",
      "54699.06664600405\n",
      "76578.69330440566\n",
      "107210.17062616794\n",
      "150094.2388766351\n",
      "210131.93442728912\n",
      "125238.63291866447\n",
      "108394.03679110447\n",
      "151751.65150754625\n",
      "212452.31211056476\n",
      "147866.80922895324\n",
      "207013.53292053452\n",
      "144081.4189126922\n",
      "201713.9864777691\n",
      "282399.5810688767\n",
      "395359.4134964274\n",
      "553503.1788949984\n",
      "449112.47935540194\n",
      "628757.4710975627\n",
      "880260.4595365878\n",
      "1232364.6433512229\n",
      "1725310.500691712\n",
      "2415434.700968397\n",
      "3381608.5813557557\n",
      "4734252.013898058\n",
      "6627952.819457281\n",
      "9279133.947240194\n",
      "12990787.526136272\n",
      "8867511.565340647\n",
      "6207258.095738453\n",
      "8690161.334033834\n",
      "12166225.867647368\n",
      "9925207.062826741\n",
      "7723796.136291781\n",
      "10813314.590808494\n",
      "6060862.828148181\n",
      "8485207.959407452\n",
      "11879291.143170435\n",
      "16631007.60043861\n",
      "23283410.640614055\n",
      "11548571.67774459\n",
      "8608305.328590825\n",
      "12051627.460027155\n",
      "8349367.504306809\n",
      "6024068.654357365\n",
      "8433696.116100311\n"
     ]
    }
   ],
   "source": [
    "capital = 10000\n",
    "lot_amount = INVERSE_PIP_RATIO*10\n",
    "lots = capital / (lot_amount * 10)\n",
    "\n",
    "for i in range(len(p.profitloss)):\n",
    "    capital = capital + lot_amount* lots * p.profitloss[i] * PIP_RATIO\n",
    "    print(capital)\n",
    "    lots = capital / (lot_amount * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sell at 2009.01.13 15:00 price 128.97000, limit order at 125.97000, stop loss at 136.97000\n",
      "Short position opened 2009.01.13 15:00 price 128.97000 closed 2009.01.15 20:30 profit -401.00000 pips\n",
      "Maximum Profit:  -6.000000000000227\n",
      "Maximum Loss:  -422.999999999999\n",
      "Cumulative Pips is : -400.9999999999991\n",
      "*************************************************\n",
      "Buy at 2009.01.15 20:30 price 132.98000, limit order at 135.98000, stop loss at 124.94000\n",
      "Long position opened 2009.01.15 20:30 price 132.98000 closed 2009.01.20 14:00 profit -804 pips\n",
      "Maximum Profit:  281.0000000000002\n",
      "Maximum Loss:  -812.9999999999995\n",
      "Cumulative Pips is : -1204.9999999999998\n",
      "*************************************************\n",
      "Sell at 2009.01.21 03:30 price 123.17000, limit order at 120.17000, stop loss at 131.17000\n",
      "Short position opened 2009.01.21 03:30 price 123.17000 closed 2009.01.21 11:00 profit 300 pips\n",
      "Maximum Profit:  371.9999999999999\n",
      "Maximum Loss:  -176.0000000000005\n",
      "Cumulative Pips is : -904.9999999999998\n",
      "*************************************************\n",
      "Buy at 2009.01.28 10:30 price 128.57000, limit order at 131.57000, stop loss at 120.53000\n",
      "Long position opened 2009.01.28 10:30 price 128.57000 closed 2009.02.05 07:00 profit 300 pips\n",
      "Maximum Profit:  340.99999999999966\n",
      "Maximum Loss:  -319.99999999999886\n",
      "Cumulative Pips is : -604.9999999999998\n",
      "************************************************\n",
      "Sell at 2009.02.12 03:30 price 128.14000, limit order at 125.14000, stop loss at 136.14000\n",
      "Short position opened 2009.02.12 03:30 price 128.14000 closed 2009.02.18 07:30 profit -665.00000 pips\n",
      "Maximum Profit:  95.99999999999795\n",
      "Maximum Loss:  -664.0000000000015\n",
      "Cumulative Pips is : -1270.0000000000005\n",
      "*************************************************\n",
      "Buy at 2009.02.18 07:30 price 134.79000, limit order at 137.79000, stop loss at 126.75000\n",
      "Long position opened 2009.02.18 07:30 price 134.79000 closed 2009.02.23 05:00 profit 300 pips\n",
      "Maximum Profit:  409.00000000000034\n",
      "Maximum Loss:  -4.999999999998295\n",
      "Cumulative Pips is : -970.0000000000005\n",
      "************************************************\n",
      "Sell at 2009.03.11 11:30 price 134.42000, limit order at 131.42000, stop loss at 142.42000\n",
      "Short position opened 2009.03.11 11:30 price 134.42000 closed 2009.03.13 04:30 profit -304.00000 pips\n",
      "Maximum Profit:  291.99999999999875\n",
      "Maximum Loss:  -392.0000000000016\n",
      "Cumulative Pips is : -1274.0000000000025\n",
      "*************************************************\n",
      "Buy at 2009.03.13 04:30 price 137.46000, limit order at 140.46000, stop loss at 129.42000\n",
      "Long position opened 2009.03.13 04:30 price 137.46000 closed 2009.03.23 04:30 profit 300 pips\n",
      "Maximum Profit:  309.99999999999943\n",
      "Maximum Loss:  -246.9999999999999\n",
      "Cumulative Pips is : -974.0000000000025\n",
      "************************************************\n",
      "Sell at 2009.03.30 00:00 price 138.27000, limit order at 135.27000, stop loss at 146.27000\n",
      "Short position opened 2009.03.30 00:00 price 138.27000 closed 2009.04.02 02:00 profit -547.00000 pips\n",
      "Maximum Profit:  250.9999999999991\n",
      "Maximum Loss:  -588.0000000000024\n",
      "Cumulative Pips is : -1521.0000000000052\n",
      "*************************************************\n",
      "Buy at 2009.04.02 02:00 price 143.74000, limit order at 146.74000, stop loss at 135.70000\n",
      "Long position opened 2009.04.02 02:00 price 143.74000 closed 2009.04.02 06:30 profit 300 pips\n",
      "Maximum Profit:  321.9999999999999\n",
      "Maximum Loss:  -1.0000000000019327\n",
      "Cumulative Pips is : -1221.0000000000052\n",
      "************************************************\n",
      "Sell at 2009.04.22 09:00 price 140.74000, limit order at 137.74000, stop loss at 148.74000\n",
      "Short position opened 2009.04.22 09:00 price 140.74000 closed 2009.05.01 04:00 profit -641.00000 pips\n",
      "Maximum Profit:  166.99999999999875\n",
      "Maximum Loss:  -684.0000000000032\n",
      "Cumulative Pips is : -1862.0000000000077\n",
      "*************************************************\n",
      "Buy at 2009.05.01 04:00 price 147.15000, limit order at 150.15000, stop loss at 139.11000\n",
      "Long position opened 2009.05.01 04:00 price 147.15000 closed 2009.05.07 05:00 profit 300 pips\n",
      "Maximum Profit:  316.99999999999875\n",
      "Maximum Loss:  -14.000000000001478\n",
      "Cumulative Pips is : -1562.0000000000077\n",
      "************************************************\n",
      "Sell at 2009.06.05 04:30 price 154.89000, limit order at 151.89000, stop loss at 162.89000\n",
      "Short position opened 2009.06.05 04:30 price 154.89000 closed 2009.06.12 01:00 profit -725.00000 pips\n",
      "Maximum Profit:  -3.0000000000001137\n",
      "Maximum Loss:  -733.0000000000013\n",
      "Cumulative Pips is : -2287.0000000000105\n",
      "*************************************************\n",
      "Buy at 2009.06.12 01:00 price 162.14000, limit order at 165.14000, stop loss at 154.10000\n",
      "Long position opened 2009.06.12 01:00 price 162.14000 closed 2009.06.17 11:00 profit -648.00000 pips\n",
      "Maximum Profit:  44.99999999999886\n",
      "Maximum Loss:  -653.0000000000001\n",
      "Cumulative Pips is : -2935.0000000000123\n",
      "*************************************************\n",
      "Sell at 2009.06.17 11:00 price 155.66000, limit order at 152.66000, stop loss at 163.66000\n",
      "Short position opened 2009.06.17 11:00 price 155.66000 closed 2009.07.07 18:30 profit 300 pips\n",
      "Maximum Profit:  309.00000000000034\n",
      "Maximum Loss:  -461.00000000000136\n",
      "Cumulative Pips is : -2635.0000000000123\n",
      "*************************************************\n",
      "Buy at 2009.07.20 03:30 price 156.00000, limit order at 159.00000, stop loss at 147.96000\n",
      "Long position opened 2009.07.20 03:30 price 156.00000 closed 2009.08.03 03:30 profit 300 pips\n",
      "Maximum Profit:  321.9999999999999\n",
      "Maximum Loss:  -368.9999999999998\n",
      "Cumulative Pips is : -2335.0000000000123\n",
      "************************************************\n",
      "Sell at 2009.08.12 02:30 price 157.02000, limit order at 154.02000, stop loss at 165.02000\n",
      "Short position opened 2009.08.12 02:30 price 157.02000 closed 2009.08.17 06:00 profit 300 pips\n",
      "Maximum Profit:  306.9999999999993\n",
      "Maximum Loss:  -334.0000000000032\n",
      "Cumulative Pips is : -2035.0000000000123\n",
      "*************************************************\n",
      "Buy at 2009.10.21 04:30 price 150.15000, limit order at 153.15000, stop loss at 142.11000\n",
      "Long position opened 2009.10.21 04:30 price 150.15000 closed 2009.10.23 03:30 profit 300 pips\n",
      "Maximum Profit:  307.9999999999984\n",
      "Maximum Loss:  9.000000000000341\n",
      "Cumulative Pips is : -1735.0000000000123\n",
      "************************************************\n",
      "Sell at 2009.10.28 05:00 price 148.41000, limit order at 145.41000, stop loss at 156.41000\n",
      "Short position opened 2009.10.28 05:00 price 148.41000 closed 2009.11.25 22:30 profit 300 pips\n",
      "Maximum Profit:  375.0\n",
      "Maximum Loss:  -331.9999999999993\n",
      "Cumulative Pips is : -1435.0000000000123\n",
      "*************************************************\n",
      "Buy at 2009.12.31 07:30 price 150.00000, limit order at 153.00000, stop loss at 141.96000\n",
      "Long position opened 2009.12.31 07:30 price 150.00000 closed 2010.02.04 11:01 profit -803 pips\n",
      "Maximum Profit:  69.99999999999886\n",
      "Maximum Loss:  -902.000000000001\n",
      "Cumulative Pips is : -2239.0000000000114\n",
      "*************************************************\n",
      "Sell at 2010.02.05 13:31 price 138.53000, limit order at 135.53000, stop loss at 146.53000\n",
      "Short position opened 2010.02.05 13:31 price 138.53000 closed 2010.02.25 11:01 profit 300 pips\n",
      "Maximum Profit:  331.9999999999993\n",
      "Maximum Loss:  -508.00000000000125\n",
      "Cumulative Pips is : -1939.0000000000114\n",
      "*************************************************\n",
      "Buy at 2010.03.17 05:31 price 138.90000, limit order at 141.90000, stop loss at 130.86000\n",
      "Long position opened 2010.03.17 05:31 price 138.90000 closed 2010.03.31 11:01 profit 300 pips\n",
      "Maximum Profit:  312.00000000000045\n",
      "Maximum Loss:  -436.00000000000136\n",
      "Cumulative Pips is : -1639.0000000000114\n",
      "************************************************\n",
      "Sell at 2010.04.08 03:01 price 141.27000, limit order at 138.27000, stop loss at 149.27000\n",
      "Short position opened 2010.04.08 03:01 price 141.27000 closed 2010.05.06 11:31 profit 300 pips\n",
      "Maximum Profit:  451.9999999999982\n",
      "Maximum Loss:  -469.0000000000026\n",
      "Cumulative Pips is : -1339.0000000000114\n",
      "*************************************************\n",
      "Buy at 2011.10.31 00:01 price 123.18000, limit order at 126.18000, stop loss at 115.14000\n",
      "Long position opened 2011.10.31 00:01 price 123.18000 closed 2011.10.31 00:31 profit 300 pips\n",
      "Maximum Profit:  343.9999999999998\n",
      "Maximum Loss:  323.9999999999995\n",
      "Cumulative Pips is : -1039.0000000000114\n",
      "************************************************\n",
      "Sell at 2012.01.11 09:31 price 118.16700, limit order at 115.16700, stop loss at 126.16700\n",
      "Short position opened 2012.01.11 09:31 price 118.16700 closed 2012.02.08 00:31 profit -444.60000 pips\n",
      "Maximum Profit:  89.00000000000148\n",
      "Maximum Loss:  -445.69999999999794\n",
      "Cumulative Pips is : -1483.6000000000097\n",
      "*************************************************\n",
      "Buy at 2012.02.08 00:31 price 122.61300, limit order at 125.61300, stop loss at 114.57300\n",
      "Long position opened 2012.02.08 00:31 price 122.61300 closed 2012.02.17 08:01 profit 300 pips\n",
      "Maximum Profit:  305.4000000000002\n",
      "Maximum Loss:  -122.40000000000038\n",
      "Cumulative Pips is : -1183.6000000000097\n",
      "************************************************\n",
      "Sell at 2012.04.06 08:31 price 129.27000, limit order at 126.27000, stop loss at 137.27000\n",
      "Short position opened 2012.04.06 08:31 price 129.27000 closed 2012.05.17 10:01 profit 299 pips\n",
      "Maximum Profit:  318.99999999999835\n",
      "Maximum Loss:  -252.800000000002\n",
      "Cumulative Pips is : -883.600000000011\n",
      "*************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy at 2012.06.07 08:01 price 123.77900, limit order at 126.77900, stop loss at 115.73900\n",
      "Long position opened 2012.06.07 08:01 price 123.77900 closed 2012.09.14 05:31 profit 300 pips\n",
      "Maximum Profit:  302.50000000000057\n",
      "Maximum Loss:  -296.9999999999999\n",
      "Cumulative Pips is : -583.600000000011\n",
      "************************************************\n",
      "Sell at 2012.10.08 11:01 price 125.15300, limit order at 122.15300, stop loss at 133.15300\n",
      "Short position opened 2012.10.08 11:01 price 125.15300 closed 2012.11.20 20:01 profit -531.30000 pips\n",
      "Maximum Profit:  42.99999999999926\n",
      "Maximum Loss:  -532.5999999999993\n",
      "Cumulative Pips is : -1114.9000000000128\n",
      "*************************************************\n",
      "Buy at 2012.11.20 20:01 price 130.46600, limit order at 133.46600, stop loss at 122.42600\n",
      "Long position opened 2012.11.20 20:01 price 130.46600 closed 2012.12.12 03:01 profit 300 pips\n",
      "Maximum Profit:  303.2999999999987\n",
      "Maximum Loss:  -47.800000000000864\n",
      "Cumulative Pips is : -814.9000000000128\n",
      "************************************************\n",
      "Sell at 2013.02.15 04:31 price 142.75800, limit order at 139.75800, stop loss at 150.75800\n",
      "Short position opened 2013.02.15 04:31 price 142.75800 closed 2013.02.25 15:01 profit 300 pips\n",
      "Maximum Profit:  440.7999999999987\n",
      "Maximum Loss:  -298.0000000000018\n",
      "Cumulative Pips is : -514.9000000000128\n",
      "*************************************************\n",
      "Buy at 2013.03.15 05:31 price 145.55700, limit order at 148.55700, stop loss at 137.51700\n",
      "Long position opened 2013.03.15 05:31 price 145.55700 closed 2013.04.05 10:01 profit 300 pips\n",
      "Maximum Profit:  332.49999999999886\n",
      "Maximum Loss:  -518.9000000000021\n",
      "Cumulative Pips is : -214.90000000001282\n",
      "************************************************\n",
      "Sell at 2013.04.15 14:01 price 148.75600, limit order at 145.75600, stop loss at 156.75600\n",
      "Short position opened 2013.04.15 14:01 price 148.75600 closed 2013.04.19 03:31 profit -323.00000 pips\n",
      "Maximum Profit:  230.89999999999975\n",
      "Maximum Loss:  -360.30000000000086\n",
      "Cumulative Pips is : -537.9000000000146\n",
      "*************************************************\n",
      "Buy at 2013.04.19 03:31 price 151.98600, limit order at 154.98600, stop loss at 143.94600\n",
      "Long position opened 2013.04.19 03:31 price 151.98600 closed 2013.05.09 13:31 profit 300 pips\n",
      "Maximum Profit:  359.89999999999895\n",
      "Maximum Loss:  -204.10000000000252\n",
      "Cumulative Pips is : -237.90000000001464\n",
      "************************************************\n",
      "Sell at 2013.06.06 12:01 price 150.96400, limit order at 147.96400, stop loss at 158.96400\n",
      "Short position opened 2013.06.06 12:01 price 150.96400 closed 2013.06.13 01:01 profit 300 pips\n",
      "Maximum Profit:  311.29999999999995\n",
      "Maximum Loss:  -325.39999999999907\n",
      "Cumulative Pips is : 62.09999999998536\n",
      "*************************************************\n",
      "Buy at 2013.09.05 06:31 price 156.27800, limit order at 159.27800, stop loss at 148.23800\n",
      "Long position opened 2013.09.05 06:31 price 156.27800 closed 2013.09.19 03:01 profit 300 pips\n",
      "Maximum Profit:  302.40000000000293\n",
      "Maximum Loss:  -216.19999999999777\n",
      "Cumulative Pips is : 362.09999999998536\n",
      "************************************************\n",
      "Sell at 2013.10.09 10:31 price 154.90500, limit order at 151.90500, stop loss at 162.90500\n",
      "Short position opened 2013.10.09 10:31 price 154.90500 closed 2013.10.17 18:01 profit -343.60000 pips\n",
      "Maximum Profit:  15.299999999999159\n",
      "Maximum Loss:  -345.5999999999989\n",
      "Cumulative Pips is : 18.499999999984652\n",
      "*************************************************\n",
      "Buy at 2013.10.17 18:01 price 158.34100, limit order at 161.34100, stop loss at 150.30100\n",
      "Long position opened 2013.10.17 18:01 price 158.34100 closed 2013.11.15 05:31 profit 300 pips\n",
      "Maximum Profit:  308.89999999999986\n",
      "Maximum Loss:  -172.80000000000086\n",
      "Cumulative Pips is : 318.49999999998465\n",
      "************************************************\n",
      "Sell at 2014.01.06 00:02 price 171.01900, limit order at 168.01900, stop loss at 179.01900\n",
      "Short position opened 2014.01.06 00:02 price 171.01900 closed 2014.01.31 08:02 profit 300 pips\n",
      "Maximum Profit:  304.30000000000064\n",
      "Maximum Loss:  -261.29999999999995\n",
      "Cumulative Pips is : 618.4999999999847\n",
      "*************************************************\n",
      "Buy at 2014.09.17 11:32 price 175.62300, limit order at 178.62300, stop loss at 167.58300\n",
      "Long position opened 2014.09.17 11:32 price 175.62300 closed 2014.09.18 17:32 profit 300 pips\n",
      "Maximum Profit:  335.40000000000134\n",
      "Maximum Loss:  -35.69999999999993\n",
      "Cumulative Pips is : 918.4999999999847\n",
      "************************************************\n",
      "Sell at 2014.12.15 11:02 price 184.39300, limit order at 181.39300, stop loss at 192.39300\n",
      "Short position opened 2014.12.15 11:02 price 184.39300 closed 2015.01.06 01:31 profit 300 pips\n",
      "Maximum Profit:  321.0999999999956\n",
      "Maximum Loss:  -319.1000000000031\n",
      "Cumulative Pips is : 1218.4999999999845\n",
      "*************************************************\n",
      "Buy at 2015.02.06 08:31 price 181.24600, limit order at 184.24600, stop loss at 173.20600\n",
      "Long position opened 2015.02.06 08:31 price 181.24600 closed 2015.02.24 01:31 profit 300 pips\n",
      "Maximum Profit:  310.9000000000009\n",
      "Maximum Loss:  -108.39999999999748\n",
      "Cumulative Pips is : 1518.4999999999845\n",
      "************************************************\n",
      "Sell at 2015.03.13 08:31 price 179.40300, limit order at 176.40300, stop loss at 187.40300\n",
      "Short position opened 2015.03.13 08:31 price 179.40300 closed 2015.04.10 04:31 profit 300 pips\n",
      "Maximum Profit:  348.3000000000004\n",
      "Maximum Loss:  -163.10000000000286\n",
      "Cumulative Pips is : 1818.4999999999845\n",
      "*************************************************\n",
      "Buy at 2015.04.29 04:01 price 183.24000, limit order at 186.24000, stop loss at 175.20000\n",
      "Long position opened 2015.04.29 04:01 price 183.24000 closed 2015.05.11 09:31 profit 300 pips\n",
      "Maximum Profit:  331.3999999999993\n",
      "Maximum Loss:  -228.8000000000011\n",
      "Cumulative Pips is : 2118.4999999999845\n",
      "************************************************\n",
      "Sell at 2015.07.07 10:01 price 188.59100, limit order at 185.59100, stop loss at 196.59100\n",
      "Short position opened 2015.07.07 10:01 price 188.59100 closed 2015.07.08 11:01 profit 300 pips\n",
      "Maximum Profit:  343.2999999999993\n",
      "Maximum Loss:  -122.90000000000134\n",
      "Cumulative Pips is : 2418.4999999999845\n",
      "*************************************************\n",
      "Buy at 2015.07.13 03:01 price 191.61000, limit order at 194.61000, stop loss at 183.57000\n",
      "Long position opened 2015.07.13 03:01 price 191.61000 closed 2015.08.05 09:31 profit 300 pips\n",
      "Maximum Profit:  328.7000000000006\n",
      "Maximum Loss:  -105.60000000000116\n",
      "Cumulative Pips is : 2718.4999999999845\n",
      "************************************************\n",
      "Sell at 2015.09.03 22:01 price 182.43700, limit order at 179.43700, stop loss at 190.43700\n",
      "Short position opened 2015.09.03 22:01 price 182.43700 closed 2015.12.22 09:31 profit 300 pips\n",
      "Maximum Profit:  313.49999999999625\n",
      "Maximum Loss:  -636.7000000000019\n",
      "Cumulative Pips is : 3018.4999999999845\n",
      "*************************************************\n",
      "Buy at 2016.01.28 22:01 price 171.19800, limit order at 174.19800, stop loss at 163.15800\n",
      "Long position opened 2016.01.28 22:01 price 171.19800 closed 2016.02.01 13:01 profit 300 pips\n",
      "Maximum Profit:  318.8999999999993\n",
      "Maximum Loss:  -112.00000000000045\n",
      "Cumulative Pips is : 3318.4999999999845\n",
      "************************************************\n",
      "Sell at 2016.02.08 06:01 price 168.18100, limit order at 165.18100, stop loss at 176.18100\n",
      "Short position opened 2016.02.08 06:01 price 168.18100 closed 2016.02.08 21:31 profit 300 pips\n",
      "Maximum Profit:  311.19999999999663\n",
      "Maximum Loss:  -8.70000000000175\n",
      "Cumulative Pips is : 3618.4999999999845\n",
      "*************************************************\n",
      "Buy at 2016.03.01 12:01 price 159.01900, limit order at 162.01900, stop loss at 150.97900\n",
      "Long position opened 2016.03.01 12:01 price 159.01900 closed 2016.03.04 11:01 profit 300 pips\n",
      "Maximum Profit:  304.49999999999875\n",
      "Maximum Loss:  -27.199999999999136\n",
      "Cumulative Pips is : 3918.4999999999845\n",
      "************************************************\n",
      "Sell at 2016.04.05 02:01 price 157.64100, limit order at 154.64100, stop loss at 165.64100\n",
      "Short position opened 2016.04.05 02:01 price 157.64100 closed 2016.04.06 09:01 profit 300 pips\n",
      "Maximum Profit:  306.8000000000012\n",
      "Maximum Loss:  4.099999999999682\n",
      "Cumulative Pips is : 4218.4999999999845\n",
      "*************************************************\n",
      "Buy at 2016.04.22 02:01 price 158.55400, limit order at 161.55400, stop loss at 150.51400\n",
      "Long position opened 2016.04.22 02:01 price 158.55400 closed 2016.04.22 16:31 profit 300 pips\n",
      "Maximum Profit:  322.80000000000086\n",
      "Maximum Loss:  -43.99999999999977\n",
      "Cumulative Pips is : 4518.4999999999845\n",
      "************************************************\n",
      "Sell at 2016.04.29 04:31 price 156.27400, limit order at 153.27400, stop loss at 164.27400\n",
      "Short position opened 2016.04.29 04:31 price 156.27400 closed 2016.05.17 03:01 profit -255.60000 pips\n",
      "Maximum Profit:  264.0999999999991\n",
      "Maximum Loss:  -269.7000000000031\n",
      "Cumulative Pips is : 4262.8999999999805\n",
      "*************************************************\n",
      "Buy at 2016.05.17 03:01 price 158.83000, limit order at 161.83000, stop loss at 150.79000\n",
      "Long position opened 2016.05.17 03:01 price 158.83000 closed 2016.05.25 07:01 profit 300 pips\n",
      "Maximum Profit:  312.29999999999905\n",
      "Maximum Loss:  -181.40000000000214\n",
      "Cumulative Pips is : 4562.8999999999805\n",
      "************************************************\n",
      "Sell at 2016.06.03 00:31 price 156.41800, limit order at 153.41800, stop loss at 164.41800\n",
      "Short position opened 2016.06.03 00:31 price 156.41800 closed 2016.06.10 09:31 profit 300 pips\n",
      "Maximum Profit:  330.6999999999988\n",
      "Maximum Loss:  -151.40000000000384\n",
      "Cumulative Pips is : 4862.8999999999805\n",
      "*************************************************\n",
      "Buy at 2016.06.17 16:31 price 150.62500, limit order at 153.62500, stop loss at 142.58500\n",
      "Long position opened 2016.06.17 16:31 price 150.62500 closed 2016.06.20 11:01 profit 300 pips\n",
      "Maximum Profit:  300.39999999999907\n",
      "Maximum Loss:  162.39999999999952\n",
      "Cumulative Pips is : 5162.8999999999805\n",
      "************************************************\n",
      "Sell at 2016.07.05 10:31 price 132.44200, limit order at 129.44200, stop loss at 140.44200\n",
      "Short position opened 2016.07.05 10:31 price 132.44200 closed 2016.07.05 22:01 profit 300 pips\n",
      "Maximum Profit:  366.40000000000157\n",
      "Maximum Loss:  -25.399999999999068\n",
      "Cumulative Pips is : 5462.8999999999805\n",
      "*************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy at 2016.11.08 13:01 price 130.29100, limit order at 133.29100, stop loss at 122.25100\n",
      "Long position opened 2016.11.08 13:01 price 130.29100 closed 2016.11.10 09:01 profit 300 pips\n",
      "Maximum Profit:  314.1999999999996\n",
      "Maximum Loss:  -359.7999999999999\n",
      "Cumulative Pips is : 5762.8999999999805\n",
      "************************************************\n",
      "Sell at 2017.01.09 08:01 price 141.36300, limit order at 138.36300, stop loss at 149.36300\n",
      "Short position opened 2017.01.09 08:01 price 141.36300 closed 2017.01.13 16:31 profit 300 pips\n",
      "Maximum Profit:  423.29999999999757\n",
      "Maximum Loss:  -39.70000000000198\n",
      "Cumulative Pips is : 6062.8999999999805\n",
      "*************************************************\n",
      "Buy at 2017.01.25 04:01 price 143.01300, limit order at 146.01300, stop loss at 134.97300\n",
      "Long position opened 2017.01.25 04:01 price 143.01300 closed 2017.01.31 09:31 profit -214.30000 pips\n",
      "Maximum Profit:  176.80000000000007\n",
      "Maximum Loss:  -227.89999999999964\n",
      "Cumulative Pips is : 5848.599999999978\n",
      "*************************************************\n",
      "Sell at 2017.01.31 09:31 price 140.87000, limit order at 137.87000, stop loss at 148.87000\n",
      "Short position opened 2017.01.31 09:31 price 140.87000 closed 2017.03.22 10:31 profit 300 pips\n",
      "Maximum Profit:  311.3999999999976\n",
      "Maximum Loss:  -325.800000000001\n",
      "Cumulative Pips is : 6148.599999999978\n",
      "*************************************************\n",
      "Buy at 2017.04.21 16:31 price 140.86900, limit order at 143.86900, stop loss at 132.82900\n",
      "Long position opened 2017.04.21 16:31 price 140.86900 closed 2017.04.27 08:31 profit 300 pips\n",
      "Maximum Profit:  302.000000000001\n",
      "Maximum Loss:  -81.29999999999882\n",
      "Cumulative Pips is : 6448.599999999978\n",
      "************************************************\n",
      "Sell at 2017.05.26 06:31 price 142.59100, limit order at 139.59100, stop loss at 150.59100\n",
      "Short position opened 2017.05.26 06:31 price 142.59100 closed 2017.06.08 20:31 profit 300 pips\n",
      "Maximum Profit:  305.5999999999983\n",
      "Maximum Loss:  -135.69999999999993\n",
      "Cumulative Pips is : 6748.599999999978\n",
      "*************************************************\n",
      "Buy at 2017.06.27 10:01 price 143.16500, limit order at 146.16500, stop loss at 135.12500\n",
      "Long position opened 2017.06.27 10:01 price 143.16500 closed 2017.06.29 04:01 profit 300 pips\n",
      "Maximum Profit:  306.60000000000025\n",
      "Maximum Loss:  -12.5\n",
      "Cumulative Pips is : 7048.599999999978\n",
      "************************************************\n",
      "Sell at 2017.08.08 13:01 price 143.25600, limit order at 140.25600, stop loss at 151.25600\n",
      "Short position opened 2017.08.08 13:01 price 143.25600 closed 2017.08.18 09:01 profit 300 pips\n",
      "Maximum Profit:  311.7999999999995\n",
      "Maximum Loss:  -31.699999999997885\n",
      "Cumulative Pips is : 7348.599999999978\n",
      "*************************************************\n",
      "Buy at 2017.09.14 07:01 price 147.50100, limit order at 150.50100, stop loss at 139.46100\n",
      "Long position opened 2017.09.14 07:01 price 147.50100 closed 2017.09.15 05:01 profit 300 pips\n",
      "Maximum Profit:  332.2999999999979\n",
      "Maximum Loss:  -90.00000000000057\n",
      "Cumulative Pips is : 7648.599999999978\n",
      "************************************************\n",
      "Sell at 2017.10.05 03:31 price 148.47500, limit order at 145.47500, stop loss at 156.47500\n",
      "Short position opened 2017.10.05 03:31 price 148.47500 closed 2017.11.30 13:01 profit -375.50000 pips\n",
      "Maximum Profit:  150.39999999999907\n",
      "Maximum Loss:  -381.7000000000007\n",
      "Cumulative Pips is : 7273.0999999999785\n",
      "*************************************************\n",
      "Buy at 2017.11.30 13:01 price 152.23000, limit order at 155.23000, stop loss at 144.19000\n",
      "Long position opened 2017.11.30 13:01 price 152.23000 closed 2018.01.22 14:37 profit 300 pips\n",
      "Maximum Profit:  302.000000000001\n",
      "Maximum Loss:  -281.89999999999884\n",
      "Cumulative Pips is : 7573.0999999999785\n",
      "************************************************\n",
      "Sell at 2018.02.09 07:37 price 150.02700, limit order at 147.02700, stop loss at 158.02700\n",
      "Short position opened 2018.02.09 07:37 price 150.02700 closed 2018.02.28 10:37 profit 300 pips\n",
      "Maximum Profit:  307.3999999999984\n",
      "Maximum Loss:  -105.60000000000116\n",
      "Cumulative Pips is : 7873.0999999999785\n",
      "*************************************************\n",
      "Buy at 2018.03.13 09:37 price 149.38300, limit order at 152.38300, stop loss at 141.34300\n",
      "Long position opened 2018.03.13 09:37 price 149.38300 closed 2018.04.12 09:07 profit 300 pips\n",
      "Maximum Profit:  306.19999999999834\n",
      "Maximum Loss:  -234.00000000000034\n",
      "Cumulative Pips is : 8173.0999999999785\n",
      "************************************************\n",
      "Sell at 2018.05.01 10:37 price 149.36400, limit order at 146.36400, stop loss at 157.36400\n",
      "Short position opened 2018.05.01 10:37 price 149.36400 closed 2018.05.23 05:37 profit 300 pips\n",
      "Maximum Profit:  309.39999999999657\n",
      "Maximum Loss:  -75.50000000000239\n",
      "Cumulative Pips is : 8473.099999999979\n",
      "*************************************************\n",
      "Buy at 2018.07.16 00:07 price 148.95200, limit order at 151.95200, stop loss at 140.91200\n",
      "Long position opened 2018.07.16 00:07 price 148.95200 closed 2018.08.10 02:07 profit -702.70000 pips\n",
      "Maximum Profit:  35.50000000000182\n",
      "Maximum Loss:  -724.5000000000005\n",
      "Cumulative Pips is : 7770.399999999977\n",
      "*************************************************\n",
      "Sell at 2018.08.10 02:07 price 141.92500, limit order at 138.92500, stop loss at 149.92500\n",
      "Short position opened 2018.08.10 02:07 price 141.92500 closed 2018.08.29 09:37 profit -182.30000 pips\n",
      "Maximum Profit:  203.2999999999987\n",
      "Maximum Loss:  -285.0000000000023\n",
      "Cumulative Pips is : 7588.099999999976\n",
      "*************************************************\n",
      "Buy at 2018.08.29 09:37 price 143.74800, limit order at 146.74800, stop loss at 135.70800\n",
      "Long position opened 2018.08.29 09:37 price 143.74800 closed 2018.09.13 15:07 profit 300 pips\n",
      "Maximum Profit:  303.60000000000014\n",
      "Maximum Loss:  -115.99999999999966\n",
      "Cumulative Pips is : 7888.099999999976\n",
      "************************************************\n",
      "Sell at 2018.10.24 11:07 price 145.00500, limit order at 142.00500, stop loss at 153.00500\n",
      "Short position opened 2018.10.24 11:07 price 145.00500 closed 2018.11.05 13:37 profit -267.20000 pips\n",
      "Maximum Profit:  223.49999999999852\n",
      "Maximum Loss:  -265.2000000000015\n",
      "Cumulative Pips is : 7620.899999999973\n",
      "*************************************************\n",
      "Buy at 2018.11.05 13:37 price 147.67700, limit order at 150.67700, stop loss at 139.63700\n",
      "Long position opened 2018.11.05 13:37 price 147.67700 closed 2018.11.15 04:07 profit -238.50000 pips\n",
      "Maximum Profit:  180.39999999999736\n",
      "Maximum Loss:  -245.40000000000362\n",
      "Cumulative Pips is : 7382.399999999971\n",
      "*************************************************\n",
      "Sell at 2018.11.15 04:07 price 145.29200, limit order at 142.29200, stop loss at 153.29200\n",
      "Short position opened 2018.11.15 04:07 price 145.29200 closed 2018.12.10 10:37 profit 300 pips\n",
      "Maximum Profit:  412.2000000000014\n",
      "Maximum Loss:  -65.0999999999982\n",
      "Cumulative Pips is : 7682.399999999971\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "#stochastic = slow_stochastic(data, 15, 5)\n",
    "stochastic = sstoc(data)\n",
    "\n",
    "limit = 300\n",
    "stop = 800\n",
    "\n",
    "#limit = 30\n",
    "#stop = 80\n",
    "trailing_stop = 0\n",
    "\n",
    "first_min = 1000\n",
    "first_max = 0\n",
    "second_min = 1000\n",
    "second_max = 0\n",
    "\n",
    "distance = 80\n",
    "p = position()\n",
    "N = len(High)\n",
    "cumpips = 0\n",
    "state = -3\n",
    "uptrend = False\n",
    "max_value = 0\n",
    "min_value = 1000\n",
    "#trendprice = Close[0]\n",
    "#trendprice = 1.34517\n",
    "#triggerprice = Close[0]\n",
    "#triggerprice = 1.36082\n",
    "\n",
    "for i in range(N):\n",
    "    #print(\"%s: state: %d, trend: %.5f, trigger: %.5f, shooting: %.5f, min:%.5f, max:%.5f, high:%.5f, low: %.5f, uptrend: %r \"%(Time[i], state, trendprice, triggerprice, shootingprice, min_value, max_value, High[i], Low[i], uptrend))\n",
    "    if p.have_position:\n",
    "        cumpips, state = p.close_position(cumpips, Time[i], Low[i], High[i], state)\n",
    "                \n",
    "            \n",
    "            #if state == 3:\n",
    "            #        state = 0\n",
    "             #   elif state == 13:\n",
    "              #      state = 10\n",
    "                    \n",
    "                \n",
    "        #elif p.position_type == \"Long\":\n",
    "         #   if distant(High[i], p.open_price, (cap+2)*10):\n",
    "          #      cumpips = p.close_position(cumpips, Time[i], cap)\n",
    "           #     if state == 3:\n",
    "            #        state = 0\n",
    "             #   elif state == 13:\n",
    "              #      state = 10\n",
    "        \n",
    "        \n",
    "    if state == -3:\n",
    "            if first_max < High[i]: first_max = High[i]\n",
    "            if first_min > Low[i]: first_min = Low[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                state = -21\n",
    "                first_min = first_max\n",
    "            elif SC==1:\n",
    "                state = -20\n",
    "                first_max = first_min\n",
    "    \n",
    "    elif state == -20:\n",
    "            if first_max < High[i]: first_max = High[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                state = -22\n",
    "                first_min = first_max\n",
    "                \n",
    "    elif state == -22:\n",
    "            if first_min > Low[i]: first_min = Low[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==1: \n",
    "                state = -24\n",
    "                second_max = first_min\n",
    "                \n",
    "    elif state == -24:\n",
    "            if second_max < High[i]: second_max = High[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                if second_max <= first_max:\n",
    "                    uptrend = False\n",
    "                    triggerprice = first_max\n",
    "                    trendprice = first_min\n",
    "                    state = 0\n",
    "                else:\n",
    "                    uptrend = True\n",
    "                    triggerprice = first_min\n",
    "                    trendprice = second_max\n",
    "                    state = 0\n",
    "\n",
    "    elif state == -21:\n",
    "            if first_min > Low[i]: first_min = Low[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==1: \n",
    "                state = -23\n",
    "                first_max = first_min\n",
    "                \n",
    "    elif state == -23:\n",
    "            if first_max < High[i]: first_max = High[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                state = -25\n",
    "                second_min = first_max\n",
    "                \n",
    "    elif state == -25:\n",
    "            if second_min > Low[i]: second_min = Low[i]\n",
    "                \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2: \n",
    "                if second_min <= first_min:\n",
    "                    uptrend = False\n",
    "                    triggerprice = first_max\n",
    "                    trendprice = second_min\n",
    "                    state = 0\n",
    "                else:\n",
    "                    uptrend = True\n",
    "                    triggerprice = first_min\n",
    "                    trendprice = first_max\n",
    "                    state = 0        \n",
    "\n",
    "    elif state == 0:\n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            if distant(max_value,trendprice, distance):\n",
    "                triggerprice = min_value\n",
    "                #min_value = High[i]\n",
    "                state = 10\n",
    "              \n",
    "            if distant(triggerprice,min_value, distance):  \n",
    "                state = 1\n",
    "                max_value = min_value\n",
    "        else: \n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            if distant(trendprice, min_value, distance):\n",
    "                triggerprice = max_value\n",
    "                #max_value = Low[i]\n",
    "                state = 10\n",
    "            \n",
    "            if distant(max_value,triggerprice, distance):\n",
    "                state = 1\n",
    "                min_value = max_value\n",
    "    \n",
    "    elif state == 10:  \n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "\n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2:\n",
    "                trendprice = max_value \n",
    "               # triggerprice = min_value\n",
    "                min_value = High[i]\n",
    "                state = 0\n",
    "            \n",
    "            if distant(triggerprice,min_value, distance):\n",
    "                trendprice = max_value\n",
    "                state = 1\n",
    "        else:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC == 1:\n",
    "                trendprice = min_value\n",
    "              #  triggerprice = max_value\n",
    "                max_value = Low[i]\n",
    "                state = 0\n",
    "                \n",
    "            if distant(max_value,triggerprice, distance):\n",
    "                trendprice = min_value\n",
    "                state = 1\n",
    "\n",
    "    elif state == 1:\n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            if distant(max_value,trendprice, distance):\n",
    "                if p.have_position:\n",
    "                    state = 3\n",
    "                    continue                \n",
    "                else:\n",
    "                    state = 0\n",
    "                    continue\n",
    "            \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==1: \n",
    "                shootingprice = min_value\n",
    "                max_value = min_value\n",
    "                state = 2\n",
    "        else:\n",
    "            \n",
    "            if max_value < High[i]: max_value=High[i]\n",
    "            if min_value > Low[i]: min_value=Low[i]\n",
    "            \n",
    "            if distant(trendprice,min_value, distance):\n",
    "                if p.have_position:\n",
    "                    state = 3\n",
    "                    continue \n",
    "                else:\n",
    "                    state = 0\n",
    "                    continue\n",
    "            \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2:\n",
    "                shootingprice = max_value\n",
    "                min_value = max_value\n",
    "                state = 2 \n",
    "    \n",
    "    elif state == 2:\n",
    "        \n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value=High[i]\n",
    "            if min_value > Low[i]: min_value=Low[i]\n",
    "            \n",
    "            if distant(max_value,trendprice, distance):\n",
    "                if p.have_position:\n",
    "                    triggerprice = min_value\n",
    "                    state = 13\n",
    "                    min_value = High[i]\n",
    "                    continue\n",
    "                else:\n",
    "                    triggerprice = shootingprice\n",
    "                    state = 10\n",
    "                    min_value = High[i]\n",
    "                    continue\n",
    "            \n",
    "            if distant(shootingprice,min_value, distance):\n",
    "                limit_price = shootingprice - (distance + limit) * PIP_RATIO\n",
    "               # stop_price = max_value + distance * 0.00001\n",
    "                stop_price = shootingprice  - (distance - stop) * PIP_RATIO\n",
    "                uptrend, cumpips = p.take_position(\"Sell\",uptrend,cumpips,shootingprice - distance * PIP_RATIO, abs(shootingprice - trendprice)*100, abs(triggerprice - trendprice)*100, Time[i], limit_price, stop_price, trailing_stop, i)\n",
    "                state = 3\n",
    "                trendprice = shootingprice\n",
    "                triggerprice = max_value\n",
    "                continue\n",
    "        else:\n",
    "            if max_value<High[i]: max_value=High[i]\n",
    "            if min_value>Low[i]: min_value=Low[i];\n",
    "            \n",
    "            if distant(trendprice, min_value, distance):\n",
    "                if p.have_position:\n",
    "                    triggerprice = max_value\n",
    "                    state = 13\n",
    "                    max_value = Low[i]\n",
    "                    continue                 \n",
    "                else:\n",
    "                    triggerprice = shootingprice\n",
    "                    state = 10\n",
    "                    max_value = Low[i]\n",
    "                    continue\n",
    "            \n",
    "            if distant(max_value,shootingprice, distance):\n",
    "                limit_price = shootingprice + (distance + MARGIN + limit) * PIP_RATIO\n",
    "                #stop_price = min_value - distance * 0.00001\n",
    "                stop_price = shootingprice + (distance  - stop) * PIP_RATIO\n",
    "                uptrend, cumpips = p.take_position(\"Buy\",uptrend,cumpips,shootingprice + (distance + MARGIN) * PIP_RATIO, abs(shootingprice - trendprice)*100, abs(triggerprice - trendprice)*100, Time[i], limit_price, stop_price, trailing_stop, i)\n",
    "                state = 3\n",
    "                trendprice = shootingprice\n",
    "                triggerprice = min_value\n",
    "                continue\n",
    "    \n",
    "    elif state == 3:\n",
    "        if uptrend:\n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "                    \n",
    "            if distant(max_value,trendprice, distance):\n",
    "                triggerprice = min_value\n",
    "                #min_value = High[i]\n",
    "                state = 13\n",
    "              \n",
    "            if distant(triggerprice,min_value, distance):  \n",
    "                state = 1 \n",
    "        else: \n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            if distant(trendprice, min_value, distance):\n",
    "                triggerprice = max_value\n",
    "                #max_value = Low[i]\n",
    "                state = 13\n",
    "            \n",
    "            if distant(max_value,triggerprice, distance):\n",
    "                state = 1\n",
    "                continue\n",
    "    \n",
    "    elif state == 13:  \n",
    "        if uptrend:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "\n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC==2:\n",
    "                trendprice = max_value \n",
    "               # triggerprice = min_value\n",
    "                min_value = High[i]\n",
    "                state = 3\n",
    "            \n",
    "            if distant(triggerprice,min_value, distance):\n",
    "                trendprice = max_value\n",
    "                state = 1\n",
    "                continue\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if max_value < High[i]: max_value = High[i]\n",
    "            if min_value > Low[i]: min_value = Low[i]\n",
    "            \n",
    "            SC = stochastic_crossover(i, stochastic)\n",
    "            if SC == 1:\n",
    "                trendprice = min_value\n",
    "              #  triggerprice = max_value\n",
    "                max_value = Low[i]\n",
    "                state = 3\n",
    "                \n",
    "            if distant(max_value,triggerprice, distance):\n",
    "                trendprice = min_value\n",
    "                state = 1 \n",
    "                continue\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009.01.01 19:00</td>\n",
       "      <td>133.680</td>\n",
       "      <td>134.070</td>\n",
       "      <td>133.650</td>\n",
       "      <td>133.990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2009.01.01 19:30</td>\n",
       "      <td>133.990</td>\n",
       "      <td>134.050</td>\n",
       "      <td>133.730</td>\n",
       "      <td>133.920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2009.01.01 20:00</td>\n",
       "      <td>133.910</td>\n",
       "      <td>133.960</td>\n",
       "      <td>133.670</td>\n",
       "      <td>133.690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2009.01.01 20:30</td>\n",
       "      <td>133.680</td>\n",
       "      <td>133.780</td>\n",
       "      <td>133.320</td>\n",
       "      <td>133.440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2009.01.01 21:00</td>\n",
       "      <td>133.450</td>\n",
       "      <td>133.570</td>\n",
       "      <td>132.930</td>\n",
       "      <td>133.110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116457</td>\n",
       "      <td>116457</td>\n",
       "      <td>2018.12.31 14:07</td>\n",
       "      <td>139.755</td>\n",
       "      <td>139.794</td>\n",
       "      <td>139.522</td>\n",
       "      <td>139.559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116458</td>\n",
       "      <td>116458</td>\n",
       "      <td>2018.12.31 14:37</td>\n",
       "      <td>139.559</td>\n",
       "      <td>139.852</td>\n",
       "      <td>139.534</td>\n",
       "      <td>139.744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116459</td>\n",
       "      <td>116459</td>\n",
       "      <td>2018.12.31 15:07</td>\n",
       "      <td>139.745</td>\n",
       "      <td>139.796</td>\n",
       "      <td>139.716</td>\n",
       "      <td>139.787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116460</td>\n",
       "      <td>116460</td>\n",
       "      <td>2018.12.31 15:37</td>\n",
       "      <td>139.788</td>\n",
       "      <td>139.820</td>\n",
       "      <td>139.696</td>\n",
       "      <td>139.819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116461</td>\n",
       "      <td>116461</td>\n",
       "      <td>2018.12.31 16:07</td>\n",
       "      <td>139.820</td>\n",
       "      <td>139.829</td>\n",
       "      <td>139.708</td>\n",
       "      <td>139.796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116462 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0              Time     Open     High      Low    Close  \\\n",
       "0                0  2009.01.01 19:00  133.680  134.070  133.650  133.990   \n",
       "1                1  2009.01.01 19:30  133.990  134.050  133.730  133.920   \n",
       "2                2  2009.01.01 20:00  133.910  133.960  133.670  133.690   \n",
       "3                3  2009.01.01 20:30  133.680  133.780  133.320  133.440   \n",
       "4                4  2009.01.01 21:00  133.450  133.570  132.930  133.110   \n",
       "...            ...               ...      ...      ...      ...      ...   \n",
       "116457      116457  2018.12.31 14:07  139.755  139.794  139.522  139.559   \n",
       "116458      116458  2018.12.31 14:37  139.559  139.852  139.534  139.744   \n",
       "116459      116459  2018.12.31 15:07  139.745  139.796  139.716  139.787   \n",
       "116460      116460  2018.12.31 15:37  139.788  139.820  139.696  139.819   \n",
       "116461      116461  2018.12.31 16:07  139.820  139.829  139.708  139.796   \n",
       "\n",
       "        Volume  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "116457       0  \n",
       "116458       0  \n",
       "116459       0  \n",
       "116460       0  \n",
       "116461       0  \n",
       "\n",
       "[116462 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              115033\n",
       "Time          2018.11.15 04:07\n",
       "Open                   145.816\n",
       "High                   145.993\n",
       "Low                    145.223\n",
       "Close                  145.313\n",
       "Volume                       0\n",
       "Name: 115033, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[p.index[-1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018.11.15 04:07'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.open_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc629a796a0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "f.set_figheight(15)\n",
    "f.set_figwidth(15)\n",
    "ax.plot(p.accumPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe251d11d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "f.set_figheight(15)\n",
    "f.set_figwidth(15)\n",
    "ax.plot(p.accumPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000.0\n",
      "16900.0\n",
      "21970.0\n",
      "28561.0\n",
      "15862.779400000045\n",
      "20621.613220000057\n",
      "26808.097186000046\n",
      "34850.52634180006\n",
      "16334.44169640163\n",
      "21234.77420532212\n",
      "27605.206466918753\n",
      "35886.76840699438\n",
      "24295.342211535128\n",
      "31583.944874995665\n",
      "41059.12833749436\n",
      "53376.866838742666\n",
      "35036.575392950646\n",
      "45547.54801083584\n",
      "59211.81241408659\n",
      "76975.35613831256\n",
      "100067.96297980634\n",
      "130088.35187374824\n",
      "169114.85743587272\n",
      "219849.31466663454\n",
      "285804.1090666249\n",
      "371545.34178661235\n",
      "483008.9443225961\n",
      "627911.6276193749\n",
      "816285.1159051873\n",
      "1061170.6506767436\n",
      "1379521.8458797666\n",
      "1793378.3996436966\n",
      "1334990.8806947605\n",
      "1735488.1449031886\n",
      "2256134.5883741453\n",
      "2932974.9648863887\n",
      "3812867.4543523053\n",
      "4956727.690657997\n",
      "6443745.997855395\n",
      "5062851.230514965\n",
      "6581706.599669455\n",
      "8556218.579570292\n",
      "11123084.153441379\n",
      "14460009.399473794\n",
      "18798012.21931593\n",
      "24437415.88511071\n",
      "15261166.220251651\n",
      "19839516.086327147\n",
      "25791370.91222529\n",
      "33528782.18589288\n",
      "43587416.841660745\n",
      "12958539.027025677\n",
      "10596197.362398887\n",
      "13775056.571118552\n",
      "10094361.45531564\n",
      "7686856.248222841\n",
      "9992913.122689694\n"
     ]
    }
   ],
   "source": [
    "capital = 10000\n",
    "lot_amount = INVERSE_PIP_RATIO*10\n",
    "lots = capital / (lot_amount * 10)\n",
    "\n",
    "for i in range(20,len(p.profitloss)):\n",
    "    capital = capital + lot_amount* lots * p.profitloss[i] * PIP_RATIO\n",
    "    print(capital)\n",
    "    lots = capital / (lot_amount * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000.0\n",
      "10920.000000000015\n",
      "15288.00000000002\n",
      "21403.200000000026\n",
      "12841.920000000016\n",
      "17978.688000000024\n",
      "25170.16320000003\n",
      "35238.22848000005\n",
      "49333.51987200007\n",
      "69066.9278208001\n",
      "96693.69894912015\n",
      "67298.8144685877\n",
      "36139.46336963163\n",
      "50595.24871748428\n",
      "70833.348204478\n",
      "99166.68748626919\n",
      "138833.36248077685\n",
      "194366.7074730876\n",
      "272113.3904623226\n",
      "189390.91976177678\n",
      "111551.25173968679\n",
      "104077.31787312792\n",
      "66401.32880305557\n",
      "31540.631181451397\n",
      "44156.88365403196\n",
      "28039.621120310396\n",
      "39255.46956843455\n",
      "54957.65739580837\n",
      "76940.72035413171\n",
      "53550.74136647573\n",
      "74971.03791306603\n",
      "104959.45307829244\n",
      "59239.11531738846\n",
      "82934.76144434384\n",
      "116108.66602208136\n",
      "162552.13243091392\n",
      "227572.98540327948\n",
      "318602.17956459126\n",
      "191161.30773875475\n",
      "133048.27018617344\n",
      "72178.68657599925\n",
      "37359.688171737325\n",
      "27907.687064287777\n",
      "39070.76189000289\n",
      "54699.06664600405\n",
      "76578.69330440566\n",
      "107210.17062616794\n",
      "150094.2388766351\n",
      "210131.93442728912\n",
      "125238.63291866447\n",
      "108394.03679110447\n",
      "151751.65150754625\n",
      "212452.31211056476\n",
      "147866.80922895324\n",
      "207013.53292053452\n",
      "144081.4189126922\n",
      "201713.9864777691\n",
      "282399.5810688767\n",
      "395359.4134964274\n",
      "553503.1788949984\n",
      "449112.47935540194\n",
      "628757.4710975627\n",
      "880260.4595365878\n",
      "1232364.6433512229\n",
      "1725310.500691712\n",
      "2415434.700968397\n",
      "3381608.5813557557\n",
      "4734252.013898058\n",
      "6627952.819457281\n",
      "9279133.947240194\n",
      "12990787.526136272\n",
      "8867511.565340647\n",
      "6207258.095738453\n",
      "8690161.334033834\n",
      "12166225.867647368\n",
      "9925207.062826741\n",
      "7723796.136291781\n",
      "10813314.590808494\n",
      "6060862.828148181\n",
      "8485207.959407452\n",
      "11879291.143170435\n",
      "16631007.60043861\n",
      "23283410.640614055\n",
      "11548571.67774459\n",
      "8608305.328590825\n",
      "12051627.460027155\n",
      "8349367.504306809\n",
      "6024068.654357365\n",
      "8433696.116100311\n"
     ]
    }
   ],
   "source": [
    "capital = 10000\n",
    "lot_amount = INVERSE_PIP_RATIO*10\n",
    "lots = capital / (lot_amount * 10)\n",
    "\n",
    "for i in range(len(p.profitloss)):\n",
    "    capital = capital + lot_amount* lots * p.profitloss[i] * PIP_RATIO\n",
    "    print(capital)\n",
    "    lots = capital / (lot_amount * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5990.000000000009\n",
      "-2049.999999999998\n",
      "950.0000000000018\n",
      "3950.000000000002\n",
      "-2700.0000000000045\n",
      "299.99999999999545\n",
      "-2740.000000000025\n",
      "259.999999999975\n",
      "-5210.000000000053\n",
      "-2210.0000000000528\n",
      "-8620.000000000076\n",
      "-5620.000000000076\n",
      "-12870.000000000106\n",
      "-19350.000000000124\n",
      "-16350.000000000124\n",
      "-13350.000000000124\n",
      "-10350.000000000124\n",
      "-7350.000000000124\n",
      "-4350.000000000124\n",
      "-12390.000000000116\n",
      "-9390.000000000116\n",
      "-6390.000000000116\n",
      "-3390.0000000001164\n",
      "-390.0000000001164\n",
      "-4836.0000000001\n",
      "-1836.0000000001\n",
      "1163.9999999998859\n",
      "4163.999999999885\n",
      "-1149.000000000131\n",
      "1850.999999999869\n",
      "4850.999999999869\n",
      "7850.999999999869\n",
      "4620.999999999851\n",
      "7620.999999999851\n",
      "10620.99999999985\n",
      "13620.99999999985\n",
      "10184.999999999844\n",
      "13184.999999999844\n",
      "16184.999999999844\n",
      "19184.999999999844\n",
      "22184.999999999844\n",
      "25184.999999999844\n",
      "28184.999999999844\n",
      "31184.999999999844\n",
      "34184.99999999984\n",
      "37184.99999999984\n",
      "40184.99999999984\n",
      "43184.99999999984\n",
      "46184.99999999984\n",
      "49184.99999999984\n",
      "52184.99999999984\n",
      "55184.99999999984\n",
      "52628.999999999796\n",
      "55628.999999999796\n",
      "58628.999999999796\n",
      "61628.999999999796\n",
      "64628.999999999796\n",
      "67628.9999999998\n",
      "70628.9999999998\n",
      "68485.99999999977\n",
      "71485.99999999977\n",
      "74485.99999999977\n",
      "77485.99999999977\n",
      "80485.99999999977\n",
      "83485.99999999977\n",
      "86485.99999999977\n",
      "82730.99999999977\n",
      "85730.99999999977\n",
      "88730.99999999977\n",
      "91730.99999999977\n",
      "94730.99999999977\n",
      "87703.99999999975\n",
      "85880.99999999974\n",
      "88880.99999999974\n",
      "86208.99999999971\n",
      "83823.9999999997\n",
      "86823.9999999997\n"
     ]
    }
   ],
   "source": [
    "capital = 10000\n",
    "lots = 1\n",
    "lot_amount = INVERSE_PIP_RATIO*10\n",
    "for i in range(len(p.profitloss)):\n",
    "    capital += lot_amount* lots * p.profitloss[i] * PIP_RATIO\n",
    "    print(capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196.0000000000007\n",
      "982.5140000000015\n",
      "855.5731912000009\n",
      "941.1305103200029\n",
      "887.7684103848582\n",
      "893.8940124165124\n",
      "818.9856941760081\n",
      "696.3835357578603\n",
      "832.8747087664013\n",
      "916.1621796430434\n",
      "1095.7299668530804\n",
      "989.1154410782755\n",
      "1084.0705234217903\n",
      "780.2055557066601\n",
      "735.655818475809\n",
      "666.2099092116935\n",
      "796.7870514171858\n",
      "732.4863363678205\n",
      "643.3427492318583\n",
      "537.3198641584491\n",
      "642.6345575335055\n",
      "642.1847133432319\n",
      "768.0529171585058\n",
      "844.8582088743582\n",
      "807.5154760421127\n",
      "969.0185712505372\n",
      "885.586072265868\n",
      "812.0824282678032\n",
      "971.250584208293\n",
      "862.5676438353869\n",
      "871.5383473312762\n",
      "1045.8460167975336\n",
      "937.600954058988\n",
      "849.6539845682555\n",
      "1016.1861655436342\n",
      "928.7941553068822\n",
      "1110.8378097470318\n",
      "1333.0053716964408\n",
      "1594.274424548944\n",
      "1913.1293094587365\n",
      "2288.1026541126503\n",
      "2333.8647071949085\n",
      "2084.8413429372126\n",
      "1803.3877616406876\n",
      "1765.6969574223986\n",
      "1942.2666531646425\n",
      "1739.6882412395717\n",
      "2087.62588948749\n",
      "2090.339803143823\n",
      "2508.4077637725923\n",
      "2143.4344341436786\n",
      "2357.7778775580514\n",
      "2218.9047605698834\n",
      "1936.4381845493392\n",
      "1506.9361952162983\n",
      "1339.9676647863328\n",
      "1183.4594415392903\n",
      "1084.0488484499904\n",
      "1296.5224227461892\n",
      "1296.5224227461922\n",
      "1165.9626147756503\n",
      "1103.0006335777643\n",
      "1012.3339814976733\n",
      "1214.8007777972105\n",
      "1452.9017302454645\n",
      "1276.5194601936646\n",
      "1261.7118344554174\n",
      "1222.4725964038546\n",
      "1462.077225299011\n",
      "1608.2849478289154\n",
      "1424.1363213025052\n",
      "1708.9635855630097\n",
      "1448.3466387646547\n",
      "1462.5404358245512\n",
      "1749.198361246164\n",
      "1639.173784323782\n"
     ]
    }
   ],
   "source": [
    "capital = 1000\n",
    "lots = 1\n",
    "lot_amount = 100000\n",
    "for i in range(len(p.profitloss)):\n",
    "    capital = capital + lots*capital*10*p.profitloss[i]*0.0001\n",
    "    print(capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11960.000000000007\n",
      "10175.000000000015\n",
      "8883.000000000011\n",
      "9883.000000000035\n",
      "9316.000000000027\n",
      "9385.000000000013\n",
      "8547.000000000007\n",
      "7050.000000000015\n",
      "9010.000000000022\n",
      "10010.000000000045\n",
      "11970.000000000051\n",
      "10997.00000000005\n",
      "11957.000000000055\n",
      "9154.000000000033\n",
      "8583.000000000022\n",
      "7639.000000000033\n",
      "9599.00000000004\n",
      "8792.00000000006\n",
      "7575.000000000081\n",
      "5927.000000000098\n",
      "7887.000000000105\n",
      "7880.000000000103\n",
      "9840.00000000011\n",
      "10840.000000000133\n",
      "10398.000000000146\n",
      "12398.00000000017\n",
      "11537.000000000191\n",
      "10707.000000000216\n",
      "12667.000000000222\n",
      "11548.00000000024\n",
      "11652.000000000255\n",
      "13652.000000000278\n",
      "12617.000000000271\n",
      "11679.000000000276\n",
      "13639.000000000284\n",
      "12779.00000000029\n",
      "14739.000000000295\n",
      "16739.00000000032\n",
      "18699.000000000327\n",
      "20699.000000000353\n",
      "22659.00000000036\n",
      "22859.000000000382\n",
      "21792.000000000386\n",
      "20442.00000000038\n",
      "20233.000000000386\n",
      "21233.000000000407\n",
      "20190.000000000415\n",
      "22190.00000000044\n",
      "22203.000000000437\n",
      "24203.000000000462\n",
      "22748.000000000455\n",
      "23748.000000000477\n",
      "23159.00000000048\n",
      "21886.00000000049\n",
      "19668.000000000506\n",
      "18560.00000000051\n",
      "17392.000000000517\n",
      "16552.00000000052\n",
      "18512.000000000528\n",
      "18512.00000000055\n",
      "17505.000000000546\n",
      "16965.00000000054\n",
      "16143.00000000055\n",
      "18143.000000000575\n",
      "20103.000000000582\n",
      "18889.00000000058\n",
      "18773.000000000575\n",
      "18462.00000000058\n",
      "20422.000000000586\n",
      "21422.000000000608\n",
      "20277.00000000061\n",
      "22277.000000000637\n",
      "20752.000000000662\n",
      "20850.000000000684\n",
      "22810.00000000069\n",
      "22181.000000000702\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DAT_MT_GBPJPY_M1_2019.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-28cc5784c1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfile_name_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DAT_MT_{}_{}_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DAT_MT_GBPJPY_M1_2019.zip'"
     ]
    }
   ],
   "source": [
    "pair = 'gbpjpy'\n",
    "year='2019'\n",
    "time_frame = \"M1\"\n",
    "\n",
    "download_hist_data(year=year,month=1,pair=pair, platform=Platform.META_TRADER, time_frame=TimeFrame.ONE_MINUTE, verbose=False)\n",
    "\n",
    "file_name = 'DAT_MT_{}_{}_{}.zip'.format(pair.upper(), time_frame,year)\n",
    "file_name_csv = 'DAT_MT_{}_{}_{}.csv'.format(pair.upper(), time_frame,year)\n",
    "\n",
    "\n",
    "\n",
    "data.columns = ['Date','Time','Open','High','Low','Close','Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile(\"DAT_MT_GBPJPY_M1_201901.zip\", 'r')\n",
    "data = pd.read_csv(archive.open(\"DAT_MT_GBPJPY_M1_201901.csv\"), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019.01.01</td>\n",
       "      <td>17:06</td>\n",
       "      <td>139.702</td>\n",
       "      <td>139.727</td>\n",
       "      <td>139.680</td>\n",
       "      <td>139.721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019.01.01</td>\n",
       "      <td>17:08</td>\n",
       "      <td>139.685</td>\n",
       "      <td>139.685</td>\n",
       "      <td>139.684</td>\n",
       "      <td>139.684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019.01.01</td>\n",
       "      <td>17:09</td>\n",
       "      <td>139.680</td>\n",
       "      <td>139.731</td>\n",
       "      <td>139.679</td>\n",
       "      <td>139.727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019.01.01</td>\n",
       "      <td>17:12</td>\n",
       "      <td>139.493</td>\n",
       "      <td>139.629</td>\n",
       "      <td>139.493</td>\n",
       "      <td>139.629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019.01.01</td>\n",
       "      <td>17:13</td>\n",
       "      <td>139.629</td>\n",
       "      <td>139.630</td>\n",
       "      <td>139.552</td>\n",
       "      <td>139.629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32021</td>\n",
       "      <td>2019.01.31</td>\n",
       "      <td>23:54</td>\n",
       "      <td>142.541</td>\n",
       "      <td>142.549</td>\n",
       "      <td>142.540</td>\n",
       "      <td>142.544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32022</td>\n",
       "      <td>2019.01.31</td>\n",
       "      <td>23:55</td>\n",
       "      <td>142.544</td>\n",
       "      <td>142.547</td>\n",
       "      <td>142.537</td>\n",
       "      <td>142.545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32023</td>\n",
       "      <td>2019.01.31</td>\n",
       "      <td>23:56</td>\n",
       "      <td>142.545</td>\n",
       "      <td>142.547</td>\n",
       "      <td>142.539</td>\n",
       "      <td>142.546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32024</td>\n",
       "      <td>2019.01.31</td>\n",
       "      <td>23:57</td>\n",
       "      <td>142.542</td>\n",
       "      <td>142.545</td>\n",
       "      <td>142.537</td>\n",
       "      <td>142.545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32025</td>\n",
       "      <td>2019.01.31</td>\n",
       "      <td>23:58</td>\n",
       "      <td>142.545</td>\n",
       "      <td>142.548</td>\n",
       "      <td>142.537</td>\n",
       "      <td>142.548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32026 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0      1        2        3        4        5  6\n",
       "0      2019.01.01  17:06  139.702  139.727  139.680  139.721  0\n",
       "1      2019.01.01  17:08  139.685  139.685  139.684  139.684  0\n",
       "2      2019.01.01  17:09  139.680  139.731  139.679  139.727  0\n",
       "3      2019.01.01  17:12  139.493  139.629  139.493  139.629  0\n",
       "4      2019.01.01  17:13  139.629  139.630  139.552  139.629  0\n",
       "...           ...    ...      ...      ...      ...      ... ..\n",
       "32021  2019.01.31  23:54  142.541  142.549  142.540  142.544  0\n",
       "32022  2019.01.31  23:55  142.544  142.547  142.537  142.545  0\n",
       "32023  2019.01.31  23:56  142.545  142.547  142.539  142.546  0\n",
       "32024  2019.01.31  23:57  142.542  142.545  142.537  142.545  0\n",
       "32025  2019.01.31  23:58  142.545  142.548  142.537  142.548  0\n",
       "\n",
       "[32026 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['Date','Time','Open', 'High', 'Low', 'Close', 'Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Time, Date, Open, High, Low, Close, Volume = time_convertor(data,30)\n",
    "\n",
    "week_day = []\n",
    "for i in range(len(Time)):\n",
    "    day = Date[i].split('.')[2]\n",
    "    month = Date[i].split('.')[1]\n",
    "    year = Date[i].split('.')[0]\n",
    "    week_day.append(calendar.weekday(int(year), int(month), int(day)))\n",
    "\n",
    "Time = np.array(Time)  \n",
    "Open = np.array(Open)  \n",
    "High =  np.array (High)\n",
    "Low =  np.array(Low)\n",
    "Close =  np.array(Close)\n",
    "#Ask = np.array(Ask)\n",
    "week_day = np.array(week_day)\n",
    "\n",
    "l = np.where(np.logical_or(week_day == 5, week_day == 6))\n",
    "\n",
    "Time = np.delete(Time, l)  \n",
    "Open = np.delete(Open, l)  \n",
    "High =  np.delete (High, l)\n",
    "Low =  np.delete(Low, l)\n",
    "Close =  np.delete(Close, l)\n",
    "Volume = np.delete(Volume, l)\n",
    "#Ask = np.delete(Ask, l)\n",
    "\n",
    "data = pd.DataFrame(list(zip(Time, Open, High, Low, Close, Volume)),\n",
    "            columns=['Time','Open', 'High', 'Low', 'Close', 'Volume'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
